{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER0 = 'vmh2.isa.ru'\n",
    "SERVER2 = 'tsa05.isa.ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp import PipelineCommon\n",
    "from isanlp.processor_remote import ProcessorRemote\n",
    "from isanlp.ru.processor_mystem import ProcessorMystem\n",
    "from isanlp.ru.converter_mystem_to_ud import ConverterMystemToUd\n",
    "\n",
    "address_morph = (SERVER0, 4333)\n",
    "address_syntax = (SERVER0, 5336)\n",
    "address_rst = (SERVER0, 3346)\n",
    "address_rst = (SERVER2, 3336)\n",
    "\n",
    "ppl = PipelineCommon([\n",
    "    (ProcessorRemote(address_syntax[0], address_syntax[1], '0'),\n",
    "     ['text'],\n",
    "     {'sentences': 'sentences',\n",
    "      'tokens': 'tokens',\n",
    "      'lemma': 'lemma',\n",
    "      'syntax_dep_tree': 'syntax_dep_tree',\n",
    "      'postag': 'ud_postag'}),\n",
    "    (ProcessorMystem(delay_init=False),\n",
    "     ['tokens', 'sentences'],\n",
    "     {'postag': 'postag'}),\n",
    "    (ConverterMystemToUd(),\n",
    "     ['postag'],\n",
    "     {'morph': 'morph',\n",
    "      'postag': 'postag'}),\n",
    "    (ProcessorRemote(address_rst[0], address_rst[1], 'default'),\n",
    "     ['text', 'tokens', 'sentences', 'postag', 'morph', 'lemma', 'syntax_dep_tree'],\n",
    "     {'rst': 'rst'})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_reading import read_annotation, read_edus, read_gold\n",
    "from utils.evaluation import *\n",
    "\n",
    "example = 'data/news2_4'\n",
    "text = open('corpus/RuRsTreebank_full_2/news2/news2_txt/news2_4.txt', 'r').read().strip()\n",
    "gold_edus = read_edus(example)\n",
    "gold_pairs = prepare_gold_pairs(read_gold(example, features=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result = ppl(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tree in result['rst']:\n",
    "    print(tree.proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tmp = pd.DataFrame([cache2])\n",
    "tmp['pr_seg'] = tmp.seg_true_pred / tmp.seg_all_pred\n",
    "tmp['re_seg'] = tmp.seg_true_pred / tmp.seg_all_true\n",
    "tmp['f1_seg'] = 2 * tmp.pr_seg * tmp.re_seg / (tmp.pr_seg + tmp.re_seg)\n",
    "tmp['pr_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_pred\n",
    "tmp['re_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_true\n",
    "tmp['f1_unlab'] = 2 * tmp.pr_unlab * tmp.re_unlab / (tmp.pr_unlab + tmp.re_unlab)\n",
    "tmp['pr_lab'] = tmp.lab_true_pred / tmp.lab_all_pred\n",
    "tmp['re_lab'] = tmp.lab_true_pred / tmp.lab_all_true\n",
    "tmp['f1_lab'] = 2 * tmp.pr_lab * tmp.re_lab / (tmp.pr_lab + tmp.re_lab)\n",
    "tmp['pr_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_pred\n",
    "tmp['re_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_true\n",
    "tmp['f1_nuc'] = 2 * tmp.pr_nuc * tmp.re_nuc / (tmp.pr_nuc + tmp.re_nuc)\n",
    "tmp['pr_full'] = tmp.full_true_pred / tmp.full_all_pred\n",
    "tmp['re_full'] = tmp.full_true_pred / tmp.full_all_true\n",
    "tmp['f1_full'] = 2 * tmp.pr_full * tmp.re_full / (tmp.pr_full + tmp.re_full)\n",
    "tmp.sort_values('f1_full', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[[key for key in tmp.keys() if 'f1' in key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gold_pairs.relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import *\n",
    "\n",
    "pred_edus = []\n",
    "for tree in result['rst']:\n",
    "    pred_edus += extr_edus(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_edus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gold_edus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_edus), len(gold_edus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation = eval_pipeline(result['rst'], gold_edus, gold_pairs, result['text'])\n",
    "evaluation['filename'] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils/evaluation.py\n",
    "\n",
    "import pandas as pd\n",
    "from utils.file_reading import text_html_map\n",
    "\n",
    "\n",
    "class_mapper = {\n",
    "        'background_NS': 'other_NS',\n",
    "        'background_SN': 'other_SN',\n",
    "        'comparison_NN': 'other_NN',\n",
    "        'interpretation-evaluation_SN': 'other_NS',\n",
    "        'evidence_NS': 'other_NS',\n",
    "        'restatement_NN': 'other_NN',\n",
    "        'sequence_NN': 'other_NN',\n",
    "        'solutionhood_SN': 'other_NS',\n",
    "        'cause-effect_SN': 'joint_NN',\n",
    "        'preparation_SN': 'elaboration_NS'\n",
    "    }\n",
    "\n",
    "def prepare_gold_pairs(gold_pairs):\n",
    "    TARGET = 'category_id'\n",
    "\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace([0.0], 'same-unit_m')\n",
    "    gold_pairs['order'] = gold_pairs['order'].replace([0.0], 'NN')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "    gold_pairs['relation'] = gold_pairs[TARGET].map(lambda row: row[:-1]) + gold_pairs['order']\n",
    "    gold_pairs['relation'].value_counts()\n",
    "    gold_pairs['relation'] = gold_pairs['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "    gold_pairs['relation'] = gold_pairs['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "    gold_pairs['relation'] = gold_pairs['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "    gold_pairs['relation'] = gold_pairs['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                             'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "\n",
    "    for key, value in class_mapper.items():\n",
    "        gold_pairs['relation'] = gold_pairs['relation'].replace(key, value)\n",
    "        \n",
    "    gold_pairs['order'] = gold_pairs['relation'].map(lambda row: row.split('_')[1])\n",
    "    gold_pairs[TARGET] = gold_pairs['relation'].map(lambda row: row.split('_')[0])\n",
    "        \n",
    "    return gold_pairs\n",
    "\n",
    "def prepare_string(string):\n",
    "    for key, value in text_html_map.items():\n",
    "        string = string.replace(key, value).strip()\n",
    "                \n",
    "    if '-' in string:\n",
    "        string = string.replace('-', ' ').strip()\n",
    "\n",
    "    while '  ' in string:\n",
    "        string = string.replace('  ', ' ')\n",
    "        \n",
    "    return string.strip()\n",
    "\n",
    "def metric_parseval(parsed_pairs, gold, span=True, labeled=False, nuc=False):\n",
    "    parsed_strings = []\n",
    "    for row in parsed_pairs:\n",
    "        if span:\n",
    "            x, y = prepare_string(row[0]), prepare_string(row[1])\n",
    "\n",
    "        else:\n",
    "            x, y = '', ''\n",
    "            \n",
    "        label = ' ' + row[2].split('_')[0] if labeled else ''\n",
    "        nuclearity = ' ' + row[3] if nuc else ''\n",
    "            \n",
    "        if class_mapper.get(label + '_' + nuclearity):\n",
    "            label = ' ' + class_mapper.get(_label).split('_')[0] if labeled else ''\n",
    "            nuclearity = ' ' + class_mapper.get(_label).split('_')[1] if nuc else ''\n",
    "                \n",
    "        parsed_strings.append(x + ' ' + y + label + nuclearity)\n",
    "\n",
    "    parsed_strings = list(set(parsed_strings))\n",
    "\n",
    "    gold_strings = []\n",
    "    for i in gold.index:\n",
    "        if span:\n",
    "            x, y = prepare_string(gold.loc[i, 'snippet_x']), prepare_string(gold.loc[i, 'snippet_y'])\n",
    "\n",
    "        else:\n",
    "            x, y = '', ''\n",
    "\n",
    "        label = ' ' + gold.loc[i, 'category_id'].split('_')[0] if labeled else ''\n",
    "        nuclearity = ' ' + gold.loc[i, 'order'] if nuc else ''\n",
    "        \n",
    "        if class_mapper.get(label + '_' + nuclearity):\n",
    "            label = ' ' + class_mapper.get(_label).split('_')[0]\n",
    "            nuclearity = ' ' + class_mapper.get(_label).split('_')[1]\n",
    "            \n",
    "        gold_strings.append(x + ' ' + y + label + nuclearity)\n",
    "\n",
    "    gold_strings = set(gold_strings)\n",
    "    \n",
    "    _to_exclude = [string.split('other')[0] for string in gold_strings if 'other' in string]\n",
    "    gold_strings = set([string for string in gold_strings if not 'other' in string])\n",
    "    \n",
    "    _remove_from_parsed_strings = []\n",
    "    for i, parsed_string in enumerate(parsed_strings):\n",
    "        for excluding_pair in _to_exclude:\n",
    "            if excluding_pair in parsed_string:\n",
    "                _remove_from_parsed_strings.append(i)\n",
    "        \n",
    "    #all_parsed = [string for string in all_parsed if not 'other' in string]\n",
    "    parsed_strings = set([parsed_strings[i] for i in range(len(parsed_strings)) if not i in _remove_from_parsed_strings])\n",
    "\n",
    "    true_pos = len(gold_strings & parsed_strings)\n",
    "    all_parsed = len(parsed_strings)\n",
    "    all_gold = len(gold_strings)\n",
    "    return true_pos, all_parsed, all_gold\n",
    "\n",
    "\n",
    "def metric_parseval_df(parsed_pairs, gold, span=True, labeled=False, nuc=False):\n",
    "    parsed_strings = []\n",
    "    \n",
    "    parsed_strings = []\n",
    "    for i in parsed_pairs.index:\n",
    "        if span:\n",
    "            x, y = prepare_string(parsed_pairs.loc[i, 'snippet_x']), prepare_string(parsed_pairs.loc[i, 'snippet_y'])\n",
    "\n",
    "        else:\n",
    "            x, y = '', ''\n",
    "\n",
    "        label = ' ' + parsed_pairs.loc[i, 'category_id'].split('_')[0] if labeled else ''\n",
    "        nuclearity = ' ' + parsed_pairs.loc[i, 'order'] if nuc else ''\n",
    "        parsed_strings.append(x + ' ' + y + label + nuclearity)\n",
    "\n",
    "    parsed_strings = list(set(parsed_strings))\n",
    "\n",
    "    gold_strings = []\n",
    "    for i in gold.index:\n",
    "        if span:\n",
    "            x, y = prepare_string(gold.loc[i, 'snippet_x']), prepare_string(gold.loc[i, 'snippet_y'])\n",
    "\n",
    "        else:\n",
    "            x, y = '', ''\n",
    "\n",
    "        label = ' ' + gold.loc[i, 'category_id'].split('_')[0] if labeled else ''\n",
    "        nuclearity = ' ' + gold.loc[i, 'order'] if nuc else ''\n",
    "        gold_strings.append(x + ' ' + y + label + nuclearity)\n",
    "\n",
    "    gold_strings = set(gold_strings)\n",
    "    \n",
    "    _to_exclude = [string.split('other')[0] for string in gold_strings if 'other' in string]\n",
    "    gold_strings = set([string for string in gold_strings if not 'other' in string])\n",
    "    \n",
    "    _remove_from_parsed_strings = []\n",
    "    for i, parsed_string in enumerate(parsed_strings):\n",
    "        for excluding_pair in _to_exclude:\n",
    "            if excluding_pair in parsed_string:\n",
    "                _remove_from_parsed_strings.append(i)\n",
    "        \n",
    "    #all_parsed = [string for string in all_parsed if not 'other' in string]\n",
    "    parsed_strings = set([parsed_strings[i] for i in range(len(parsed_strings)) if not i in _remove_from_parsed_strings])\n",
    "\n",
    "    true_pos = len(gold_strings & parsed_strings)\n",
    "    all_parsed = len(parsed_strings)\n",
    "    all_gold = len(gold_strings)\n",
    "    return true_pos, all_parsed, all_gold\n",
    "\n",
    "\n",
    "def extr_pairs(tree):\n",
    "    pp = []\n",
    "    if tree.left:\n",
    "        pp.append([tree.left.text, tree.right.text, tree.relation])\n",
    "        pp += extr_pairs(tree.left)\n",
    "        pp += extr_pairs(tree.right)\n",
    "    return pp\n",
    "\n",
    "\n",
    "def extr_pairs(tree, text):\n",
    "    pp = []\n",
    "    if tree.left:\n",
    "        pp.append([text[tree.left.start:tree.left.end], text[tree.right.start:tree.right.end], tree.relation,\n",
    "                   tree.nuclearity])\n",
    "        pp += extr_pairs(tree.left, text)\n",
    "        pp += extr_pairs(tree.right, text)\n",
    "    return pp\n",
    "\n",
    "\n",
    "def extr_pairs_forest(forest, text):\n",
    "    pp = []\n",
    "    for tree in forest:\n",
    "        pp += extr_pairs(tree, text)\n",
    "    return pp\n",
    "\n",
    "\n",
    "def _check_snippet_pair_in_dataset(left_snippet, right_snippet):\n",
    "    left_snippet = left_snippet.strip()\n",
    "    right_snippet = right_snippet.strip()\n",
    "    return ((((gold.snippet_x == left_snippet) & (gold.snippet_y == right_snippet)).sum(axis=0) != 0)\n",
    "            or ((gold.snippet_y == left_snippet) & (gold.snippet_x == right_snippet)).sum(axis=0) != 0)\n",
    "\n",
    "\n",
    "def _not_parsed_as_in_gold(parsed_pairs: pd.DataFrame, gold: pd.DataFrame, labeled=False):\n",
    "    for key in text_html_map.keys():\n",
    "        parsed_pairs['snippet_x'].replace(key, text_html_map[key], regex=True, inplace=True)\n",
    "        parsed_pairs['snippet_y'].replace(key, text_html_map[key], regex=True, inplace=True)\n",
    "\n",
    "    for key in text_html_map.keys():\n",
    "        gold['snippet_x'].replace(key, text_html_map[key], regex=True, inplace=True)\n",
    "        gold['snippet_y'].replace(key, text_html_map[key], regex=True, inplace=True)\n",
    "\n",
    "    tmp = pd.merge(gold, parsed_pairs, on=['snippet_x', 'snippet_y'], how='left', suffixes=('_gold', '_parsed'))\n",
    "    if labeled:\n",
    "        tmp = tmp.fillna(0)\n",
    "        tmp = tmp[tmp.category_id_parsed != 0]\n",
    "        #tmp.category_id_gold = tmp.category_id_gold.map(lambda row: row[:-2])\n",
    "        return tmp[tmp.category_id_gold != tmp.category_id_parsed]\n",
    "    else:\n",
    "        return tmp[pd.isnull(tmp.category_id_parsed)]\n",
    "\n",
    "def extr_edus(tree):\n",
    "    edus = []\n",
    "    if tree.left:\n",
    "        edus += extr_edus(tree.left)\n",
    "        edus += extr_edus(tree.right)\n",
    "    else:\n",
    "        edus.append(tree.text)\n",
    "    return edus\n",
    "\n",
    "\n",
    "def eval_segmentation(trees, _gold_edus):\n",
    "    true_predictions = 0\n",
    "    all_predicted = 0\n",
    "    \n",
    "    gold_edus = []\n",
    "    \n",
    "    for gold_edu in _gold_edus:\n",
    "        gold_edus.append(prepare_string(gold_edu))\n",
    "\n",
    "    for tree in trees:\n",
    "        pred_edus = extr_edus(tree)\n",
    "        all_predicted += len(pred_edus)\n",
    "\n",
    "        for pred_edu in pred_edus:\n",
    "            pred_edu = prepare_string(pred_edu)\n",
    "\n",
    "            if prepare_string(pred_edu) in gold_edus:\n",
    "                true_predictions += 1\n",
    "                \n",
    "#             else:\n",
    "#                 print(pred_edu)\n",
    "\n",
    "    return true_predictions, all_predicted, len(gold_edus)\n",
    "\n",
    "\n",
    "def eval_pipeline(trees, gold_edus, gold_pairs, text):\n",
    "    parsed_pairs = extr_pairs_forest(trees, text)\n",
    "    result = {}\n",
    "    result['seg_true_pred'], result['seg_all_pred'], result['seg_all_true'] = eval_segmentation(trees, gold_edus)\n",
    "    result['unlab_true_pred'], result['unlab_all_pred'], result['unlab_all_true'] = metric_parseval(parsed_pairs,\n",
    "                                                                                                    gold_pairs)\n",
    "    result['lab_true_pred'], result['lab_all_pred'], result['lab_all_true'] = metric_parseval(parsed_pairs, gold_pairs,\n",
    "                                                                                              labeled=True, nuc=False)\n",
    "    result['nuc_true_pred'], result['nuc_all_pred'], result['nuc_all_true'] = metric_parseval(parsed_pairs, gold_pairs,\n",
    "                                                                                              labeled=False, nuc=True)\n",
    "    result['full_true_pred'], result['full_all_pred'], result['full_all_true'] = metric_parseval(parsed_pairs, gold_pairs,\n",
    "                                                                                                labeled=True, nuc=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm.autonotebook import tqdm\n",
    "from utils.train_test_split import split_train_dev_test\n",
    "from utils.file_reading import read_edus, read_gold\n",
    "from utils.evaluation import *\n",
    "\n",
    "result = ppl(text)\n",
    "file = example\n",
    "out_file = file.split('/')[-1]\n",
    "pickle.dump(result, open(f'parsing_results_0.5/{out_file}.pkl', 'wb'))\n",
    "\n",
    "cache = []\n",
    "gold_edus = read_edus(file)\n",
    "gold_pairs = prepare_gold_pairs(read_gold(file, features=True))\n",
    "\n",
    "evaluation = eval_pipeline(result['rst'], gold_edus, gold_pairs, result['text'])\n",
    "evaluation['filename'] = file\n",
    "cache.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "from utils.train_test_split import split_train_dev_test\n",
    "from utils.file_reading import read_edus, read_gold\n",
    "from utils.evaluation import *\n",
    "import pickle\n",
    "\n",
    "pipeline_evaluation = {}\n",
    "train, dev, test = split_train_dev_test('data/')\n",
    "\n",
    "# news only (temporarily)\n",
    "#test = [filename for filename in test if 'news' in filename]\n",
    "cache = []\n",
    "thrown_error = []\n",
    "\n",
    "test.sort()\n",
    "for file in tqdm(dev):\n",
    "    file = file.replace('.edus', '')\n",
    "    for name in ['news1', 'news2', 'blogs']:\n",
    "        if name in file:\n",
    "            text = open(f'corpus/RuRsTreebank_full/{name}/{file.replace(\"data/\", name+\"_txt/\")}.txt', 'r').read().strip()\n",
    "    if 'sci.ling' in file:\n",
    "        text = open(f'corpus/RuRsTreebank_full/sci_ling/sci_ling_txt/{file.replace(\"data/\", \"\")}.txt', 'r').read().strip()\n",
    "    elif 'sci.comp' in file:\n",
    "        text = open(f'corpus/RuRsTreebank_full/sci_comp/sci_comp_txt/{file.replace(\"data/\", \"\")}.txt', 'r').read().strip()\n",
    "\n",
    "    result = ppl(text)\n",
    "    out_file = file.split('/')[-1]\n",
    "    pickle.dump(result, open(f'parsing_results_0.35/{out_file}.pkl', 'wb'))\n",
    "\n",
    "    gold_edus = read_edus(file)\n",
    "    gold_pairs = prepare_gold_pairs(read_gold(file, features=True))\n",
    "\n",
    "    evaluation = eval_pipeline(result['rst'], gold_edus, gold_pairs, result['text'])\n",
    "    evaluation['filename'] = file\n",
    "    cache.append(evaluation)\n",
    "\n",
    "    #pipeline_evaluation[file] = eval_pipeline(result['rst'], gold_edus, gold_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "from utils.train_test_split import split_train_dev_test\n",
    "from utils.file_reading import read_edus, read_gold\n",
    "from utils.evaluation import *\n",
    "import pickle\n",
    "\n",
    "pipeline_evaluation = {}\n",
    "train, dev, test = split_train_dev_test('data/')\n",
    "\n",
    "cache = []\n",
    "thrown_error = []\n",
    "\n",
    "for file in tqdm('parsing_results_0.35/*.pkl'):\n",
    "    #file = file.replace('.edus', '')\n",
    "    for name in ['news1', 'news2', 'blogs']:\n",
    "        if name in file:\n",
    "            text = open(f'corpus/RuRsTreebank_full/{name}/{file.replace(\"data/\", name+\"_txt/\")}.txt', 'r').read().strip()\n",
    "    if 'sci.ling' in file:\n",
    "        text = open(f'corpus/RuRsTreebank_full/sci_ling/sci_ling_txt/{file.replace(\"data/\", \"\")}.txt', 'r').read().strip()\n",
    "    elif 'sci.comp' in file:\n",
    "        text = open(f'corpus/RuRsTreebank_full/sci_comp/sci_comp_txt/{file.replace(\"data/\", \"\")}.txt', 'r').read().strip()\n",
    "\n",
    "    try:\n",
    "        result = pickle.load(open(file, 'rb'))\n",
    "        file = file.replace('.edus', '')\n",
    "\n",
    "        gold_edus = read_edus(file)\n",
    "        gold_pairs = prepare_gold_pairs(read_gold(file, features=True))\n",
    "\n",
    "        evaluation = eval_pipeline(result['rst'], gold_edus, gold_pairs, result['text'])\n",
    "        evaluation['filename'] = file\n",
    "        cache.append(evaluation)\n",
    "    except:\n",
    "        thrown_error.append(file)\n",
    "    #pipeline_evaluation[file] = eval_pipeline(result['rst'], gold_edus, gold_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.export_to_rs3 import ForestExporter\n",
    "\n",
    "ex = ForestExporter()\n",
    "ex(result['rst'], 'blogs_26_pred.rs3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(cache)\n",
    "tmp['pr_seg'] = tmp.seg_true_pred / tmp.seg_all_pred\n",
    "tmp['re_seg'] = tmp.seg_true_pred / tmp.seg_all_true\n",
    "tmp['f1_seg'] = 2 * tmp.pr_seg * tmp.re_seg / (tmp.pr_seg + tmp.re_seg)\n",
    "tmp['pr_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_pred\n",
    "tmp['re_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_true\n",
    "tmp['f1_unlab'] = 2 * tmp.pr_unlab * tmp.re_unlab / (tmp.pr_unlab + tmp.re_unlab)\n",
    "tmp['pr_lab'] = tmp.lab_true_pred / tmp.lab_all_pred\n",
    "tmp['re_lab'] = tmp.lab_true_pred / tmp.lab_all_true\n",
    "tmp['f1_lab'] = 2 * tmp.pr_lab * tmp.re_lab / (tmp.pr_lab + tmp.re_lab)\n",
    "tmp['pr_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_pred\n",
    "tmp['re_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_true\n",
    "tmp['f1_nuc'] = 2 * tmp.pr_nuc * tmp.re_nuc / (tmp.pr_nuc + tmp.re_nuc)\n",
    "tmp.sort_values('f1_seg', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp.seg_all_true.sum(), tmp.seg_all_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp.lab_all_true.sum(), tmp.lab_all_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp2[tmp2.filename.str.contains('blogs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_score = {\n",
    "    'pr_seg': tmp.seg_true_pred.sum() / tmp.seg_all_pred.sum(),\n",
    "    're_seg': tmp.seg_true_pred.sum() / tmp.seg_all_true.sum(),\n",
    "    'pr_unlab': tmp.unlab_true_pred.sum() / tmp.unlab_all_pred.sum(),\n",
    "    're_unlab': tmp.unlab_true_pred.sum() / tmp.unlab_all_true.sum(),\n",
    "    'pr_lab': tmp.lab_true_pred.sum() / tmp.lab_all_pred.sum(),\n",
    "    're_lab': tmp.lab_true_pred.sum() / tmp.lab_all_true.sum(),\n",
    "    'pr_nuc': tmp.nuc_true_pred.sum() / tmp.nuc_all_pred.sum(),\n",
    "    're_nuc': tmp.nuc_true_pred.sum() / tmp.nuc_all_true.sum(),\n",
    "    'pr_full': tmp.full_true_pred.sum() / tmp.full_all_pred.sum(),\n",
    "    're_full': tmp.full_true_pred.sum() / tmp.full_all_true.sum(),  \n",
    "}\n",
    "\n",
    "def get_overall_score(step: str):\n",
    "    return 2. * overall_score['pr_' + step] * overall_score['re_' + step] / (\n",
    "    overall_score['pr_' + step] + overall_score['re_' + step])\n",
    "\n",
    "for step in ('seg', 'unlab', 'nuc', 'lab', 'full'):\n",
    "    overall_score['f1_' + step] = get_overall_score(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_table = pd.DataFrame(columns=['component', 'P', 'R', 'F1'], data=[\n",
    "    ['segmentation', overall_score['pr_seg'], overall_score['re_seg'], overall_score['f1_seg']],\n",
    "    ['span', overall_score['pr_unlab'], overall_score['re_unlab'], overall_score['f1_unlab']],\n",
    "    ['nuclearity', overall_score['pr_nuc'], overall_score['re_nuc'], overall_score['f1_nuc']],\n",
    "    ['relation', overall_score['pr_lab'], overall_score['re_lab'], overall_score['f1_lab']],\n",
    "    ['full', overall_score['pr_full'], overall_score['re_full'], overall_score['f1_full']],\n",
    "])\n",
    "\n",
    "evaluation_table['P'] *= 100\n",
    "evaluation_table['R'] *= 100\n",
    "evaluation_table['F1'] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation_table.to_latex(index=False, float_format='%.2f', column_format='|l|l|l|l|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = {\n",
    "    'predicted': [\"<Осталось только копченый сыр порезать.> <В суп, ага.> <IMG>\", \"<Кот дик и неподкупен,>\"],\n",
    "    'gold': [\"<Осталось только копченый сыр порезать. В суп, ага.\\texttt{\\textbackslash{n}}IMG>\", \"<Кот дик> <и неподкупен,>\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(qa).to_latex(index=None, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(cache)\n",
    "tmp['pr_seg'] = tmp.seg_true_pred / tmp.seg_all_pred\n",
    "tmp['re_seg'] = tmp.seg_true_pred / tmp.seg_all_true\n",
    "tmp['f1_seg'] = 2 * tmp.pr_seg * tmp.re_seg / (tmp.pr_seg + tmp.re_seg)\n",
    "tmp['pr_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_pred\n",
    "tmp['re_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_true\n",
    "tmp['f1_unlab'] = 2 * tmp.pr_unlab * tmp.re_unlab / (tmp.pr_unlab + tmp.re_unlab)\n",
    "tmp['pr_lab'] = tmp.lab_true_pred / tmp.lab_all_pred\n",
    "tmp['re_lab'] = tmp.lab_true_pred / tmp.lab_all_true\n",
    "tmp['f1_lab'] = 2 * tmp.pr_lab * tmp.re_lab / (tmp.pr_lab + tmp.re_lab)\n",
    "tmp['pr_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_pred\n",
    "tmp['re_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_true\n",
    "tmp['f1_nuc'] = 2 * tmp.pr_nuc * tmp.re_nuc / (tmp.pr_nuc + tmp.re_nuc)\n",
    "tmp.sort_values('f1_unlab', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp.lab_all_true.sum(), tmp.lab_all_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_score = {\n",
    "    'pr_seg': tmp.seg_true_pred.sum() / tmp.seg_all_pred.sum(),\n",
    "    're_seg': tmp.seg_true_pred.sum() / tmp.seg_all_true.sum(),\n",
    "    'pr_unlab': tmp.unlab_true_pred.sum() / tmp.unlab_all_pred.sum(),\n",
    "    're_unlab': tmp.unlab_true_pred.sum() / tmp.unlab_all_true.sum(),\n",
    "    'pr_lab': tmp.lab_true_pred.sum() / tmp.lab_all_pred.sum(),\n",
    "    're_lab': tmp.lab_true_pred.sum() / tmp.lab_all_true.sum(),\n",
    "    'pr_nuc': tmp.nuc_true_pred.sum() / tmp.nuc_all_pred.sum(),\n",
    "    're_nuc': tmp.nuc_true_pred.sum() / tmp.nuc_all_true.sum(),\n",
    "}\n",
    "\n",
    "overall_score['f1_seg'] = 2. * overall_score['pr_seg'] * overall_score['re_seg'] / (\n",
    "    overall_score['pr_seg'] + overall_score['re_seg'])\n",
    "overall_score['f1_unlab'] = 2. * overall_score['pr_unlab'] * overall_score['re_unlab'] / (\n",
    "    overall_score['pr_unlab'] + overall_score['re_unlab'])\n",
    "overall_score['f1_lab'] = 2. * overall_score['pr_lab'] * overall_score['re_lab'] / (\n",
    "    overall_score['pr_lab'] + overall_score['re_lab'])\n",
    "overall_score['f1_nuc'] = 2. * overall_score['pr_nuc'] * overall_score['re_nuc'] / (\n",
    "    overall_score['pr_nuc'] + overall_score['re_nuc'])\n",
    "\n",
    "overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_table = pd.DataFrame(columns=['component', 'P', 'R', 'F1'], data=[\n",
    "    ['segmentation', overall_score['pr_seg'], overall_score['re_seg'], overall_score['f1_seg']],\n",
    "    ['span', overall_score['pr_unlab'], overall_score['re_unlab'], overall_score['f1_unlab']],\n",
    "    ['nuclearity', overall_score['pr_nuc'], overall_score['re_nuc'], overall_score['f1_nuc']],\n",
    "    ['relation', overall_score['pr_lab'], overall_score['re_lab'], overall_score['f1_lab']],\n",
    "])\n",
    "\n",
    "evaluation_table['P'] *= 100\n",
    "evaluation_table['R'] *= 100\n",
    "evaluation_table['F1'] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation_table.to_latex(index=False, float_format='%.2f', column_format='|l|l|l|l|'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
