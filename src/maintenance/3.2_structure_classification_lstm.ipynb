{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary structure classification used in tree building\n",
    "\n",
    "1. Create train and test sets; Save negative samples of file ``filename.rs3`` as `filename.neg`\n",
    "2. Train models, save the best one.\n",
    "\n",
    "Output:\n",
    " - ``data/*.neg``\n",
    " - ``models/structure_predictor/*``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utils.file_reading import read_edus, read_gold, read_negative, read_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models/structure_predictor_lstm’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'models/structure_predictor_lstm'\n",
    "! mkdir $MODEL_PATH\n",
    "\n",
    "TRAIN_FILE_PATH = os.path.join(MODEL_PATH, 'structure_cf_train.tsv')\n",
    "TEST_FILE_PATH = os.path.join(MODEL_PATH, 'structure_cf_test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate train/test files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news in train: 0.3886792452830189,\tin test: 0.3939393939393939\n",
      "ling in train: 0.1509433962264151,\tin test: 0.15151515151515152\n",
      "comp in train: 0.1471698113207547,\tin test: 0.15151515151515152\n",
      "blog in train: 0.3132075471698113,\tin test: 0.3181818181818182\n"
     ]
    }
   ],
   "source": [
    "from utils.train_test_split import split_data\n",
    "\n",
    "train, test = split_data('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2caf2917e31a4b5b8faa4215cbf641fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=265), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "random_state = 45\n",
    "train_samples = []\n",
    "\n",
    "for file in tqdm(train):\n",
    "    gold = read_gold(file.replace('.edus', ''), features=True)\n",
    "    gold['relation'] = 1\n",
    "    gold['len_x'] = gold.tokens_x.map(len)\n",
    "    gold = gold[gold.len_x < MAX_LEN]\n",
    "    gold['len_y'] = gold.tokens_y.map(len)\n",
    "    gold = gold[gold.len_y < MAX_LEN]\n",
    "    gold['snippet_x'] = gold.tokens_x.map(lambda row: ' '.join(row))\n",
    "    gold['snippet_y'] = gold.tokens_y.map(lambda row: ' '.join(row))\n",
    "    sample = gold[['relation', 'snippet_x', 'snippet_y']]\n",
    "    negative = read_negative(file.replace('.edus', ''), features=True)\n",
    "    negative['relation'] = 0\n",
    "    negative['len_x'] = negative.tokens_x.map(len)\n",
    "    negative = negative[negative.len_x < MAX_LEN]\n",
    "    negative['len_y'] = negative.tokens_y.map(len)\n",
    "    negative = negative[negative.len_y < MAX_LEN]\n",
    "    negative['snippet_x'] = negative.tokens_x.map(lambda row: ' '.join(row))\n",
    "    negative['snippet_y'] = negative.tokens_y.map(lambda row: ' '.join(row))\n",
    "    sample = pd.concat([sample, negative[['relation', 'snippet_x', 'snippet_y']]])\n",
    "    sample = sample.sort_values(['relation'], ascending=True).drop_duplicates(['snippet_x', 'snippet_y'], keep='last')    \n",
    "    train_samples.append(sample)\n",
    "\n",
    "train_samples = pd.concat(train_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "train_samples.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    66420\n",
       "1    25728\n",
       "Name: relation, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples.relation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>snippet_x</th>\n",
       "      <th>snippet_y</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>основанного прежде всего на логических операци...</td>\n",
       "      <td>Во - вторых , сомневаться в истинности языка н...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Восстанавливаемыми называют объекты , допускаю...</td>\n",
       "      <td>Невосстанавливаемые же в процессе выполнения с...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Что может - отложить и подвигать окно качества .</td>\n",
       "      <td>В рамках этой модели первое что должен сделать...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>нередко отличается безжалостностью ,</td>\n",
       "      <td>так как в его ментальном состоянии происходит ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Между тем , представляется , что среди концепт...</td>\n",
       "      <td>С этой точки зрения интересно решение , найден...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relation                                          snippet_x  \\\n",
       "0         0  основанного прежде всего на логических операци...   \n",
       "1         1  Восстанавливаемыми называют объекты , допускаю...   \n",
       "2         0   Что может - отложить и подвигать окно качества .   \n",
       "3         0               нередко отличается безжалостностью ,   \n",
       "4         0  Между тем , представляется , что среди концепт...   \n",
       "\n",
       "                                           snippet_y  index  \n",
       "0  Во - вторых , сомневаться в истинности языка н...      0  \n",
       "1  Невосстанавливаемые же в процессе выполнения с...      1  \n",
       "2  В рамках этой модели первое что должен сделать...      2  \n",
       "3  так как в его ментальном состоянии происходит ...      3  \n",
       "4  С этой точки зрения интересно решение , найден...      4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TRAIN_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32a6743bbf148a1b28a37d5417b5e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=67), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random_state = 45\n",
    "test_samples = []\n",
    "\n",
    "for file in tqdm(test):\n",
    "    gold = read_gold(file.replace('.edus', ''), features=True)\n",
    "    gold['relation'] = 1\n",
    "    gold['len_x'] = gold.tokens_x.map(len)\n",
    "    gold = gold[gold.len_x < MAX_LEN]\n",
    "    gold['len_y'] = gold.tokens_y.map(len)\n",
    "    gold = gold[gold.len_y < MAX_LEN]\n",
    "    gold['snippet_x'] = gold.tokens_x.map(lambda row: ' '.join(row))\n",
    "    gold['snippet_y'] = gold.tokens_y.map(lambda row: ' '.join(row))\n",
    "    sample = gold[['relation', 'snippet_x', 'snippet_y']]\n",
    "    negative = read_negative(file.replace('.edus', ''), features=True)\n",
    "    negative['relation'] = 0\n",
    "    negative['len_x'] = negative.tokens_x.map(len)\n",
    "    negative = negative[negative.len_x < MAX_LEN]\n",
    "    negative['len_y'] = negative.tokens_y.map(len)\n",
    "    negative = negative[negative.len_y < MAX_LEN]\n",
    "    negative['snippet_x'] = negative.tokens_x.map(lambda row: ' '.join(row))\n",
    "    negative['snippet_y'] = negative.tokens_y.map(lambda row: ' '.join(row))\n",
    "    sample = pd.concat([sample, negative[['relation', 'snippet_x', 'snippet_y']]])\n",
    "    sample = sample.sort_values(['relation'], ascending=True).drop_duplicates(['snippet_x', 'snippet_y'], keep='last') \n",
    "    test_samples.append(sample)\n",
    "\n",
    "test_samples = pd.concat(test_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "test_samples.reset_index(level=0, inplace=True)\n",
    "test_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TEST_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/structure_predictor_lstm/config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $MODEL_PATH/config.json\n",
    "\n",
    "// Configuration for a sentence matching model based on:\n",
    "//   Wang, Zhiguo, Wael Hamza, and Radu Florian. \"Bilateral multi-perspective matching for natural language sentences.\"\n",
    "//   Proceedings of the 26th International Joint Conference on Artificial Intelligence. 2017.\n",
    "\n",
    "{\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": \"quora_paraphrase\",\n",
    "    \"lazy\": false,\n",
    "    \"token_indexers\": {\n",
    "      \"bert\": {\n",
    "          \"type\": \"bert-pretrained\",\n",
    "          \"pretrained_model\": \"rubert_cased_L-12_H-768_A-12_pt\",\n",
    "          \"do_lowercase\": false,\n",
    "          \"use_starting_offsets\": true\n",
    "      },\n",
    "      \"token_characters\": {\n",
    "        \"type\": \"characters\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"train_data_path\": \"structure_predictor_lstm/structure_cf_train.tsv\",\n",
    "  \"validation_data_path\": \"structure_predictor_lstm/structure_cf_test.tsv\",\n",
    "  \"model\": {\n",
    "    \"type\": \"bimpm\",\n",
    "    \"dropout\": 0.1,\n",
    "    \"text_field_embedder\": {\n",
    "        \"allow_unmatched_keys\": true,\n",
    "        \"embedder_to_indexer_map\": {\n",
    "            \"bert\": [\"bert\", \"bert-offsets\"],\n",
    "            \"token_characters\": [\"token_characters\"],\n",
    "        },\n",
    "        \"token_embedders\": {\n",
    "            \"bert\": {\n",
    "                \"type\": \"bert-pretrained\",\n",
    "                \"pretrained_model\": \"rubert_cased_L-12_H-768_A-12_pt\",\n",
    "            },\n",
    "            \"token_characters\": {\n",
    "                \"type\": \"character_encoding\",\n",
    "                \"embedding\": {\n",
    "                    \"embedding_dim\": 20,\n",
    "                    \"padding_index\": 0\n",
    "                },\n",
    "                \"encoder\": {\n",
    "                    \"type\": \"gru\",\n",
    "                    \"input_size\": 20,\n",
    "                    \"hidden_size\": 50,\n",
    "                    \"num_layers\": 1,\n",
    "                    \"bidirectional\": true\n",
    "              }\n",
    "            }\n",
    "      }\n",
    "    },\n",
    "    \"matcher_word\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 768+100,\n",
    "      \"num_perspectives\": 10,\n",
    "      \"with_full_match\": false\n",
    "    },\n",
    "    \"encoder1\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 768+100,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward1\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward1\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"encoder2\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 400,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward2\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward2\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"aggregator\":{\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 264,\n",
    "      \"hidden_size\": 100,\n",
    "      \"num_layers\": 2,\n",
    "      \"dropout\": 0.1\n",
    "    },\n",
    "    \"classifier_feedforward\": {\n",
    "      \"input_dim\": 400,\n",
    "      \"num_layers\": 2,\n",
    "      \"hidden_dims\": [200, 2],\n",
    "      \"activations\": [\"relu\", \"linear\"],\n",
    "      \"dropout\": [0.1, 0.0]\n",
    "    },\n",
    "    \"initializer\": [\n",
    "      [\".*linear_layers.*weight\", {\"type\": \"xavier_normal\"}],\n",
    "      [\".*linear_layers.*bias\", {\"type\": \"constant\", \"val\": 0}],\n",
    "      [\".*weight_ih.*\", {\"type\": \"xavier_normal\"}],\n",
    "      [\".*weight_hh.*\", {\"type\": \"orthogonal\"}],\n",
    "      [\".*bias.*\", {\"type\": \"constant\", \"val\": 0}],\n",
    "      [\".*matcher.*match_weights.*\", {\"type\": \"kaiming_normal\"}]\n",
    "    ]\n",
    "  },\n",
    "  \"iterator\": {\n",
    "    \"type\": \"basic\",\n",
    "    \"batch_size\": 8\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": 40,\n",
    "    \"patience\": 5,\n",
    "    \"cuda_device\": 0,\n",
    "    \"grad_clipping\": 5.0,\n",
    "    \"validation_metric\": \"+accuracy\",\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"bert_adam\",\n",
    "      \"lr\": 0.001\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
