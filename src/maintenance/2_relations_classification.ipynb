{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-9VVVLqWnV5"
   },
   "source": [
    "## Rhetorical relations classification\n",
    "\n",
    "1. Data cleaning: obtain the data and clean it (X, y)\n",
    " - transformations: normalization, scaling\n",
    "2. Classifiers & CV-training for relations classification (cause/background/attribution/etc.)\n",
    "4. Save the best classifier to ``models/label_predictor/model.pkl``\n",
    "3. Feature selection\n",
    " - Find features with single unique value\n",
    " - Find collinear features\n",
    "4. Classifiers & CV-training for nuclearity classification (NN/NS/SN)\n",
    "\n",
    "Output:\n",
    " - ``models/label_predictor/*``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! pip install -U pandas==0.24.1\n",
    "! pip install -Uq pip catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import rcParams\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from catboost import CatBoostClassifier\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['font.sans-serif'] = 'Arial'\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-mEy6IbWs7K"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "df = []\n",
    "for filename in glob.glob(\"data/*.gold.pkl\"):\n",
    "    tmp = pd.read_pickle(filename)   \n",
    "    df.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df)\n",
    "df = df.fillna(0.)\n",
    "constants = [c for c in df.columns if len(set(df[c])) == 1]\n",
    "to_drop = ['snippet_x', 'snippet_y', 'snippet_x_tmp', 'snippet_y_tmp', 'filename', 'order', 'postags_x', 'postags_y']\n",
    "df = df.drop(columns=constants)\n",
    "pickle.dump(constants+to_drop, open('models/label_predictor/drop_columns.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ZLNUgdjWnV9"
   },
   "source": [
    "### 1. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7ocFlmXWnWD"
   },
   "outputs": [],
   "source": [
    "TARGET = 'category_id'\n",
    "\n",
    "df[TARGET] = df[TARGET].replace(['cause-effect_r', 'effect_r'], 'cause_r')\n",
    "df[TARGET] = df[TARGET].replace(['interpretation-evaluation_r', 'conclusion_r'], 'evaluation_r')\n",
    "\n",
    "y_stat = df[TARGET].value_counts()\n",
    "drop_ys = y_stat[y_stat < 500].index\n",
    "\n",
    "for dy in drop_ys:\n",
    "    df = df[df[TARGET] != dy]\n",
    "    \n",
    "for dy in ['elaboration_r', 'joint_m', 'same-unit_m']:\n",
    "    df = df[df[TARGET] != dy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[TARGET].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_type_list = df[TARGET].unique()\n",
    "unique_type_list = ['attribution_r', 'purpose_r', 'contrast_m', 'preparation_r', 'sequence_m', 'condition_r', 'cause_r', 'evaluation_r', 'comparison_m', 'evidence_r', 'background_r']\n",
    "y, X = df[TARGET].to_frame(), df.drop(TARGET, axis=1).drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_mask = X.dtypes==object\n",
    "categorical_cols = X.columns[categorical_feature_mask].tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "lab_encoder = LabelEncoder().fit(unique_type_list)\n",
    "y = lab_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "class MyLabelEncoder(LabelEncoder):\n",
    "\n",
    "    def fit(self, y):\n",
    "        y = column_or_1d(y, warn=True)\n",
    "        self.classes_ = pd.Series(y)\n",
    "        return self\n",
    "    \n",
    "lab_encoder = MyLabelEncoder().fit(unique_type_list)\n",
    "y = lab_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X[categorical_cols] = X[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_ohe = ohe.fit_transform(X[categorical_cols].values)\n",
    "\n",
    "#X_ohe = pd.DataFrame(X_ohe, X.index, columns=ohe.get_feature_names(categorical_cols))\n",
    "X_ohe = ohe.fit_transform(X[categorical_cols].values)\n",
    "X = X.join(\n",
    "   pd.DataFrame(X_ohe, X.index).add_prefix('cat_'), how='right'\n",
    ").drop(columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "n0c6ZierWnWO",
    "outputId": "0dd4dc4e-07a8-4ab8-b2a9-bd79dc18879b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X.values)\n",
    "\n",
    "X_scaled_np = scaler.transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled_np, index=X.index, columns=X.columns)\n",
    "\n",
    "X = X_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zz2VY2YNDHSh"
   },
   "source": [
    "### 2. Make different feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mM4SWsHFDHSi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# locational = [feat for feat in list(X.keys()) if '_pair_' in feat]\n",
    "# quantitative = [feat for feat in list(X.keys()) if '_count_' in feat]\n",
    "\n",
    "# X_quant = X.drop(columns=locational)  # quantitative only \n",
    "# X_positional = X.drop(columns=quantitative)  # positional only\n",
    "\n",
    "# lexical = ['tf_idf_y_167', 'tf_idf_y_114', 'tf_idf_y_97', 'tf_idf_y_46', 'tf_idf_x_291', 'tf_idf_x_261', 'tf_idf_x_118', 'tf_idf_x_97']\n",
    "# morphosynt = ['last_X_X_y', 'first_X_X_y', 'last_X_NOUN_y', 'first_X_NOUN_y', 'first_X_y', 'first_VERB_X_y', 'first_VERB_PRON_y', 'last_VERB_NOUN_y', 'first_VERB_NOUN_y', 'first_VERB_ADV_y', 'last_VERB_ADP_y', 'first_VERB_ADP_y', 'first_VERB_ADJ_y', 'first_PRON_X_y', 'last_PRON_PRON_y', 'first_PRON_PRON_y', 'last_PRON_NOUN_y', 'first_PRON_NOUN_y', 'first_PART_X_y', 'last_PART_VERB_y', 'first_PART_VERB_y', 'first_NUM_NOUN_y', 'last_VERB_PRON_x', 'first_VERB_X_x', 'last_VERB_ADV_x', 'first_VERB_NOUN_x', 'last_VERB_NOUN_x', 'first_X_NOUN_x', 'last_X_NOUN_x', 'first_X_X_x', 'first_NOUN_VERB_x', 'last_NOUN_VERB_x', 'first_NOUN_X_x', 'last_NOUN_X_x', 'last_NUM_NOUN_x', 'first_PART_VERB_x', 'last_PART_VERB_x', 'first_NUM_NOUN_x', 'last_NOUN_PART_x', 'last_NOUN_NOUN_x', 'first_NOUN_PART_x', 'first_PART_X_x', 'first_PRON_X_x', 'last_PRON_X_x', 'first_VERB_ADJ_x', 'last_VERB_ADJ_x', 'first_VERB_ADP_x', 'last_VERB_ADP_x', 'last_PRON_PRON_x', 'first_PRON_NOUN_x', 'last_PRON_NOUN_x', 'first_PRON_PRON_x', 'last_NOUN_ADV_x', 'last_NUM_NOUN_y', 'first_ADP_ADJ_x', 'last_ADJ_X_x', 'last_ADJ_NOUN_x', 'fPOS_CONJ_y', 'fPOS_ADV_y', 'last_ADV_ADV_x', 'last_ADP_NOUN_x', 'first_ADP_NOUN_x', 'last_ADP_ADJ_x', 'fPOS_ADJ_y', 'first_ADJ_NOUN_y', 'first_ADJ_X_y', 'first_ADP_ADJ_y', 'last_ADP_ADJ_y', 'first_ADP_NOUN_y', 'last_ADP_NOUN_y', 'first_ADV_NOUN_y', 'Case_Ins_x', 'first_ADV_VERB_y', 'first_ADV_X_y', 'last_ADV_X_y', 'first_CONJ_NOUN_y', 'first_CONJ_X_y', 'first_NOUN_ADJ_y', 'last_NOUN_ADJ_y', 'first_NOUN_ADV_y', 'last_NOUN_NOUN_y', 'first_NOUN_VERB_y', 'first_NOUN_X_y', 'last_NOUN_X_y', 'first_ADV_ADV_y', 'Voice_Pass_y', 'VerbForm_Inf_y', 'VerbForm_Ger_y', 'fPOS_PRON_x', 'fPOS_ADV_x', 'Comparision_Sup_y', 'last_CONJ_X_x', 'last_ADV_X_x', 'first_CONJ_NOUN_x', 'first_ADV_X_x', 'first_CONJ_X_x', 'first_NOUN_ADV_x', 'last_NOUN_ADJ_x', 'last_CONJ_NOUN_x', 'first_NOUN_ADJ_x', 'last_PART_X_x', 'last_CONJ_ADV_y', 'last_ADJ_X_y', 'last_ADV_ADV_y', 'last_VERB_X_x', 'last_NOUN_ADV_y', 'first_CONJ_ADV_y', 'last_X_X_x', 'last_VERB_ADV_y', 'last_VERB_PRON_y', 'last_NOUN_PART_y', 'first_ADV_VERB_x', 'fPOS_VERB_y', 'last_ADJ_NOUN_y', 'first_ADV_ADV_x', 'fPOS_ADP_y', 'first_VERB_ADV_x', 'first_NOUN_NOUN_y', 'morph_correlation']\n",
    "# textual = ['\\\\bтам_count_X', '\\\\bв\\\\b_count_X', '\\\\bеще_count_X', 'полагаем_count_X', '\\\\bпока\\\\b_count_X', 'поз(?:дн|же)_count_X', 'позволяющ_count_X', 'позволя_count_X', 'подход_count_X', 'последн_count_X', 'подразумевает_count_X', '\\\\bпод\\\\b_count_X', '\\\\bпо\\\\b_count_X', 'переда_count_X', 'перед_count_X', 'первоначально_count_X', 'ошибкой_count_X', 'очередь_count_X', 'получаем_count_X', 'поможет_count_X', 'порожда_count_X', 'при условии_count_X', 'прежде_count_X', 'проявля_count_X', 'предъяв_count_X', 'представ_count_X', 'предназначен_count_X', 'пределами_count_X', 'правда_count_X', 'похож(?:ий|ая|ие|ее)_count_X', 'послужи_count_X', 'порожд_count_X', 'отчасти_count_X', 'обстоятельств_count_X', 'образцы_count_X', 'обнаружил_count_X', 'обнаружи_count_X', 'обеспечивающ_count_X', 'обеспечива_count_X', 'обвини_count_X', '\\\\bоб?\\\\b_count_X', '\\\\bно и\\\\b_count_X', '\\\\bних\\\\b_count_X', 'неясн_count_X', 'несомненн_count_X', 'несмотря_count_X', 'неразумн_count_X', 'необходим_count_X', 'обусловл_count_X', 'объясн_count_X', 'обязательн_count_X', 'отреагирова_count_X', 'отправной_count_X', 'отмеч_count_X', 'отмети_count_X', 'отместку_count_X', 'отличи_count_X', '\\\\bот\\\\b_count_X', 'приводи_count_X', 'особ_count_X', 'определ_count_X', 'оправдыва_count_X', 'опасаться_count_X', 'одним_count_X', '(?:один|одна|одно|одни)_count_X', 'особенн_count_X', 'призна_count_X', '\\\\bстать\\\\b_count_X', '\\\\bстав\\\\b_count_X', 'состоять_count_X', 'составе_count_X', 'сопровождении_count_X', 'сомневаться_count_X', 'совместно_count_X', 'случа_count_X', 'слову_count_X', '\\\\bисходя\\\\b_count_X', 'слишком_count_X', 'следующим_count_X', 'степени_count_X', '\\\\bтон\\\\b_count_X', '\\\\bтому\\\\b_count_X', 'только_count_X', 'толчком_count_X', 'теперь_count_X', '\\\\bтак(?:ие|им|их|ов|ой|ая|ое)\\\\b_count_X', '\\\\bтакже\\\\b_count_X', 'считать,_count_X', 'считать_count_X', 'счету_count_X', '\\\\bсути\\\\b_count_X', '\\\\bсудя\\\\b_count_X', 'тогда_count_X', 'немедленн_count_X', '\\\\bследу_count_X', '\\\\bследстви_count_X', 'район_count_X', 'разумеется_count_X', 'разделя_count_X', 'разве_count_X', 'равно_count_X', 'пути_count_X', 'пусть_count_X', 'противоположн_count_X', 'против_count_X', 'просто_count_X', 'проблемы_count_X', 'причем_count_X', 'приходится_count_X', 'пример_count_X', 'применительно_count_X', 'ранее_count_X', 'скорее_count_X', 'сказаться_count_X', 'сказать,_count_X', 'связан_count_X', 'сведениям_count_X', '\\\\bс тем\\\\b_count_X', 'ряде_count_X', 'роль_count_X', 'речь_count_X', 'рассказ(?:а|ыва)_count_X', '\\\\bсам[ое]_count_X', 'вместо_count_X', 'включи_count_X', '\\\\bвидно\\\\b_count_X', '\\\\bвидимо\\\\b_count_X', '\\\\bвид.?\\\\b_count_X', 'ввиду_count_X', '\\\\bважн_count_X', '\\\\bв чем\\\\b_count_X', '\\\\bв целом_count_X', '\\\\bбыл\\\\b_count_X', '\\\\bбы\\\\b_count_X', 'будь_count_X', 'будучи_count_X', 'больш[оаи]_count_X', 'гарантирова_count_X', 'вышесказан_count_X', 'высказ(ыв)?ать_count_X', 'вывод[ау]_count_X', '\\\\bвывод\\\\b_count_X', 'выби?ра_count_X', '\\\\bвтор_count_X', 'всяком_count_X', 'вследствие_count_X', '\\\\bвслед\\\\b_count_X', 'вскоре_count_X', 'всего_count_X', 'вряд(?: ли)_count_X', '\\\\bвот\\\\b_count_X', 'возникающ_count_X', 'возможность_count_X', 'бесспорно_count_X', '\\\\(_count_X', '\\\\bэто_count_X', '\\\\bтом\\\\b_count_X', '\\\\bтем\\\\b_count_X', '\\\\bте_count_X', '\\\\bта_count_X', '\\\\bсо\\\\b_count_X', '\\\\bситуаци_count_X', '\\\\bсамым\\\\b_count_X', '\\\\bс\\\\b_count_X', '\\\\bрода\\\\b_count_X', '\\\\bнего_count_X', '\\\\bза\\\\b_count_X', '\\\\bже\\\\b_count_X', '\\\\(.+\\\\)_count_X', '\\\\)_count_X', '\\\\bаналогичн_count_X', '\\\\bанализ\\\\b_count_X', '\\\\bа\\\\b_count_X', '\\\\bзаканчива_count_X', '^[-—]_count_X', '\\\\bгде\\\\b_count_X', '«_count_X', '\\\\[_count_X', '\\\\?_count_X', ':_count_X', '\\\\\\\\-_count_X', ',$_count_X', 'где [a-zа-я ]+ [—-]_count_X', '\\\\bговори.?\\\\b_count_X', '\\\\bмере\\\\b_count_X', 'между_count_X', 'маловероятн_count_X', '\\\\bлица\\\\b_count_X', 'линии_count_X', 'кроме э?того_count_X', 'котор_count_X', 'концов_count_X', 'комментари_count_X', '\\\\bко(?:й|ю|я|ем)\\\\b_count_X', 'когда_count_X', '\\\\bко?\\\\b_count_X', 'как(?:ая|ой|ое|ие)_count_X', '\\\\bих\\\\b_count_X', 'месте_count_X', 'мире_count_X', '\\\\bне только_count_X', 'настаива_count_X', 'например_count_X', 'напомни_count_X', 'написа_count_X', 'намека_count_X', 'надеяться_count_X', '\\\\bна\\\\b_count_X', 'мотиваци(?:я|ей)_count_X', 'момента_count_X', 'можно_count_X', 'может_count_X', '\\\\bмог_count_X', 'неизменно_count_X', 'иными?_count_X', 'доказыв_count_X', 'довольно_count_X', 'добавля_count_X', 'добави_count_X', '\\\\bдо\\\\b_count_X', 'для\\\\b_count_X', 'делят_count_X', 'делать_count_X', '\\\\bдела.т\\\\b_count_X', '\\\\bдела_count_X', 'действительно_count_X', 'дальше_count_X', '\\\\bдал\\\\b_count_X', '\\\\bдавать\\\\b_count_X', '\\\\bдава_count_X', 'грани_count_X', 'говорят?_count_X', 'допустим_count_X', '\\\\bему\\\\b_count_X', 'есть_count_X', 'информаци_count_X', 'интерес\\\\b_count_X', 'ин[?:ое|ой|ая]_count_X', 'иногда_count_X', 'иначе_count_X', 'имени_count_X', '\\\\bили\\\\b_count_X', 'известно_count_X', 'исключением_count_X', '\\\\bиз\\\\b_count_X', 'здесь_count_X', 'затем_count_X', 'застав[ли]_count_X', 'завери_count_X', 'очевидно_count_X', '\\\\bлибо\\\\b_count_X', 'невзирая_count_X', 'нетрудн_count_X', '\\\\._count_X', 'заключа_count_X', 'соответств_count_X', 'наряду_count_X', 'сдела_count_X', 'следовательно_count_X', 'подчерк_count_X', 'результат_count_X', 'объект_count_X', 'свете_count_X', 'писа_count_X', 'сыграть_count_X', '\\\\bведь\\\\b_count_X', 'противном_count_X', 'привести_count_X', 'из-за_count_X', 'столько_count_X', 'раздел_count_X', 'некотор_count_X', '(?:то есть|т\\\\\\\\. ?е\\\\\\\\.)_count_X', 'объяви_count_X', 'сказа_count_X', 'заяв(?:и|ля)_count_X', '\\\\bодной\\\\b_count_X', '\\\\bа с\\\\b_count_X', 'поэтому_count_X', '\\\\bвключая\\\\b_count_X', 'логично_count_X', '\\\\bне[е|ё]_count_X', 'получа_count_X', 'названи(?:ем|ям|ю)_count_X', 'свидетельств_count_X', 'ради_count_X', '\\\\bмомент\\\\b_count_X', 'назва_count_X', 'начн_count_X', 'включа_count_X', 'почему_count_X', 'отчего_count_X', 'причин_count_X', '\\\\?$_count_X', 'име(?:я|ем|ет|ют)_count_X', 'настоящ_count_X', 'способств_count_X', '\\\\bвидим\\\\b_count_X', '\\\\bобщ[иеу]_count_X', '\\\\bтой\\\\b_count_X', 'впрочем_count_X', 'больше_count_X', 'во многом_count_X', 'источником_count_X', 'насколько_count_X', '- ?_count_X', 'имя_count_X', 'получим_count_X', 'потребова_count_X', 'откуда_count_X', 'завис[и|я]_count_X', 'впоследствии_count_X', ',_count_X', 'преддверии_count_X', 'обозначи_count_X', 'главе_count_X', 'значит_count_X', 'потому_count_X', 'ранн(?:ий|яя|ее|ие)_count_X', 'описывать_count_X', '\\\\bисточник\\\\b_count_X', 'сообщи_count_X', 'помо[чщ]_count_X', 'отсюда_count_X', 'защиту_count_X', '=_count_X', 'предпочтительн_count_X', '\\\\bдело\\\\b_count_X', 'распоряж_count_X', 'протяжении_count_X', 'согласиться_count_X', 'невозможн_count_X', 'менее_count_X', 'вед[еу]т_count_X', '\\\\bво\\\\b_count_X', 'следует_count_X', '\\\\bибо\\\\b_count_X', '\\\\bим\\\\b_count_X', 'наглядн_count_X', '\\\\bи если_count_X', 'сообща_count_X', 'напротив_count_X', 'должны_count_X', 'процессе_count_X', 'задолго_count_X', 'значени_count_X', 'выра(?:зи|жа)ть_count_X', '\\\\bб\\\\b_count_X', 'интересн_count_X', '\\\\bв частности_count_X', 'однако_count_X', '\\\\bи\\\\b_count_X', '\\\\bбез\\\\b_count_X', 'зависимост_count_X', 'пожалуй,_count_X', 'получа_count_Y', 'позволя_count_Y', 'подчерк_count_Y', 'подтвержд_count_Y', 'подачи_count_Y', '\\\\bпод\\\\b_count_Y', '\\\\bпо\\\\b_count_Y', 'первоначально_count_Y', '\\\\bперв_count_Y', 'ошибкой_count_Y', 'очевидно_count_Y', 'приведе_count_Y', '\\\\bи при\\\\b_count_Y', 'проявля_count_Y', 'предъяв_count_Y', 'представ_count_Y', 'предпочтительн_count_Y', 'предположив_count_Y', 'предмет_count_Y', 'преддверии_count_Y', 'правах_count_Y', 'почему_count_Y', 'похож(?:ий|ая|ие|ее)_count_Y', 'потребова_count_Y', 'послужи_count_Y', 'порожда_count_Y', 'оценк_count_Y', 'отреагирова_count_Y', 'образом_count_Y', 'обнаружи_count_Y', 'обвини_count_Y', 'нужно_count_Y', '\\\\bних\\\\b_count_Y', 'ниве_count_Y', 'несмотря_count_Y', 'неразумн_count_Y', 'необходим_count_Y', 'немедленн_count_Y', 'обстоятельств_count_Y', 'отправной_count_Y', 'отместку_count_Y', 'отличи_count_Y', 'откуда_count_Y', '\\\\bот\\\\b_count_Y', 'особенн_count_Y', 'особ_count_Y', 'основ_count_Y', 'определ_count_Y', 'описывать_count_Y', 'однако_count_Y', '(?:один|одна|одно|одни)_count_Y', 'приводи_count_Y', 'применив_count_Y', 'ср\\\\._count_Y', 'состоять_count_Y', 'состоит_count_Y', 'сопровождении_count_Y', 'сообщи_count_Y', 'сомневаться_count_Y', 'согласиться_count_Y', 'смену_count_Y', 'см\\\\._count_Y', 'слову_count_Y', '\\\\bисходя\\\\b_count_Y', '\\\\bсловам\\\\b_count_Y', 'следующим_count_Y', '\\\\bстать\\\\b_count_Y', 'стоит_count_Y', 'столь_count_Y', 'шагом_count_Y', 'следующ_count_Y', '\\\\bтех\\\\b_count_Y', '\\\\bтак(?:ие|им|их|ов|ой|ая|ое)\\\\b_count_Y', '\\\\bтак\\\\b_count_Y', '\\\\bсчет\\\\b_count_Y', 'разумеется_count_Y', 'разделя_count_Y', 'ради_count_Y', 'пусть_count_Y', 'протяжении_count_Y', 'противоположн_count_Y', 'противном_count_Y', 'проблемы_count_Y', 'приходится_count_Y', 'применительно_count_Y', 'рамках_count_Y', 'ранее_count_Y', 'ранн(?:ий|яя|ее|ие)_count_Y', 'сказаться_count_Y', 'сказать,_count_Y', 'сказа_count_Y', '\\\\bсилу\\\\b_count_Y', 'связан_count_Y', 'свидетельств_count_Y', 'свете_count_Y', 'сведениям_count_Y', '\\\\bследстви_count_Y', 'ряде_count_Y', 'роль_count_Y', 'роли_count_Y', 'решение_count_Y', 'результат_count_Y', 'рассчитывая_count_Y', 'рассм[ао]тр_count_Y', 'неимением_count_Y', 'независим_count_Y', 'вместе_count_Y', 'включи_count_Y', 'включа_count_Y', '\\\\bвидимо\\\\b_count_Y', '\\\\bвид.?\\\\b_count_Y', 'вед[еу]т_count_Y', '\\\\bважн_count_Y', '\\\\bв [а-я]+[еи]_count_Y', '\\\\bбы\\\\b_count_Y', 'будучи_count_Y', 'буд[еу][мт]_count_Y', 'вместо_count_Y', '\\\\bбок_count_Y', 'во?-[а-я]+х_count_Y', 'возможность_count_Y', 'гарантирова_count_Y', 'вышесказан_count_Y', 'выполня[ею]тся_count_Y', 'вызы?ва_count_Y', '\\\\bвтор_count_Y', 'всяком_count_Y', '\\\\bвслед\\\\b_count_Y', 'вряд(?: ли)_count_Y', 'впоследствии_count_Y', '\\\\bвот\\\\b_count_Y', 'безусловно_count_Y', '\\\\bбез\\\\b_count_Y', '\"_count_Y', '(?:то есть|т\\\\\\\\. ?е\\\\\\\\.)_count_Y', '\\\\bтам_count_Y', '\\\\bсо\\\\b_count_Y', '\\\\bсамым\\\\b_count_Y', '\\\\bрода\\\\b_count_Y', '\\\\bобщ[иеу]_count_Y', '\\\\bо\\\\b_count_Y', '\\\\bим\\\\b_count_Y', '\\\\bже\\\\b_count_Y', '\\\\bеще_count_Y', '\\\\(_count_Y', '\\\\(.+\\\\)_count_Y', '\\\\bаналогичн_count_Y', '\\\\bанализ\\\\b_count_Y', '\\\\bа\\\\b_count_Y', '\\\\bто\\\\b_count_Y', '\\\\bпосле\\\\b_count_Y', '\\\\bзаканчива_count_Y', '^[-—]_count_Y', ',$_count_Y', '\\\\[_count_Y', ':_count_Y', '\\\\d+_count_Y', '\\\\.\\\\.\\\\._count_Y', '- ?_count_Y', '\\\\\\\\-_count_Y', '\\\\+_count_Y', 'где [a-zа-я ]+ [—-]_count_Y', '\\\\bмере\\\\b_count_Y', 'менее_count_Y', 'между_count_Y', '\\\\bмало\\\\b_count_Y', '\\\\bлишь\\\\b_count_Y', 'линии_count_Y', 'котор_count_Y', 'концов_count_Y', '\\\\bко(?:й|ю|я|ем)\\\\b_count_Y', '\\\\bкак\\\\b_count_Y', 'источником_count_Y', 'месте_count_Y', 'мире_count_Y', '\\\\bне только_count_Y', 'начина_count_Y', 'настаива_count_Y', 'насколько_count_Y', 'наряду_count_Y', 'наоборот_count_Y', '\\\\bисточник\\\\b_count_Y', '\\\\bнам\\\\b_count_Y', 'надеяться_count_Y', 'наглядн_count_Y', 'момента_count_Y', 'можно_count_Y', 'может_count_Y', 'назва_count_Y', 'исключением_count_Y', 'добави_count_Y', 'для\\\\b_count_Y', 'делят_count_Y', '\\\\bдело\\\\b_count_Y', 'делать_count_Y', 'дальше_count_Y', '\\\\bдал\\\\b_count_Y', 'говорить?ся_count_Y', 'должны_count_Y', 'интересн_count_Y', 'иногда_count_Y', 'име(?:я|ем|ет|ют)_count_Y', '\\\\bиз\\\\b_count_Y', '\\\\bи если_count_Y', 'зрения_count_Y', 'заяв(?:и|ля)_count_Y', 'защиту_count_Y', 'затем_count_Y', 'застав[ли]_count_Y', 'заме(?:ти|чать)_count_Y', 'есть_count_Y', '\\\\bибо\\\\b_count_Y', '\\\\bситуаци_count_Y', 'мнени_count_Y', '\\\\bвсе\\\\b_count_Y', 'большинство_count_Y', '\\\\d+[)\\\\.#]_count_Y', 'бесспорно_count_Y', '\\\\bлибо\\\\b_count_Y', 'оказ_count_Y', 'причин_count_Y', '\\\\bстановит_count_Y', '\\\\bнего_count_Y', 'раздел_count_Y', 'очередь_count_Y', 'повыс_count_Y', 'подобным_count_Y', 'мочь_count_Y', 'несомненн_count_Y', 'наблюдени_count_Y', '\\\\bгде\\\\b_count_Y', 'образцы_count_Y', 'вести_count_Y', '\\\\?$_count_Y', 'завери_count_Y', 'невзирая_count_Y', 'тогда_count_Y', 'пути_count_Y', '\\\\bко?\\\\b_count_Y', '\\\\bта_count_Y', '\\\\bслова\\\\b_count_Y', 'толчком_count_Y', 'обнаружил_count_Y', 'качестве_count_Y', 'обеспечива_count_Y', '\\\\bтом(?:\\\\),|,|..)_count_Y', 'иначе_count_Y', 'задолго_count_Y', 'подобн_count_Y', 'подразумевает_count_Y', '\\\\bдо\\\\b_count_Y', '\\\\bтем\\\\b_count_Y', 'считать,_count_Y', 'объект_count_Y', 'потому_count_Y', 'совместно_count_Y', 'распоряж_count_Y', '\\\\bследу_count_Y', 'значени_count_Y', 'во многом_count_Y', 'обеспечивающ_count_Y', 'отсюда_count_Y', 'данн_count_Y', 'возникающ_count_Y', '\\\\bсам[ое]_count_Y', '\\\\bему\\\\b_count_Y', '\\\\bна\\\\b_count_Y', '\\\\bтому\\\\b_count_Y', 'показ_count_Y', '\\\\bмог_count_Y', 'именно_count_Y', 'порожд_count_Y', 'повод_count_Y', 'довольно_count_Y', 'согласно_count_Y', 'отмети_count_Y', 'считать_count_Y', 'далее_count_Y', 'только_count_Y', '\\\\bитог.\\\\b_count_Y', 'ключев_count_Y', 'добавля_count_Y', '\\\\bб\\\\b_count_Y', 'итак_count_Y', 'нетрудн_count_Y', '\\\\bа с\\\\b_count_Y', '\\\\bтам\\\\b_count_Y', 'отчасти_count_Y', 'столько_count_Y', 'притом_count_Y', 'прошествии_count_Y', 'маловероятн_count_Y', 'вывод[ау]_count_Y', 'напротив_count_Y', '\\\\bно и\\\\b_count_Y', 'действительно_count_Y', '\\\\bих\\\\b_count_Y', '\\\\bвключая\\\\b_count_Y', 'имени_count_Y', 'означа_count_Y', '\\\\bно\\\\b_count_Y', 'параллельно_count_Y', 'последн_count_Y', '\\\\bпор\\\\b_count_Y', 'некотор_count_Y', 'скорее_count_Y', ';_count_Y', 'оправдыва_count_Y', 'полагаем_count_Y', 'изменя_count_Y', 'призна_count_Y', 'пос[кт]ольку_count_Y', '\\\\bте_count_Y', 'просто_count_Y', '\\\\)_count_Y', '\\\\bмы\\\\b_count_Y', '\\\\bлица\\\\b_count_Y', '\\\\bв целом_count_Y', 'впрочем_count_Y', 'обозначи_count_Y', '\\\\bвывод\\\\b_count_Y', 'отношении_count_Y', '\\\\bн[е|и]\\\\b_count_Y', 'получим_count_Y', 'сравнению_count_Y', 'обязательн_count_Y', '\\\\bпока\\\\b_count_Y', 'интерес\\\\b_count_Y', 'следует_count_Y', 'как(?:ая|ой|ое|ие)_count_Y', 'ввиду_count_Y', 'first_pair_помога_y', 'first_pair_одновременно_y', 'first_pair_после_y', 'first_pair_;_y', 'first_pair_подчерк_y', 'first_pair_\\\\bн[е|и]\\\\b_y', 'first_pair_\\\\bмог_y', 'first_pair_подобн_y', 'first_pair_\\\\bитог.\\\\b_y', 'first_pair_:_y', 'first_pair_,_y', 'first_pair_\\\\bих\\\\b_y', 'first_pair_\\\\bсилу\\\\b_y', 'first_pair_всяком_y', 'first_pair_\\\\bтак\\\\b_y', 'first_pair_\\\\bзаканчива_y', 'first_pair_потому_y', 'first_pair_дальше_y', 'first_pair_\\\\bточк(?:и|ой)_y', 'first_pair_\\\\bиз\\\\b_y', 'first_pair_поз(?:дн|же)_y', 'first_pair_сведениям_y', 'first_pair_значени_y', 'first_pair_имя_y', 'first_pair_врем_y', 'first_pair_\\\\bмере\\\\b_y', 'first_pair_име(?:я|ем|ет|ют)_y', 'first_pair_\\\\bа\\\\b_y', 'first_pair_,$_y', 'first_pair_^[-—]_y', 'first_pair_\\\\bко?\\\\b_y', 'first_pair_стоит_y', 'first_pair_заключа_y', 'first_pair_\\\\bпо\\\\b_y', 'first_pair_начина_y', 'first_pair_перед_y', 'first_pair_соответств_y', 'first_pair_начал[аеоу]_y', 'first_pair_\\\\bнам\\\\b_y', 'first_pair_добави_y', 'first_pair_\\\\bговори.?\\\\b_y', 'first_pair_обеспечивающ_y', 'first_pair_район_y', 'first_pair_\\\\bведь\\\\b_y', 'first_pair_\\\\bна\\\\b_y', 'first_pair_буд[еу][мт]_y', 'first_pair_вывод[ау]_y', 'first_pair_\\\\bвсе\\\\b_y', 'first_pair_между_y', 'first_pair_\\\\bпод\\\\b_y', 'first_pair_далее_y', 'first_pair_\\\\bпор\\\\b_y', 'first_pair_обстоятельств_y', 'first_pair_здесь_y', 'first_pair_\\\\bбы\\\\b_y', 'first_pair_\\\\._y', 'first_pair_имени_y', 'first_pair_\\\\bвот\\\\b_y', 'first_pair_друго_y', 'first_pair_предмет_y', 'first_pair_даже_y', 'first_pair_делать_y', 'first_pair_нужно_y', 'first_pair_\\\\bчего\\\\b_y', 'first_pair_ходе_y', 'first_pair_называ_y', 'first_pair_други_y', 'first_pair_столь_y', 'first_pair_\\\\bисходя\\\\b_y', 'first_pair_\\\\bтот\\\\b_y', 'first_pair_!_y', 'first_pair_сторон_y', 'first_pair_причем_y', 'first_pair_сказа_y', 'first_pair_маловероятн_y', 'first_pair_роль_y', 'first_pair_форме_y', 'first_pair_порожда_y', 'first_pair_\\\\bмало\\\\b_y', 'first_pair_разделя_y', 'first_pair_разумеется_y', 'first_pair_\"_y', 'first_pair_больше_y', 'first_pair_показ_y', 'first_pair_как(?:ая|ой|ое|ие)_y', 'first_pair_обнаружил_y', 'first_pair_откуда_y', 'first_pair_мире_y', 'first_pair_целях_y', 'first_pair_иными?_y', 'first_pair_вызы?ва_y', 'first_pair_надеяться_y', 'first_pair_кажется_y', 'first_pair_требуется_y', 'first_pair_причин_y', 'first_pair_приходится_y', 'first_pair_\\\\bтом\\\\b_y', 'first_pair_–_y', 'first_pair_\\\\bли\\\\b_y', 'first_pair_\\\\bчаще\\\\b_y', 'first_pair_\\\\bвидно\\\\b_y', 'first_pair_\\\\bто ?_y', 'first_pair_пос[кт]ольку_y', 'first_pair_(?:один|одна|одно|одни)_y', 'first_pair_заяв(?:и|ля)_y', 'first_pair_означа_y', 'first_pair_\\\\bи если_y', 'first_pair_противоположн_y', 'first_pair_\\\\bследстви_y', 'first_pair_\\\\bцель\\\\b_y', 'first_pair_позволя_y', 'first_pair_\\\\bи при\\\\b_y', 'first_pair_потребова_y', 'first_pair_\\\\bлица\\\\b_y', 'first_pair_\\\\bпока\\\\b_y', 'first_pair_\\\\bеще_y', 'first_pair_тогда_y', 'first_pair_раздел_y', 'first_pair_\\\\bнего_y', 'first_pair_отместку_y', 'first_pair_части_y', 'first_pair_переда_y', 'first_pair_\\\\bему\\\\b_y', 'first_pair_\\\\bс\\\\b_y', 'first_pair_разве_y', 'first_pair_направленн_y', 'first_pair_чтобы_y', 'first_pair_собственно_y', 'first_pair_\\\\bи\\\\b_y', 'first_pair_заме(?:ти|чать)_y', 'first_pair_вести_y', 'first_pair_настоящ_y', 'first_pair_намека_y', 'first_pair_\\\\bтут\\\\b_y', 'first_pair_неимением_y', 'first_pair_\\\\.\\\\\\\\.\\\\\\\\._y', 'first_pair_результат_y', 'first_pair_первоначально_y', 'first_pair_рамках_y', 'first_pair_\\\\bно\\\\b_y', 'first_pair_трет(?:ий|ая|ое|ьи)_y', 'first_pair_приводи_y', 'first_pair_\\\\bсам[ое]_y', 'first_pair_\\\\bчто\\\\b_y', 'first_pair_однако_y', 'first_pair_свидетельств_y', 'first_pair_объяви_y', 'first_pair_качестве_y', 'first_pair_ранее_y', 'first_pair_довольно_y', 'first_pair_подход_y', 'first_pair_обнаружи_y', 'first_pair_степени_y', 'first_pair_отличи_y', 'first_pair_назва_y', 'first_pair_\\\\(_y', 'first_pair_теперь_y', 'first_pair_может_y', 'first_pair_менее_y', 'first_pair_рассказыва_y', 'first_pair_\\\\bчему\\\\b_y', 'first_pair_должны_y', 'first_pair_писа_y', 'first_pair_\\\\bдава_y', 'first_pair_согласно_y', 'first_pair_\\\\bили\\\\b_y', 'first_pair_\\\\bте_y', 'first_pair_\\\\bэто[ймг]\\\\b_y', 'first_pair_\\\\bв\\\\b_y', 'first_pair_\\\\bтого\\\\b_y', 'first_pair_завери_y', 'first_pair_изменя_y', 'first_pair_если_y', 'first_pair_очевидно_y', 'first_pair_конечн_y', 'first_pair_скорее_y', 'first_pair_особ_y', 'first_pair_\\\\bтакже\\\\b_y', 'first_pair_информаци_y', 'first_pair_правда_y', 'first_pair_некотор_y', 'first_pair_указыва_y', 'first_pair_пути_y', 'first_pair_\\\\bдо\\\\b_y', 'first_pair_\\\\bвслед\\\\b_y', 'first_pair_\\\\bим\\\\b_y', 'first_pair_\\\\bтам\\\\b_y', 'first_pair_именно_y', 'first_pair_\\\\bта_y', 'first_pair_через_y', 'first_pair_\\\\bлибо\\\\b_y', 'first_pair_объект_y', 'first_pair_выби?ра_y', 'first_pair_необходим_y', 'first_pair_числ_y', 'first_pair_рассчитывая_y', 'first_pair_конце_y', 'first_pair_неясн_y', 'first_pair_\\\\)_y', 'first_pair_\\\\d+_y', 'first_pair_частности_y', 'first_pair_невозможн_y', 'first_pair_\\\\bуказа_y', 'first_pair_\\\\bэто_y', 'first_pair_повыш_y', 'first_pair_одним_y', 'first_pair_\\\\bгде\\\\b_y', 'first_pair_несмотря_y', 'first_pair_\\\\bрода\\\\b_y', 'first_pair_говорить?ся_y', 'first_pair_получа_y', 'first_pair_\\\\bоб?\\\\b_y', 'first_pair_особенн_y', 'first_pair_предназначен_y', 'first_pair_\\\\bтом(?:\\\\),|,|..)_y', 'first_pair_\\\\bсамым\\\\b_y', 'first_pair_точнее_y', 'first_pair_следующ_y', 'first_pair_решение_y', 'first_pair_\\\\bв [а-я]+[еи]_y', 'first_pair_образцы_y', 'first_pair_\\\\bтому\\\\b_y', 'first_pair_только_y', 'first_pair_предпочтительн_y', 'first_pair_основ_y', 'first_pair_независим_y', 'first_pair_«_y', 'first_pair_\\\\bчем\\\\b_y', 'first_pair_\\\\bслова\\\\b_y', 'first_pair_\\\\bявля[ею]_y', 'first_pair_всего_y', 'first_pair_ради_y', 'first_pair_притом_y', 'first_pair_когда_y', 'first_pair_направлен_y', 'first_pair_\\\\bдело\\\\b_y', 'first_pair_котор_y', 'first_pair_призна_y', 'first_pair_\\\\bтем[ау]\\\\b_y', 'first_pair_послужи_y', 'first_pair_главе_y', 'first_pair_характеризу_y', 'first_pair_утвержда_y', 'first_pair_сдела_y', 'first_pair_случа_y', 'first_pair_\\\\bуже\\\\b_y', 'first_pair_способств_y', 'first_pair_пределами_y', 'first_pair_\\\\+_y', 'first_pair_хотя_y', 'first_pair_\\\\bтой\\\\b_y', 'first_pair_\\\\bэтим\\\\b_y', 'first_pair_известно_y', 'first_pair_проявля_y', 'first_pair_сыграть_y', 'first_pair_равно_y', 'first_pair_отмеч_y', 'first_pair_\\\\bстать\\\\b_y', 'first_pair_отмети_y', 'first_pair_можно_y', 'first_pair_следует_y', 'first_pair_широк_y', 'first_pair_\\\\bмы\\\\b_y', 'first_pair_почему_y', 'first_pair_слишком_y', 'first_pair_\\\\bчто [а-я]+ет\\\\b_y', 'first_pair_обвини_y', 'first_pair_учетом_y', 'first_pair_отсюда_y', 'first_pair_речь_y', 'first_pair_\\\\bза\\\\b_y', 'first_pair_\\\\bот\\\\b_y', 'first_pair_\\\\bвид.?\\\\b_y', 'first_pair_составе_y', 'first_pair_застав[ли]_y', 'first_pair_пример_y', 'first_pair_\\\\bних\\\\b_y', 'first_pair_наблюдени_y', 'first_pair_интересн_y', 'first_pair_течение_y', 'first_pair_ин[?:ое|ой|ая]_y', 'first_pair_связан_y', 'first_pair_применительно_y', 'first_pair_позволяющ_y', 'first_pair_оказ_y', 'first_pair_состоять_y', 'first_pair_\\\\bлишь\\\\b_y', 'first_pair_учитыва_y', 'first_pair_больш[оаи]_y', 'first_pair_привести_y', 'first_pair_сторон_x', 'first_pair_маловероятн_x', 'first_pair_роль_x', 'first_pair_\\\\._x', 'first_pair_\\\\?_x', 'first_pair_\\\\bговори.?\\\\b_x', 'first_pair_обеспечивающ_x', 'first_pair_имени_x', 'first_pair_\\\\bтот\\\\b_x', 'first_pair_\\\\bисходя\\\\b_x', 'first_pair_добави_x', 'first_pair_\\\\bвот\\\\b_x', 'first_pair_друго_x', 'first_pair_предмет_x', 'first_pair_даже_x', 'first_pair_делать_x', 'first_pair_нужно_x', 'first_pair_\\\\bчего\\\\b_x', 'first_pair_ходе_x', 'first_pair_други_x', 'first_pair_форме_x', 'first_pair_необходим_x', 'first_pair_конце_x', 'first_pair_наоборот_x', 'first_pair_котор_x', 'first_pair_призна_x', 'first_pair_точнее_x', 'first_pair_\\\\bтем[ау]\\\\b_x', 'first_pair_главе_x', 'first_pair_характеризу_x', 'first_pair_\\\\bведь\\\\b_x', 'first_pair_\\\\bбы\\\\b_x', 'first_pair_\\\\bна\\\\b_x', 'first_pair_вывод[ау]_x', 'first_pair_\\\\bвсе\\\\b_x', 'first_pair_зрения_x', 'first_pair_\\\\bже\\\\b_x', 'first_pair_\\\\bпор\\\\b_x', 'first_pair_обстоятельств_x', 'first_pair_\\\\bто\\\\b_x', 'first_pair_\\\\bко?\\\\b_x', 'first_pair_стоит_x', 'first_pair_заключа_x', 'first_pair_\\\\bтех\\\\b_x', 'first_pair_начина_x', 'first_pair_перед_x', 'first_pair_соответств_x', 'first_pair_^[-—]_x', 'first_pair_настоящ_x', 'first_pair_намека_x', 'first_pair_столь_x', 'first_pair_значени_x', 'first_pair_имя_x', 'first_pair_врем_x', 'first_pair_име(?:я|ем|ет|ют)_x', 'first_pair_\\\\bа\\\\b_x', 'first_pair_есть_x', 'first_pair_,_x', 'first_pair_\\\\bих\\\\b_x', 'first_pair_\\\\bсилу\\\\b_x', 'first_pair_всяком_x', 'first_pair_\\\\bвывод\\\\b_x', 'first_pair_потому_x', 'first_pair_объясн_x', 'first_pair_\\\\bточк(?:и|ой)_x', 'first_pair_\\\\bитог.\\\\b_x', 'first_pair_сведениям_x', 'first_pair_после_x', 'first_pair_;_x', 'first_pair_повод_x', 'first_pair_подчерк_x', 'first_pair_\\\\bмог_x', 'first_pair_помо[чщ]_x', 'first_pair_подобн_x', 'first_pair_\\\\bсамым\\\\b_x', 'first_pair_\\\\bсвязи\\\\b_x', 'first_pair_можно_x', 'first_pair_\\\\bте_x', 'first_pair_\\\\bили\\\\b_x', 'first_pair_широк_x', 'first_pair_\\\\bэто[ймг]\\\\b_x', 'first_pair_\\\\bмы\\\\b_x', 'first_pair_почему_x', 'first_pair_\\\\bсо\\\\b_x', 'first_pair_рассм[ао]тр_x', 'first_pair_привести_x', 'first_pair_связан_x', 'first_pair_позволяющ_x', 'first_pair_изменя_x', 'first_pair_\\\\bстать\\\\b_x', 'first_pair_состоять_x', 'first_pair_завери_x', 'first_pair_\\\\bтого\\\\b_x', 'first_pair_\\\\bв\\\\b_x', 'first_pair_отмеч_x', 'first_pair_\\\\bв [а-я]+[еи]_x', 'first_pair_\\\\bвслед\\\\b_x', 'first_pair_\\\\bим\\\\b_x', 'first_pair_против_x', 'first_pair_\\\\bтам\\\\b_x', 'first_pair_может_x', 'first_pair_именно_x', 'first_pair_просто_x', 'first_pair_\\\\bта_x', 'first_pair_скорее_x', 'first_pair_\\\\bлибо\\\\b_x', 'first_pair_проблемы_x', 'first_pair_пути_x', 'first_pair_решение_x', 'first_pair_\\\\?$_x', 'first_pair_порожд_x', 'first_pair_особ_x', 'first_pair_писа_x', 'first_pair_\\\\bтакже\\\\b_x', 'first_pair_информаци_x', 'first_pair_некотор_x', 'first_pair_должны_x', 'first_pair_ид(?:ет|ти)_x', 'first_pair_наблюдени_x', 'first_pair_\\\\bважн_x', 'first_pair_\\\\bгде\\\\b_x', 'first_pair_\\\\bэтим\\\\b_x', 'first_pair_значит_x', 'first_pair_\\\\bдело\\\\b_x', 'first_pair_говорят?_x', 'first_pair_повыш_x', 'first_pair_образцы_x', 'first_pair_\\\\bтому\\\\b_x', 'first_pair_ниве_x', 'first_pair_отношении_x', 'first_pair_\\\\bвопрос_x', 'first_pair_\\\\bвключая\\\\b_x', 'first_pair_несмотря_x', 'first_pair_утвержда_x', 'first_pair_сдела_x', 'first_pair_особенн_x', 'first_pair_\\\\bоб?\\\\b_x', 'first_pair_получа_x', 'first_pair_\\\\bвтор_x', 'first_pair_способств_x', 'first_pair_пределами_x', 'first_pair_\\\\+_x', 'first_pair_\\\\bуже\\\\b_x', 'first_pair_предпочтительн_x', 'first_pair_интересн_x', 'first_pair_\\\\bисточник\\\\b_x', 'first_pair_объект_x', 'first_pair_\\\\bза\\\\b_x', 'first_pair_составе_x', 'first_pair_застав[ли]_x', 'first_pair_пример_x', 'first_pair_\\\\bних\\\\b_x', 'first_pair_\\\\bот\\\\b_x', 'first_pair_сыграть_x', 'first_pair_\\\\bуказа_x', 'first_pair_независим_x', 'first_pair_«_x', 'first_pair_\\\\bчем\\\\b_x', 'first_pair_\\\\bкак\\\\b_x', 'first_pair_\\\\bслова\\\\b_x', 'first_pair_\\\\bявля[ею]_x', 'first_pair_сообщи_x', 'first_pair_притом_x', 'first_pair_частности_x', 'first_pair_когда_x', 'first_pair_\\\\d+_x', 'first_pair_\\\\bтом(?:\\\\),|,|..)_x', 'first_pair_!_x', 'first_pair_вести_x', 'first_pair_кажется_x', 'first_pair_надеяться_x', 'first_pair_целях_x', 'first_pair_откуда_x', 'first_pair_обнаружил_x', 'first_pair_как(?:ая|ой|ое|ие)_x', 'first_pair_определ_x', 'first_pair_\"_x', 'first_pair_роли_x', 'first_pair_\\\\bсути\\\\b_x', 'first_pair_показ_x', 'first_pair_\\\\bмало\\\\b_x', 'first_pair_оценк_x', 'first_pair_причин_x', 'first_pair_ранее_x', 'first_pair_объяви_x', 'first_pair_\\\\bсам[ое]_x', 'first_pair_приводи_x', 'first_pair_\\\\bно\\\\b_x', 'first_pair_распоряж_x', 'first_pair_результат_x', 'first_pair_\\\\.\\\\\\\\.\\\\\\\\._x', 'first_pair_\\\\bеще_x', 'first_pair_трет(?:ий|ая|ое|ьи)_x', 'first_pair_довольно_x', 'first_pair_\\\\bли\\\\b_x', 'first_pair_\\\\bчто и\\\\b_x', 'first_pair_–_x', 'first_pair_\\\\bбыл\\\\b_x', 'first_pair_проявля_x', 'first_pair_\\\\bмомент\\\\b_x', 'first_pair_- ?_x', 'first_pair_\\\\bтем\\\\b_x', 'first_pair_\\\\bчаще\\\\b_x', 'first_pair_приходится_x', 'first_pair_\\\\bлица\\\\b_x', 'first_pair_\\\\bтом\\\\b_x', 'first_pair_более_x', 'first_pair_\\\\bфакт\\\\b_x', 'first_pair_означа_x', 'first_pair_заяв(?:и|ля)_x', 'first_pair_(?:один|одна|одно|одни)_x', 'first_pair_\\\\bобщ[иеу]_x', 'first_pair_пос[кт]ольку_x', 'first_pair_\\\\bвидно\\\\b_x', 'first_pair_пусть_x', 'first_pair_направленн_x', 'first_pair_неимением_x', 'first_pair_\\\\bи\\\\b_x', 'first_pair_чтобы_x', 'first_pair_\\\\bнего_x', 'first_pair_\\\\bтак(?:ие|им|их|ов|ой|ая|ое)\\\\b_x', 'first_pair_\\\\bс\\\\b_x', 'first_pair_собственно_x', 'first_pair_степени_x', 'first_pair_переда_x', 'first_pair_обнаружи_x', 'first_pair_тогда_x', 'first_pair_части_x', 'first_pair_действительно_x', 'first_pair_подход_x', 'first_pair_отместку_x', 'first_pair_\\\\bтут\\\\b_x', 'first_pair_услови_y', 'first_pair_грани_y', 'first_pair_\\\\bрода\\\\b_x', 'first_pair_вместо_y', 'first_pair_объясн_y', 'first_pair_пользу_y', 'first_pair_ошибкой_y', 'first_pair_говорят?_y', 'first_pair_сообщи_y', 'first_pair_\\\\bэто\\\\b_y', 'first_pair_мнени_x', 'first_pair_разве_x', 'first_pair_\\\\bвтор_y', 'first_pair_смену_y', 'first_pair_район_x', 'first_pair_повод_y', 'first_pair_равно_x', 'first_pair_ин[?:ое|ой|ая]_x', 'first_pair_\\\\bчто и\\\\b_y', 'first_pair_есть_y', 'first_pair_помога_x', 'first_pair_\\\\bэто\\\\b_x', 'first_pair_\\\\bкак\\\\b_y', 'first_pair_\\\\bситуаци_x', 'first_pair_учитыва_x', 'first_pair_\\\\bн[е|и]\\\\b_x', 'first_pair_помо[чщ]_y', 'first_pair_\\\\bпока\\\\b_x', 'first_pair_применительно_x', 'first_pair_\\\\bто ?_x', 'first_pair_просто_y', 'first_pair_\\\\bибо\\\\b_x', 'first_pair_порожд_y', 'first_pair_сообща_y', 'first_pair_распоряж_y', 'first_pair_\\\\bисточник\\\\b_y', 'first_pair_разделя_x', 'first_pair_выби?ра_x', 'first_pair_против_y', 'first_pair_\\\\bчему\\\\b_x', 'first_pair_слишком_x', 'first_pair_числ_x', 'first_pair_\\\\bвид.?\\\\b_x', 'first_pair_игра_x', 'first_pair_вызы?ва_x', 'first_pair_одним_x', 'first_pair_говорить?ся_x', 'first_pair_рамках_x', 'first_pair_наоборот_y', 'first_pair_благодаря_y', 'first_pair_рассм[ао]тр_y', 'first_pair_данн_y', 'first_pair_называ_x', 'first_pair_\\\\bсвязи\\\\b_y', 'first_pair_данн_x', 'first_pair_далее_x', 'first_pair_\\\\bэто_x', 'first_pair_послужи_x', 'first_pair_\\\\bситуаци_y', 'first_pair_рассчитывая_x', 'first_pair_отличи_x', 'first_pair_\\\\bиз\\\\b_x', 'first_pair_затем_x', 'first_pair_случа_x', 'first_pair_для\\\\b_x', 'first_pair_\\\\bдо\\\\b_x', 'first_pair_\\\\bчто [а-я]+ет\\\\b_x', 'first_pair_\\\\bбез\\\\b_y', 'first_pair_\\\\bстав\\\\b_x', 'first_pair_\\\\bсловам\\\\b_y', 'first_pair_через_x', 'first_pair_\\\\bбез\\\\b_x', 'first_pair_уточня_y', 'first_pair_раздел_x', 'first_pair_\\\\bтой\\\\b_x', 'first_pair_\\\\bперв_y', 'first_pair_роли_y', 'first_pair_\\\\bтак(?:ие|им|их|ов|ой|ая|ое)\\\\b_y', 'first_pair_\\\\bзаканчива_x', 'first_pair_\\\\bда\\\\b_x', 'first_pair_обязательн_x', 'first_pair_\\\\bво\\\\b_y', 'first_pair_грани_x', 'first_pair_ид(?:ет|ти)_y', 'first_pair_\\\\bсо\\\\b_y', 'first_pair_хотя_x', 'first_pair_зависимост_x', 'first_pair_\\\\?_y', 'first_pair_\\\\bдава_x', 'first_pair_сказа_x', 'first_pair_рассказыва_x', 'first_pair_речь_x', 'first_pair_между_x', 'first_pair_\\\\bсреди\\\\b_x', 'first_pair_известно_x', 'first_pair_\\\\bто\\\\b_y', 'first_pair_направлен_x', 'first_pair_ошибкой_x', 'first_pair_назва_x', 'first_pair_образом_y', 'first_pair_\\\\bво\\\\b_x', 'first_pair_\\\\(_x', 'first_pair_\\\\bибо\\\\b_y', 'first_pair_\\\\bтех\\\\b_y', 'first_pair_уточня_x', 'first_pair_однако_x', 'first_pair_\\\\bстав\\\\b_y', 'first_pair_подтвержд_y', 'first_pair_\\\\bдела_y', 'first_pair_теперь_x', 'first_pair_одновременно_x', 'last_pair_\\\\bн[е|и]\\\\b_y', 'last_pair_\\\\bитог.\\\\b_y', 'last_pair_,_y', 'last_pair_\\\\bда\\\\b_y', 'last_pair_\\\\bзаканчива_y', 'last_pair_помога_y', 'last_pair_\\\\bнам\\\\b_y', 'last_pair_\\\\bстав\\\\b_y', 'last_pair_значени_y', 'last_pair_имя_y', 'last_pair_име(?:я|ем|ет|ют)_y', 'last_pair_\\\\bа\\\\b_y', 'last_pair_^[-—]_y', 'last_pair_заключа_y', 'last_pair_смену_y', 'last_pair_начал[аеоу]_y', 'last_pair_поз(?:дн|же)_y', 'last_pair_\\\\bвот\\\\b_y', 'last_pair_\\\\?_y', 'last_pair_обеспечивающ_y', 'last_pair_район_y', 'last_pair_\\\\bна\\\\b_y', 'last_pair_буд[еу][мт]_y', 'last_pair_\\\\bпод\\\\b_y', 'last_pair_далее_y', 'last_pair_обстоятельств_y', 'last_pair_здесь_y', 'last_pair_наоборот_y', 'last_pair_\\\\._y', 'last_pair_имени_y', 'last_pair_друго_y', 'last_pair_даже_y', 'last_pair_форме_y', 'last_pair_!_y', 'last_pair_сторон_y', 'last_pair_сказа_y', 'last_pair_роль_y', 'last_pair_отличи_y', 'last_pair_столь_y', 'last_pair_\\\\bчто\\\\b_y', 'last_pair_разделя_y', 'last_pair_ошибкой_y', 'last_pair_разумеется_y', 'last_pair_определ_y', 'last_pair_как(?:ая|ой|ое|ие)_y', 'last_pair_обнаружил_y', 'last_pair_мире_y', 'last_pair_порожда_y', 'last_pair_\\\\bпока\\\\b_y', 'last_pair_\\\\bбыл\\\\b_y', 'last_pair_месте_y', 'last_pair_\\\\bто ?_y', 'last_pair_означа_y', 'last_pair_\\\\bцель\\\\b_y', 'last_pair_\\\\bперв_y', 'last_pair_\\\\bсловам\\\\b_y', 'last_pair_потребова_y', 'last_pair_образом_y', 'last_pair_\\\\.\\\\\\\\.\\\\\\\\._y', 'last_pair_тогда_y', 'last_pair_раздел_y', 'last_pair_\\\\bнего_y', 'last_pair_данн_y', 'last_pair_пусть_y', 'last_pair_заме(?:ти|чать)_y', 'last_pair_вести_y', 'last_pair_настоящ_y', 'last_pair_\\\\bтут\\\\b_y', 'last_pair_неимением_y', 'last_pair_распоряж_y', 'last_pair_\\\\bно\\\\b_y', 'last_pair_приводи_y', 'last_pair_однако_y', 'last_pair_затем_y', 'last_pair_довольно_y', 'last_pair_обнаружи_y', 'last_pair_степени_y', 'last_pair_свидетельств_y', 'last_pair_против_y', 'last_pair_должны_y', 'last_pair_\\\\bво\\\\b_y', 'last_pair_\\\\?$_y', 'last_pair_рассм[ао]тр_y', 'last_pair_\\\\bте_y', 'last_pair_\\\\bтого\\\\b_y', 'last_pair_\\\\bважн_y', 'last_pair_очевидно_y', 'last_pair_правда_y', 'last_pair_некотор_y', 'last_pair_указыва_y', 'last_pair_\\\\bдо\\\\b_y', 'last_pair_\\\\bвслед\\\\b_y', 'last_pair_сообща_y', 'last_pair_\\\\bтам\\\\b_y', 'last_pair_именно_y', 'last_pair_благодаря_y', 'last_pair_через_y', 'last_pair_скорее_y', 'last_pair_выби?ра_y', 'last_pair_необходим_y', 'last_pair_пользу_y', 'last_pair_рассчитывая_y', 'last_pair_неясн_y', 'last_pair_сообщи_y', 'last_pair_одним_y', 'last_pair_\\\\bрода\\\\b_y', 'last_pair_порожд_y', 'last_pair_говорить?ся_y', 'last_pair_\\\\bоб?\\\\b_y', 'last_pair_\\\\bтом(?:\\\\),|,|..)_y', 'last_pair_\\\\bсамым\\\\b_y', 'last_pair_\\\\bвтор_y', 'last_pair_ниве_y', 'last_pair_только_y', 'last_pair_независим_y', 'last_pair_«_y', 'last_pair_\\\\bслова\\\\b_y', 'last_pair_всего_y', 'last_pair_ради_y', 'last_pair_когда_y', 'last_pair_направлен_y', 'last_pair_случа_y', 'last_pair_образцы_y', 'last_pair_\\\\bвопрос_y', 'last_pair_\\\\bдело\\\\b_y', 'last_pair_характеризу_y', 'last_pair_утвержда_y', 'last_pair_сдела_y', 'last_pair_\\\\bуже\\\\b_y', 'last_pair_хотя_y', 'last_pair_\\\\bтой\\\\b_y', 'last_pair_\\\\bэтим\\\\b_y', 'last_pair_известно_y', 'last_pair_значит_y', 'last_pair_способств_y', 'last_pair_\\\\bза\\\\b_y', 'last_pair_отмеч_y', 'last_pair_отмети_y', 'last_pair_можно_y', 'last_pair_следует_y', 'last_pair_широк_y', 'last_pair_\\\\bситуаци_y', 'last_pair_\\\\bмы\\\\b_y', 'last_pair_\\\\bдела_y', 'last_pair_слишком_y', 'last_pair_\\\\bчто [а-я]+ет\\\\b_y', 'last_pair_\\\\bибо\\\\b_y', 'last_pair_\\\\bв [а-я]+[еи]_y', 'last_pair_равно_y', 'last_pair_отсюда_y', 'last_pair_\\\\bвид.?\\\\b_y', 'last_pair_пример_y', 'last_pair_\\\\bних\\\\b_y', 'last_pair_наблюдени_y', 'last_pair_привести_y', 'last_pair_\\\\bлишь\\\\b_y', 'last_pair_учитыва_y', 'last_pair_\\\\bлибо\\\\b_x', 'last_pair_причем_x', 'last_pair_сказа_x', 'last_pair_маловероятн_x', 'last_pair_роль_x', 'last_pair_!_x', 'last_pair_имени_x', 'last_pair_\\\\._x', 'last_pair_\\\\?_x', 'last_pair_\\\\bговори.?\\\\b_x', 'last_pair_обеспечивающ_x', 'last_pair_район_x', 'last_pair_\\\\bвот\\\\b_x', 'last_pair_даже_x', 'last_pair_называ_x', 'last_pair_други_x', 'last_pair_форме_x', 'last_pair_\\\\bисходя\\\\b_x', 'last_pair_нужно_x', 'last_pair_добави_x', 'last_pair_\\\\bведь\\\\b_x', 'last_pair_необходим_x', 'last_pair_конце_x', 'last_pair_отличи_x', 'last_pair_назва_x', 'last_pair_\\\\)_x', 'last_pair_\\\\(_x', 'last_pair_котор_x', 'last_pair_\\\\bтем[ау]\\\\b_x', 'last_pair_главе_x', 'last_pair_характеризу_x', 'last_pair_для\\\\b_x', 'last_pair_призна_x', 'last_pair_пользу_x', 'last_pair_буд[еу][мт]_x', 'last_pair_\\\\bвсе\\\\b_x', 'last_pair_зрения_x', 'last_pair_\\\\bбы\\\\b_x', 'last_pair_между_x', 'last_pair_\\\\bпод\\\\b_x', 'last_pair_далее_x', 'last_pair_рассчитывая_x', 'last_pair_\\\\bпор\\\\b_x', 'last_pair_обстоятельств_x', 'last_pair_здесь_x', 'last_pair_\\\\bже\\\\b_x', 'last_pair_\\\\bто\\\\b_x', 'last_pair_\\\\bнам\\\\b_x', 'last_pair_стоит_x', 'last_pair_\\\\bко?\\\\b_x', 'last_pair_начина_x', 'last_pair_смену_x', 'last_pair_соответств_x', 'last_pair_начал[аеоу]_x', 'last_pair_есть_x', 'last_pair_намека_x', 'last_pair_\\\\bчто\\\\b_x', 'last_pair_обязательн_x', 'last_pair_столь_x', 'last_pair_значени_x', 'last_pair_^[-—]_x', 'last_pair_врем_x', 'last_pair_\\\\bмере\\\\b_x', 'last_pair_име(?:я|ем|ет|ют)_x', 'last_pair_,$_x', 'last_pair_имя_x', 'last_pair_сведениям_x', 'last_pair_,_x', 'last_pair_\\\\bтак\\\\b_x', 'last_pair_\\\\bэто\\\\b_x', 'last_pair_потому_x', 'last_pair_дальше_x', 'last_pair_объясн_x', 'last_pair_\\\\bвывод\\\\b_x', 'last_pair_:_x', 'last_pair_поз(?:дн|же)_x', 'last_pair_помога_x', 'last_pair_после_x', 'last_pair_;_x', 'last_pair_повод_x', 'last_pair_\\\\bн[е|и]\\\\b_x', 'last_pair_\\\\bмог_x', 'last_pair_помо[чщ]_x', 'last_pair_подобн_x', 'last_pair_\\\\bитог.\\\\b_x', 'last_pair_\\\\bтом(?:\\\\),|,|..)_x', 'last_pair_\\\\bэто[ймг]\\\\b_x', 'last_pair_можно_x', 'last_pair_\\\\bте_x', 'last_pair_широк_x', 'last_pair_\\\\bситуаци_x', 'last_pair_\\\\bмы\\\\b_x', 'last_pair_рассм[ао]тр_x', 'last_pair_почему_x', 'last_pair_слишком_x', 'last_pair_\\\\bсо\\\\b_x', 'last_pair_\\\\bчто [а-я]+ет\\\\b_x', 'last_pair_\\\\bибо\\\\b_x', 'last_pair_отмети_x', 'last_pair_\\\\bстать\\\\b_x', 'last_pair_течение_x', 'last_pair_ин[?:ое|ой|ая]_x', 'last_pair_связан_x', 'last_pair_позволяющ_x', 'last_pair_если_x', 'last_pair_\\\\bлишь\\\\b_x', 'last_pair_больш[оаи]_x', 'last_pair_завери_x', 'last_pair_\\\\bтого\\\\b_x', 'last_pair_равно_x', 'last_pair_изменя_x', 'last_pair_привести_x', 'last_pair_\\\\bв [а-я]+[еи]_x', 'last_pair_\\\\bдо\\\\b_x', 'last_pair_\\\\bвслед\\\\b_x', 'last_pair_\\\\bим\\\\b_x', 'last_pair_должны_x', 'last_pair_может_x', 'last_pair_благодаря_x', 'last_pair_\\\\bта_x', 'last_pair_через_x', 'last_pair_очевидно_x', 'last_pair_скорее_x', 'last_pair_теперь_x', 'last_pair_согласно_x', 'last_pair_решение_x', 'last_pair_\\\\bдава_x', 'last_pair_\\\\?$_x', 'last_pair_\\\\bво\\\\b_x', 'last_pair_порожд_x', 'last_pair_особ_x', 'last_pair_проблемы_x', 'last_pair_ид(?:ет|ти)_x', 'last_pair_информаци_x', 'last_pair_правда_x', 'last_pair_некотор_x', 'last_pair_наблюдени_x', 'last_pair_\\\\bэтим\\\\b_x', 'last_pair_известно_x', 'last_pair_\\\\bдело\\\\b_x', 'last_pair_\\\\bгде\\\\b_x', 'last_pair_\\\\bтой\\\\b_x', 'last_pair_\\\\bвопрос_x', 'last_pair_образцы_x', 'last_pair_ниве_x', 'last_pair_отношении_x', 'last_pair_повыш_x', 'last_pair_только_x', 'last_pair_предназначен_x', 'last_pair_сдела_x', 'last_pair_особенн_x', 'last_pair_\\\\bоб?\\\\b_x', 'last_pair_несмотря_x', 'last_pair_\\\\bуже\\\\b_x', 'last_pair_говорить?ся_x', 'last_pair_пределами_x', 'last_pair_\\\\+_x', 'last_pair_\\\\bрода\\\\b_x', 'last_pair_хотя_x', 'last_pair_предпочтительн_x', 'last_pair_основ_x', 'last_pair_\\\\d+_x', 'last_pair_\\\\bисточник\\\\b_x', 'last_pair_выби?ра_x', 'last_pair_\\\\bза\\\\b_x', 'last_pair_объект_x', 'last_pair_интересн_x', 'last_pair_\\\\bот\\\\b_x', 'last_pair_\\\\bвид.?\\\\b_x', 'last_pair_составе_x', 'last_pair_пример_x', 'last_pair_конечн_x', 'last_pair_\\\\bних\\\\b_x', 'last_pair_сыграть_x', 'last_pair_случа_x', 'last_pair_независим_x', 'last_pair_\\\\bчем\\\\b_x', 'last_pair_\\\\bкак\\\\b_x', 'last_pair_\\\\bслова\\\\b_x', 'last_pair_\\\\bявля[ею]_x', 'last_pair_сообщи_x', 'last_pair_когда_x', 'last_pair_направлен_x', 'last_pair_частности_x', 'last_pair_настоящ_x', 'last_pair_требуется_x', 'last_pair_кажется_x', 'last_pair_вызы?ва_x', 'last_pair_целях_x', 'last_pair_мире_x', 'last_pair_откуда_x', 'last_pair_оценк_x', 'last_pair_как(?:ая|ой|ое|ие)_x', 'last_pair_показ_x', 'last_pair_больше_x', 'last_pair_определ_x', 'last_pair_\"_x', 'last_pair_зависимост_x', 'last_pair_разумеется_x', 'last_pair_ошибкой_x', 'last_pair_довольно_x', 'last_pair_ранее_x', 'last_pair_объяви_x', 'last_pair_затем_x', 'last_pair_свидетельств_x', 'last_pair_однако_x', 'last_pair_приводи_x', 'last_pair_причин_x', 'last_pair_уточня_x', 'last_pair_трет(?:ий|ая|ое|ьи)_x', 'last_pair_\\\\bно\\\\b_x', 'last_pair_рамках_x', 'last_pair_первоначально_x', 'last_pair_результат_x', 'last_pair_\\\\.\\\\\\\\.\\\\\\\\._x', 'last_pair_\\\\bеще_x', 'last_pair_\\\\bпока\\\\b_x', 'last_pair_включа_x', 'last_pair_\\\\bтем\\\\b_x', 'last_pair_\\\\bли\\\\b_x', 'last_pair_\\\\bмало\\\\b_x', 'last_pair_\\\\bвидно\\\\b_x', 'last_pair_порожда_x', 'last_pair_\\\\bтом\\\\b_x', 'last_pair_\\\\bсреди\\\\b_x', 'last_pair_мнени_x', 'last_pair_образом_x', 'last_pair_\\\\bфакт\\\\b_x', 'last_pair_месте_x', 'last_pair_\\\\bи при\\\\b_x', 'last_pair_\\\\bсловам\\\\b_x', 'last_pair_\\\\bи если_x', 'last_pair_означа_x', 'last_pair_заяв(?:и|ля)_x', 'last_pair_\\\\bобщ[иеу]_x', 'last_pair_\\\\bто ?_x', 'last_pair_подход_x', 'last_pair_приходится_x', 'last_pair_\\\\bему\\\\b_x', 'last_pair_чтобы_x', 'last_pair_разве_x', 'last_pair_степени_x', 'last_pair_\\\\bи\\\\b_x', 'last_pair_пусть_x', 'last_pair_собственно_x', 'last_pair_\\\\bтак(?:ие|им|их|ов|ой|ая|ое)\\\\b_x', 'last_pair_\\\\bнего_x', 'last_pair_неимением_x', 'last_pair_\\\\bс\\\\b_x', 'last_pair_грани_x', 'last_pair_переда_x', 'last_pair_направленн_x', 'last_pair_действительно_x', 'last_pair_тогда_x', 'last_pair_данн_x', 'last_pair_обнаружи_x', 'last_pair_части_x', 'last_pair_\\\\bтак(?:ие|им|их|ов|ой|ая|ое)\\\\b_y', 'last_pair_други_y', 'last_pair_повод_y', 'last_pair_больш[оаи]_y', 'last_pair_всяком_y', 'last_pair_\\\\bтут\\\\b_x', 'last_pair_речь_y', 'last_pair_сыграть_y', 'last_pair_соответств_y', 'last_pair_\\\\bв\\\\b_x', 'last_pair_просто_x', 'last_pair_намека_y', 'last_pair_ради_x', 'last_pair_пос[кт]ольку_x', 'last_pair_предмет_x', 'last_pair_объясн_y', 'last_pair_\\\\bиз\\\\b_y', 'last_pair_\\\\bважн_x', 'last_pair_чтобы_y', 'last_pair_помо[чщ]_y', 'last_pair_говорят?_x', 'last_pair_\\\\bбыл\\\\b_x', 'last_pair_значит_x', 'last_pair_послужи_y', 'last_pair_друго_x', 'last_pair_оказ_x', 'last_pair_\\\\bчему\\\\b_x', 'last_pair_перед_y', 'last_pair_\\\\bстать\\\\b_y', 'last_pair_\\\\bтому\\\\b_x', 'last_pair_\\\\bдава_y', 'last_pair_\\\\bуказа_x', 'last_pair_способств_x', 'last_pair_включа_y', 'last_pair_позволя_y', 'last_pair_перед_x', 'last_pair_обнаружил_x', 'last_pair_следующ_x', 'last_pair_раздел_x', 'last_pair_застав[ли]_x', 'last_pair_почему_y', 'last_pair_\\\\bто\\\\b_y', 'last_pair_изменя_y', 'last_pair_\\\\(_y', 'last_pair_для\\\\b_y', 'last_pair_\\\\bэто_y', 'last_pair_указыва_x', 'last_pair_получа_x', 'last_pair_сведениям_y', 'last_pair_разделя_x', 'last_pair_\\\\bдела_x', 'last_pair_\\\\bчему\\\\b_y', 'last_pair_\\\\bведь\\\\b_y', 'last_pair_рассказыва_y', 'last_pair_причин_y', 'last_pair_интересн_y', 'last_pair_потому_y', 'last_pair_\\\\bстав\\\\b_x', 'last_pair_разве_y', 'last_pair_говорят?_y', 'last_pair_\\\\bко?\\\\b_y', 'last_pair_одним_x', 'last_pair_\\\\bпо\\\\b_x', 'last_pair_собственно_y', 'last_pair_ранее_y', 'last_pair_писа_x', 'last_pair_\\\\bили\\\\b_x', 'last_pair_\\\\bна\\\\b_x', 'last_pair_уточня_y', 'last_pair_просто_y', 'last_pair_проявля_x', 'last_pair_проблемы_y', 'last_pair_:_y', 'last_pair_\\\\bлица\\\\b_y', 'last_pair_\\\\bтот\\\\b_y', 'last_pair_кажется_y', 'last_pair_«_x', 'last_pair_\\\\bчего\\\\b_x', 'last_pair_части_y', 'last_pair_заключа_x', 'last_pair_\\\\bда\\\\b_x', 'last_pair_причем_y', 'last_pair_рамках_y', 'last_pair_ходе_x', 'last_pair_одновременно_x', 'last_pair_именно_x', 'last_pair_утвержда_x', 'last_pair_менее_y', 'last_pair_\\\\bмере\\\\b_y', 'last_pair_невозможн_y', 'last_pair_\\\\bих\\\\b_y', 'last_pair_применительно_y', 'last_pair_позволяющ_y', 'last_pair_может_y', 'last_pair_течение_y', 'last_pair_состоять_y', 'last_pair_следует_x', 'last_pair_более_y', 'last_pair_надеяться_x', 'last_pair_подобн_y', 'last_pair_отместку_x', 'last_pair_менее_x', 'last_pair_целях_y', 'last_pair_\\\\bбыть\\\\b_y', 'last_pair_\\\\bисточник\\\\b_y', 'last_pair_\\\\bих\\\\b_x', 'last_pair_\\\\bтех\\\\b_x', 'last_pair_учитыва_x', 'last_pair_предпочтительн_y', 'last_pair_точнее_x', 'last_pair_повыш_y', 'last_pair_\\\\bи если_y', 'last_pair_\\\\bбез\\\\b_x', 'last_pair_игра_y', 'last_pair_послужи_x', 'last_pair_отмеч_x', 'last_pair_иными?_x', 'last_pair_\\\\bсам[ое]_x', 'last_pair_более_x', 'last_pair_представ_y', 'last_pair_\\\\bвывод\\\\b_y', 'last_pair_надеяться_y', 'last_pair_добави_y', 'last_pair_частности_y', 'last_pair_распоряж_x', 'last_pair_\\\\bлибо\\\\b_y', 'last_pair_\\\\bеще_y', 'last_pair_наоборот_x', 'last_pair_\\\\bкак\\\\b_y', 'last_pair_\\\\bтам\\\\b_x', 'last_pair_всего_x', 'last_pair_\\\\bгде\\\\b_y', 'last_pair_зрения_y', 'last_pair_\\\\bэто_x', 'last_pair_услови_y', 'last_pair_\\\\bуказа_y', 'last_pair_\\\\bвключая\\\\b_x', 'last_pair_учетом_x', 'last_pair_роли_x', 'last_pair_\\\\bтому\\\\b_y', 'last_pair_\\\\bот\\\\b_y', 'last_pair_есть_y', 'last_pair_\\\\bа\\\\b_x', 'last_pair_\\\\bэто[ймг]\\\\b_y', 'last_pair_\\\\)_y', 'last_pair_приходится_y', 'last_pair_вести_x', 'last_pair_отместку_y', 'last_pair_\\\\bи\\\\b_y', 'last_pair_подтвержд_x', 'last_pair_всяком_x', 'last_pair_отсюда_x', 'last_pair_игра_x', 'last_pair_\\\\bчаще\\\\b_x']\n",
    "\n",
    "# X_wo_textual = X.drop(columns=[feature for feature in textual])\n",
    "# X_wo_lexical = X.drop(columns=[feature for feature in lexical])\n",
    "# X_wo_morpho = X.drop(columns=[feature for feature in morphosynt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FILvBY4QWnWU"
   },
   "source": [
    "### 3. Classifiers & CV-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HjAX-ooWnWV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(random_state=random_state, C=0.001, class_weight='balanced')\n",
    "\n",
    "bagger_lsvc = BaggingClassifier(base_estimator=lsvc, \n",
    "                                n_estimators=2, \n",
    "                                max_samples=.9, \n",
    "                                max_features=.7, \n",
    "                                bootstrap=True, \n",
    "                                bootstrap_features=False, \n",
    "                                oob_score=False, \n",
    "                                warm_start=False, \n",
    "                                n_jobs=-1, \n",
    "                                random_state=random_state, \n",
    "                                verbose=0)\n",
    "\n",
    "logreg = LogisticRegression(random_state=random_state,\n",
    "                            solver='lbfgs',\n",
    "                            n_jobs=8,\n",
    "                            C=0.002,\n",
    "                            multi_class='multinomial',\n",
    "                            class_weight='balanced')\n",
    "\n",
    "lgbm_param =  {\n",
    "    'tree_learner': 'feature',\n",
    "    'task': 'train',\n",
    "    'scale_pos_weight': 155,\n",
    "    'reg_lambda': 0.11,\n",
    "    'reg_alpha': 0.11,\n",
    "    'random_state': random_state,\n",
    "    'num_leaves': 36,\n",
    "    'num_class': 11,\n",
    "    'min_split_gain': 0.76,\n",
    "    'min_child_weight': 0.11,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.45,\n",
    "    'boosting_type': 'dart',\n",
    "    'bagging_fraction': 0.9,\n",
    "    'application': 'multiclass',\n",
    "    'num_iterations': 1000,\n",
    "}\n",
    "#lgb_class = lgb.LGBMClassifier(**lgbm_param)\n",
    "lgb_class = None\n",
    "\n",
    "class SklearnWrapperKerasEstimator(Model):      \n",
    "    def fit(self, _X, _y):\n",
    "        indices = np.arange(_y.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        try:\n",
    "            _X = _X.iloc[indices]\n",
    "            _y = _y.iloc[indices]\n",
    "        except AttributeError:\n",
    "            _X = pd.DataFrame(_X, columns=X.columns).iloc[indices]\n",
    "            _y = pd.DataFrame(_y, columns=y.columns).iloc[indices]\n",
    "          \n",
    "        replace_map = {TARGET : {k: v for k,v in zip(top11,list(range(0,len(top11))))}}\n",
    "        y_categorical = to_categorical(_y.replace(replace_map))\n",
    "\n",
    "        session = K.get_session()\n",
    "        for layer in self.layers: \n",
    "            if hasattr(layer, 'kernel_initializer'):\n",
    "                layer.kernel.initializer.run(session=session)\n",
    "        \n",
    "        return super(SklearnWrapperKerasEstimator, self).fit(_X, y_categorical, epochs=7, batch_size=128, validation_split=0.)\n",
    "      \n",
    "    def predict(self, *args, **kwargs):\n",
    "        preds = super().predict(*args, **kwargs)\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        preds = [unique_type_list[prediction] for prediction in preds]\n",
    "        return preds\n",
    "\n",
    "    def predict_proba(self, *args, **kwargs):\n",
    "        return super().predict(*args, **kwargs)\n",
    "    \n",
    "def construct_simple_nn_classifier(input_length, output_length):\n",
    "    input_features = Input(shape=(input_length,))\n",
    "    l = BatchNormalization(axis = 1)(input_features)\n",
    "    l = Dense(100)(input_features)\n",
    "    l = Activation('relu')(l)\n",
    "    l = BatchNormalization(axis = 1)(l)\n",
    "    l = Dropout(0.5)(l)\n",
    "    outputs = Dense(output_length, activation='softmax')(l)\n",
    "\n",
    "    model = SklearnWrapperKerasEstimator(inputs=[input_features], outputs=outputs)\n",
    "    adam = Adam(lr=0.01, amsgrad=True)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['mean_squared_error', 'acc'])\n",
    "\n",
    "    return model\n",
    "  \n",
    "#nnclassifier = construct_simple_nn_classifier(input_length=X.shape[1], output_length=len(np.unique(y)))\n",
    "\n",
    "catboost = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.2,\n",
    "    custom_loss=['F1'],\n",
    "    random_seed=random_state,\n",
    "    verbose=0,\n",
    "    loss_function='MultiClass',\n",
    "    task_type='GPU',\n",
    "    devices='0',\n",
    "    class_weights=[0.55, .47, 0.5, 0.35, 0.7, 0.4, 0.25, 1., 0.6, 1., 1.]\n",
    ")\n",
    "\n",
    "fs_catboost = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LogisticRegression(solver='saga', penalty='l1', C=1., n_jobs=-1))),\n",
    "  ('classification', catboost)\n",
    "])\n",
    "\n",
    "fs_lgbm = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LogisticRegression(penalty='l1', C=1.))),\n",
    "  ('classification', lgb_class)\n",
    "])\n",
    "\n",
    "fs_catboost_plus_logreg = VotingClassifier([('fs_catboost', fs_catboost), ('logreg', logreg)], voting='soft')\n",
    "fs_catboost_plus_svc = VotingClassifier([('fs_catboost', fs_catboost), ('lsvc', SVC(random_state=random_state, C=0.001, probability=True))], voting='soft')\n",
    "fs_lgbm_plus_svc = VotingClassifier([('fs_lgbm', fs_lgbm), ('lsvc', SVC(random_state=random_state, C=0.001, probability=True))], voting='soft')\n",
    "\n",
    "#smt = SMOTE(random_state=random_state)\n",
    "#lsvc_smote = Pipeline([('smt', smt), ('lsvc', lsvc)])\n",
    "#logreg_smote = Pipeline([('smt', smt), ('logreg', logreg)])\n",
    "##nnclassifier_smote = Pipeline([('smt', smt), ('nnclassifier', nnclassifier)])\n",
    "\n",
    "name = lambda x : str(x).split('(')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vN2D-XdQWnWZ"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(unique_type_list))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n",
    "    return model\n",
    "            \n",
    "def train_stratified(models, X, y, add_idf=False, nsplits=5, confusion=False):\n",
    "    fig_i = 0\n",
    "    kf = StratifiedShuffleSplit(n_splits=nsplits, test_size=0.1, random_state=random_state)\n",
    "    \n",
    "    # Store folds score for each classifier in a dictionary\n",
    "    dico_score = {}\n",
    "    dic_report = {}\n",
    "\n",
    "    for num, model in enumerate(models):\n",
    "        dico_score[num] = [[],[],[]]  # macro_f1, micro_f1, accuracy\n",
    "        dic_report[num] = []\n",
    "        \n",
    "    _useless = []\n",
    "    \n",
    "    # Stratified Split\n",
    "    for train, test in kf.split(X, y):\n",
    "        X_train, X_test, y_train, y_test = X.iloc[train], X.iloc[test], y[train], y[test]\n",
    "        \n",
    "        for num, model in enumerate(models):\n",
    "            print(num, '>>', name(model))\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "#             fi = np.array(model.feature_importances_)\n",
    "#             sorted_idx = np.argsort(fi)\n",
    "#             print('nonzero:', np.count_nonzero(fi))\n",
    "#             dd = pd.DataFrame({'Feature': np.array(X.keys())[sorted_idx], 'Importance': fi[sorted_idx][::-1]})\n",
    "#             dd = dd[dd['Importance'] == 0]\n",
    "#             _useless.append(dd.Feature.tolist())\n",
    "\n",
    "            preds = model.predict(X_test)\n",
    "            macroscore = f1_score(y_test, preds, average='macro')\n",
    "            print('%s macro F score: %s' % (name(model), macroscore))\n",
    "            dico_score[num][0].append(macroscore)\n",
    "            microscore = f1_score(y_test, preds, average='micro')\n",
    "            print('%s micro F score: %s' % (name(model), microscore))\n",
    "            dico_score[num][1].append(microscore)\n",
    "            \n",
    "            dic_report[num].append(metrics.classification_report(lab_encoder.inverse_transform(y_test), \n",
    "                                                                 lab_encoder.inverse_transform(preds), \n",
    "                                                                 output_dict=True))\n",
    "\n",
    "            if confusion:\n",
    "                cnf_matrix = confusion_matrix(lab_encoder.inverse_transform(y_test), \n",
    "                                              lab_encoder.inverse_transform(preds),\n",
    "                                              labels=lab_encoder.classes_)\n",
    "                np.set_printoptions(precision=2)\n",
    "                plt.figure(fig_i)\n",
    "                fig_i += 1\n",
    "                plot_confusion_matrix(cnf_matrix, normalize=True, classes=lab_encoder.classes_,\n",
    "                                      title=('Confusion matrix %s' % name(model)))\n",
    "        \n",
    "    return dico_score, _useless, dic_report\n",
    "  \n",
    "def macro(results):\n",
    "    return np.mean(results[0]), np.std(results[0])\n",
    "\n",
    "def micro(results):\n",
    "    return np.mean(results[1]), np.std(results[1])\n",
    "\n",
    "def describe_cv_result(results):\n",
    "    for model in results.keys():\n",
    "        print(model, 'macro f1', macro(results[model]))\n",
    "        print(model, 'micro f1', micro(results[model]))\n",
    "\n",
    "def describe_reports(reports):\n",
    "    for model in reports.keys():\n",
    "        frames = []\n",
    "    for result in reports[model]:\n",
    "        frames.append(pd.DataFrame.from_dict(result, orient='columns'))\n",
    "    conc = pd.concat(frames)\n",
    "    print(conc.groupby(by=conc.index, axis=0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results, classifiers, reports = train_stratified([logreg], X, y, nsplits=5, confusion=True)\n",
    "describe_cv_result(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_reports(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the cool one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.train_test_split import split_data\n",
    "\n",
    "train, test = split_data('data/', 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_state = 41\n",
    "\n",
    "train_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for file in train:\n",
    "    train_samples.append(pd.read_pickle(file.replace('.edus', '.gold.pkl')))\n",
    "\n",
    "for file in test:\n",
    "    test_samples.append(pd.read_pickle(file.replace('.edus', '.gold.pkl')))\n",
    "\n",
    "train_samples = pd.concat(train_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "test_samples = pd.concat(test_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'category_id'\n",
    "\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['cause-effect_r', 'effect_r'], 'cause_r')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['interpretation-evaluation_r', 'conclusion_r'], 'evaluation_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['cause-effect_r', 'effect_r'], 'cause_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['interpretation-evaluation_r', 'conclusion_r'], 'evaluation_r')\n",
    "\n",
    "y_stat = train_samples[TARGET].value_counts()\n",
    "drop_ys = y_stat[y_stat < 100].index\n",
    "\n",
    "for dy in drop_ys:\n",
    "    train_samples = train_samples[train_samples[TARGET] != dy]\n",
    "    \n",
    "y_stat = test_samples[TARGET].value_counts()\n",
    "drop_ys = y_stat[y_stat < 100].index\n",
    "\n",
    "for dy in drop_ys:\n",
    "    test_samples = test_samples[test_samples[TARGET] != dy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[TARGET].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array([5742., 5500., 2086., 1580., 1331., 1316., 1184., 1141., 1027., \n",
    "                   924., 621., 616., 601., 397., 287., 285., 201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = pickle.load(open('models/label_predictor/drop_columns.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'category_id'\n",
    "y_train, X_train = train_samples[TARGET].to_frame(), train_samples.drop(TARGET, axis=1).drop(columns=drop_columns)\n",
    "y_test, X_test = test_samples[TARGET].to_frame(), test_samples.drop(TARGET, axis=1).drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_scaled_np = scaler.transform(X_train)\n",
    "X_train = pd.DataFrame(X_scaled_np, index=X_train.index)#, columns=X.columns)\n",
    "\n",
    "X_scaled_np = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_scaled_np, index=X_test.index)#, columns=X.columns)\n",
    "\n",
    "pickle.dump(scaler, open('models/label_predictor/scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "y_train = lab_encoder.fit_transform(y_train)\n",
    "pickle.dump(lab_encoder, open('models/label_predictor/label_encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.2,\n",
    "    custom_loss=['F1'],\n",
    "    random_seed=random_state,\n",
    "    verbose=0,\n",
    "    loss_function='MultiClass',\n",
    "    task_type='GPU',\n",
    "    devices='0',\n",
    "    class_weights=counts / counts[-1]\n",
    ")\n",
    "\n",
    "fs_catboost = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LogisticRegression(solver='saga', penalty='l1', C=1., n_jobs=-1))),\n",
    "  ('classification', catboost)\n",
    "])\n",
    "\n",
    "logreg = LogisticRegression(random_state=random_state,\n",
    "                            solver='lbfgs',\n",
    "                            n_jobs=-1,\n",
    "                            C=0.001,\n",
    "                            multi_class='multinomial',\n",
    "                            class_weight='balanced')\n",
    "\n",
    "fs_catboost_plus_logreg = VotingClassifier([('fs_catboost', fs_catboost), ('logreg', logreg)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_catboost_plus_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(fs_catboost_plus_logreg, open('models/label_predictor/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fs_catboost_plus_logreg = pickle.load(open('models/label_predictor/model.pkl', 'rb'))\n",
    "lab_encoder = pickle.load(open('models/label_predictor/label_encoder.pkl', 'rb'))\n",
    "scaler = pickle.load(open('models/label_predictor/scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = lab_encoder.inverse_transform(fs_catboost_plus_logreg.predict(scaler.transform(X_test)))\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_test.values, predicted, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_test.values, predicted, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_test.values, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = lab_encoder.inverse_transform(fs_catboost_plus_logreg.predict(scaler.transform(X_test)))\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_test.values, predicted, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_test.values, predicted, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_test.values, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KO7mkyUvherq"
   },
   "source": [
    "### 4. Important features exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = []\n",
    "for classifier in classifiers:\n",
    "    fi = np.array(classifier.feature_importances_)\n",
    "    sorted_idx = np.argsort(fi)\n",
    "    print('nonzero:', np.count_nonzero(fi))\n",
    "\n",
    "    pd.set_option('display.max_rows', 150)\n",
    "    dd = pd.DataFrame({'Feature': np.array(X.keys())[sorted_idx], 'Importance': fi[sorted_idx][::-1]})\n",
    "    dd = dd[dd['Importance'] == 0]\n",
    "    useless.append(dd.Feature.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifiers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifiers[0].estimators[0][1]._final_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_UifKiN0aN4X",
    "outputId": "8bbf2313-99d0-496c-ba5b-b59a51f5468f"
   },
   "outputs": [],
   "source": [
    "fi = np.array(classifier.feature_importances_)\n",
    "sorted_idx = np.argsort(fi)\n",
    "print(np.count_nonzero(fi))\n",
    "\n",
    "pd.set_option('display.max_rows', 150)\n",
    "dd = pd.DataFrame({'Feature': np.array(X.keys())[sorted_idx], 'Importance': fi[sorted_idx][::-1]})\n",
    "dd = dd[dd['Importance'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_import = dd.Feature.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_import.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[key for key in null_import if '_count_y' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in null_import if '_count_x' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "F62mE9k1nMM6",
    "outputId": "a905caac-bfa3-4a00-a34f-b6bb3487b09e"
   },
   "outputs": [],
   "source": [
    "lexical = pd.concat([dd[dd.Feature.str.contains('tf_idf')], \n",
    "                     dd[dd.Feature.str.contains('upper_')],\n",
    "                     dd[dd.Feature.str.contains('jac')],\n",
    "                     dd[dd.Feature.str.contains('len')]]).drop_duplicates()\n",
    "lexical = list(lexical.Feature)\n",
    "print(len(lexical), lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3738
    },
    "colab_type": "code",
    "id": "qquG0IPsp3bV",
    "outputId": "91cd522b-4320-4c84-a08e-2e8f69eff935"
   },
   "outputs": [],
   "source": [
    "morphosynt = pd.concat([dd[dd.Feature.str.islower() == False],\n",
    "                        dd[dd.Feature.str.contains('morph')]]).drop_duplicates()\n",
    "morphosynt = morphosynt.replace(['tf_idf_', 'upper', 'len_', 'stopwords'], np.NaN, regex=True).dropna()\n",
    "morphosynt = morphosynt[morphosynt.Feature.str[-2:] != '_X']\n",
    "morphosynt = morphosynt[morphosynt.Feature.str[-2:] != '_Y']\n",
    "\n",
    "morphosynt = list(morphosynt.Feature)\n",
    "print(len(morphosynt), morphosynt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4759
    },
    "colab_type": "code",
    "id": "I7ZcRUBDsyYX",
    "outputId": "7b19a1f3-cd41-475c-b783-3a76bc0e0c38"
   },
   "outputs": [],
   "source": [
    "textual = pd.concat([dd[dd.Feature.str[-2:] == '_X'],\n",
    "                     dd[dd.Feature.str[-2:] == '_Y'],\n",
    "                     dd[dd.Feature.str.contains('stopwords')]])\n",
    "textual2 = pd.concat([dd[dd.Feature.str.contains('first')],\n",
    "                      dd[dd.Feature.str.contains('last')]])\n",
    "textual2 = textual2[textual2.Feature.str.islower()]\n",
    "textual = pd.concat([textual, textual2])\n",
    "textual = textual.replace(['tf_idf_', 'upper', 'len_', 'fPOS'], np.NaN, regex=True).dropna()\n",
    "\n",
    "textual = list(textual.Feature)\n",
    "print(len(textual), textual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-c_AkAvbnN3f"
   },
   "outputs": [],
   "source": [
    "textX = textual[textual.Feature.str[-2:] == '_x']\n",
    "textY = textual[textual.Feature.str[-2:] == '_y']\n",
    "firstPX = textX[textX.Feature.str.contains('first_pair')]\n",
    "firstPY = textY[textY.Feature.str.contains('first_pair')]\n",
    "lastPX = textX[textX.Feature.str.contains('last_pair')]\n",
    "lastPY = textY[textY.Feature.str.contains('last_pair')]\n",
    "countPX = textual[textual.Feature.str.contains('_X')]\n",
    "countPY = textual[textual.Feature.str.contains('_Y')]\n",
    "\n",
    "len(firstPX), len(firstPY), len(lastPX), len(lastPY), len(countPX), len(countPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5sKNSaD3tGDU",
    "outputId": "3fc00703-5430-4c2f-aeaa-1b25821fc116"
   },
   "outputs": [],
   "source": [
    "for _ in [lexical, morphosynt, textual]:\n",
    "    print(len(_) / dd.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=1800,\n",
    "    learning_rate=0.2,\n",
    "    custom_loss=['F1'],\n",
    "    random_seed=random_state,\n",
    "    verbose=2,\n",
    "    loss_function='MultiClass',\n",
    "    task_type='GPU'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    feature: 0 for feature in X.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#result = pd.DataFrame({'feature': X.keys(), 'score': np.zeros(X.shape[1])})\n",
    "\n",
    "kf = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "for train, test in kf.split(X, y):\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train], X.iloc[test], y[train], y[test]\n",
    "    model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "    fi = np.array(model.feature_importances_)\n",
    "    sorted_idx = np.argsort(fi)\n",
    "    dd = pd.DataFrame({'Feature': np.array(X.keys())[sorted_idx], 'Importance': fi[sorted_idx][::-1]})\n",
    "    dd = dd[dd['Importance'] > 0].Feature.values\n",
    "    for feat in dd:\n",
    "        result[feat] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rr = pd.DataFrame.from_dict(result, orient='index')\n",
    "rr[rr[0] > 0].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr[rr[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rr[rr[0] == 0].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XL9qxhZeGdB1"
   },
   "source": [
    "### 5. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install feature_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekCgcf89bOnt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from feature_selector import FeatureSelector\n",
    "\n",
    "fs = FeatureSelector(data=X, labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfzngIGObVPi"
   },
   "outputs": [],
   "source": [
    "fs.identify_missing(missing_threshold=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNGYIPB0cPdW"
   },
   "source": [
    "####  - Find features with single unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aX09NNk6bkJw"
   },
   "outputs": [],
   "source": [
    "fs.identify_single_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OD3S5rIwbntV"
   },
   "outputs": [],
   "source": [
    "# list of single unique values features\n",
    "fs.ops['single_unique']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMD4jEJScaFy"
   },
   "source": [
    "#### - Find collinear features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:, :10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzuD1-ITb5c2"
   },
   "outputs": [],
   "source": [
    "fs = FeatureSelector(data=X.iloc[:, 1400:1800], labels=y)\n",
    "fs.identify_collinear(correlation_threshold=.98, one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of collinear features to remove\n",
    "fs.ops['collinear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tom = fs.corr_matrix[['last_pair_извест(?:ен|но)_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = tom > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tom[aa['last_pair_извест(?:ен|но)_x']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH78XWkQJKNj"
   },
   "source": [
    "### 6. Symmetry regressor implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITaPlWDsDHVO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(PATH+DATAFILE)\n",
    "TARGET = 'category_id'\n",
    "\n",
    "def get_classes(df, y_name, classes):\n",
    "    res = []\n",
    "    for class_name in classes:\n",
    "        res.append(df[df[y_name] == class_name])\n",
    "\n",
    "    return pd.concat(res).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "for_bin_regr = [\n",
    "    'joint_m',\n",
    "    'elaboration_r',\n",
    "    'restatement_m',\n",
    "    'concession_r',\n",
    "    'solutionhood_r',\n",
    "    'antithesis_r',\n",
    "]\n",
    "\n",
    "df_bin = get_classes(df, 'category_id', for_bin_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DfCAl1vqKUd3"
   },
   "outputs": [],
   "source": [
    "TARGET = 'category_id'\n",
    "\n",
    "names = list(df[TARGET].unique())\n",
    "\n",
    "replace_map = {\n",
    "    TARGET: {\n",
    "        k: v for k, v in [(name, name[-1]) for name in names]\n",
    "    }\n",
    "}\n",
    "\n",
    "df_bin = df_bin.replace(replace_map).replace({TARGET: {'r': 0, 'm': 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Q0COb1PMl3q"
   },
   "outputs": [],
   "source": [
    "df_bin.category_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHridQW5DPBJ"
   },
   "outputs": [],
   "source": [
    "TARGET = 'category_id'\n",
    "\n",
    "y_bin, X_bin = df_bin[TARGET].to_frame(), df_bin.drop(TARGET, axis=1).drop(columns=['snippet_x', 'snippet_y', 'snippet_x_tmp', 'snippet_y_tmp', 'order', 'filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdJ9NzPoCmOn"
   },
   "outputs": [],
   "source": [
    "lgbm_param_bin =  {\n",
    "    'tree_learner': 'feature',\n",
    "    'task': 'train',\n",
    "    'random_state': random_state,\n",
    "    'metric': 'binary_logloss',\n",
    "    'feature_fraction': 0.8,\n",
    "    'colsample_bytree' : 0.8,\n",
    "    'boosting_type': 'dart',\n",
    "    'application': 'regression',\n",
    "    'num_iterations': 150\n",
    "}\n",
    "\n",
    "lgb_bin_class = lgb.LGBMClassifier(**lgbm_param_bin)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bin, y_bin, shuffle=True, test_size=.1, random_state=random_state)\n",
    "\n",
    "feature_selector = SelectFromModel(LogisticRegression(class_weight='balanced', solver='liblinear', penalty='l1'))\n",
    "model_single = Pipeline([('feature_selector', feature_selector), \n",
    "                         ('classifier', lgb_bin_class)])\n",
    "\n",
    "model = BaggingClassifier(base_estimator=model_single, \n",
    "                          n_estimators=7,\n",
    "                          max_samples=1.0, \n",
    "                          max_features=0.6, \n",
    "                          bootstrap=True, \n",
    "                          random_state=random_state)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wGHqjVz4FSOx"
   },
   "outputs": [],
   "source": [
    "filename = 'symmetry_predictor.save'\n",
    "pickle.dump(model, open(PATH + filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLWoep2DHdLm"
   },
   "source": [
    "### 7. Classifiers parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "YEaJP1yHHdLn",
    "outputId": "15372852-7ab9-4f65-de3f-23b355e873ac",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.0001, 0.005, 0.001] }\n",
    "clf = GridSearchCV(LinearSVC(random_state=random_state), param_grid, cv=5, verbose=2)\n",
    "clf.fit(X.values, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h4fjXFHCd49-",
    "outputId": "eb28f226-7287-41a8-a90f-56e58c38425b"
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPuB901JHdLs"
   },
   "source": [
    "#### - RandomSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LOPP8_3HdLt"
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier()\n",
    "\n",
    "lgbm_param =  {\n",
    "    'task': ['train'],\n",
    "    'boosting_type': ['gbdt'],\n",
    "    'objective': ['multiclass'],\n",
    "    'num_class': [6,],\n",
    "    'metric': ['multi_error'],\n",
    "    \"learning_rate\": list(np.arange(0.05, 1, 0.25)),\n",
    "    \"num_leaves\": list(range(32, 128, 16)),\n",
    "    \"max_depth\": list(range(2, 17, 2)),\n",
    "    \"reg_alpha\": [.15],\n",
    "    \"reg_lambda\": [.15],\n",
    "}\n",
    "\n",
    "clf = RandomSearchCV(lgb_model, lgbm_param, n_jobs=8, cv=5)\n",
    "clf.fit(scaling.transform(X.values), y.values.ravel())\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid score:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuclearity types classification\n",
    "\n",
    "1. Data cleaning: obtain the data and clean it (X, y)\n",
    " - transformations: normalization, scaling\n",
    "2. Classifiers & CV-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(PATH+DATAFILE)\n",
    "TARGET = 'order'\n",
    "df[TARGET].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_type_list = df[TARGET].unique()\n",
    "replace_map = {TARGET : {k: v for k,v in zip(unique_type_list, list(range(0,len(unique_type_list))))}}\n",
    "y, X = df[TARGET].to_frame(), df.drop(TARGET, axis=1).drop(columns=['snippet_x', 'snippet_y', 'snippet_x_tmp', 'snippet_y_tmp', 'filename', 'category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = MinMaxScaler(feature_range=(-1,1)).fit(X)\n",
    "scl = StandardScaler().fit(X.values)\n",
    "\n",
    "X_scaled_np = scl.transform(X.values)\n",
    "X_scaled_df = pd.DataFrame(X_scaled_np, index=X.index, columns=X.columns)\n",
    "\n",
    "X = X_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Classifiers & CV-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(random_state=random_state, C=0.001)\n",
    "logreg = LogisticRegression(random_state=random_state,\n",
    "                            solver='lbfgs',\n",
    "                            n_jobs=8,\n",
    "                            C=0.001,\n",
    "                            multi_class='auto')\n",
    "\n",
    "lgbm_param =  {\n",
    "    'tree_learner': 'feature',\n",
    "    'task': 'train',\n",
    "    'scale_pos_weight': 155,\n",
    "    'reg_lambda': 0.11,\n",
    "    'reg_alpha': 0.11,\n",
    "    'random_state': random_state,\n",
    "    'num_leaves': 36,\n",
    "    'num_class': 3,\n",
    "    'min_split_gain': 0.76,\n",
    "    'min_child_weight': 0.11,\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.45,\n",
    "    'boosting_type': 'dart',\n",
    "    'bagging_fraction': 0.9,\n",
    "    'application': 'multiclass',\n",
    "    'num_iterations': 500,\n",
    "}\n",
    "lgb_class = lgb.LGBMClassifier(**lgbm_param)\n",
    "     \n",
    "lgbm_plus_bagger_lsvc = VotingClassifier([('LGBM', lgb_class), ('bagger', bagger_lsvc)], voting='soft')\n",
    "\n",
    "def construct_simple_nn_classifier(input_length, output_length):\n",
    "    input_features = Input(shape=(input_length,))\n",
    "    l = Dense(100, kernel_initializer='he_uniform')(input_features)\n",
    "    l = Activation('relu')(l)\n",
    "    l = BatchNormalization(axis = 1)(l)\n",
    "    l = Dropout(0.5)(l)\n",
    "    outputs = Dense(output_length, activation='softmax')(l)\n",
    "\n",
    "    model = SklearnWrapperKerasEstimator(inputs=[input_features], outputs=outputs)\n",
    "    adam = Adam(lr=0.001, amsgrad=True)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['mean_squared_error', 'acc'])\n",
    "\n",
    "    return model\n",
    "  \n",
    "nnclassifier = construct_simple_nn_classifier(input_length=X.shape[1], output_length=len(np.unique(y)))\n",
    "\n",
    "catboost = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.1,\n",
    "    custom_loss=['F1'],\n",
    "    random_seed=random_state,\n",
    "    verbose=0,\n",
    "    loss_function='MultiClass',\n",
    "    task_type='GPU',\n",
    ")\n",
    "\n",
    "fs_catboost = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LogisticRegression(penalty='l1', C=1.))),\n",
    "  ('classification', catboost)\n",
    "])\n",
    "\n",
    "fs_lgbm = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LogisticRegression(penalty='l1', C=1.))),\n",
    "  ('classification', lgb_class)\n",
    "])\n",
    "\n",
    "nnclassifier_smote = Pipeline([('smt', smt), ('nnclassifier', nnclassifier)])\n",
    "\n",
    "name = lambda x : str(x).split('(')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, classifiers, reports = train_stratified([nnclassifier_smote, \n",
    "                                                  logreg, \n",
    "                                                  lsvc, \n",
    "                                                  catboost, \n",
    "                                                  lgb_class, \n",
    "                                                  fs_catboost, \n",
    "                                                  fs_lgbm], X, y, nsplits=5, confusion=False)\n",
    "\n",
    "describe_cv_result(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre classification and feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filename = df.filename.map(lambda row: row.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = df['filename'].to_frame(), df.drop(\n",
    "    columns=[TARGET, 'snippet_x', 'snippet_y', 'snippet_x_tmp', 'snippet_y_tmp', \n",
    "             'filename', 'order', 'postags_x', 'postags_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(\n",
    "    iterations=1800,\n",
    "    learning_rate=0.2,\n",
    "    custom_loss=['F1'],\n",
    "    random_seed=random_state,\n",
    "    verbose=2,\n",
    "    loss_function='MultiClass',\n",
    "    task_type='GPU',\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "catboost.fit(X_train, y_train, eval_set=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(catboost.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = np.array(catboost.feature_importances_)\n",
    "sorted_idx = np.argsort(fi)\n",
    "print(np.count_nonzero(fi))\n",
    "\n",
    "pd.set_option('display.max_rows', 150)\n",
    "dd = pd.DataFrame({'Feature': np.array(X.keys())[sorted_idx], 'Importance': fi[sorted_idx][::-1]})\n",
    "dd = dd[dd['Importance'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "XL9qxhZeGdB1",
    "EAiXKY8dnxQs",
    "-WGdV8VGcJUt",
    "WNGYIPB0cPdW",
    "WMD4jEJScaFy",
    "9idVoMLIBytW"
   ],
   "name": "experiments_ml.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
