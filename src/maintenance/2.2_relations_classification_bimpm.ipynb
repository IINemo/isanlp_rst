{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass relations classification used in tree building\n",
    "\n",
    "1. prepare train/test sets\n",
    "2. generate config files for bimpm model\n",
    "3. generate training/prediction script\n",
    "4. model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utils.file_reading import read_edus, read_gold, read_negative, read_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_sequence(sequence):\n",
    "    symbol_map = {\n",
    "        'x': '—Ö',\n",
    "        'X': 'X',\n",
    "        'y': '—É',\n",
    "        '‚Äî': '-',\n",
    "        '‚Äú': '¬´',\n",
    "        '‚Äò': '¬´',\n",
    "        '‚Äù': '¬ª',\n",
    "        '‚Äô': '¬ª',\n",
    "        'üòÜ': 'üòÑ',\n",
    "        'üòä': 'üòÑ',\n",
    "        'üòë': 'üòÑ',\n",
    "        'üòî': 'üòÑ',\n",
    "        'üòâ': 'üòÑ',\n",
    "        '‚ùó': 'üòÑ',\n",
    "        'ü§î': 'üòÑ',\n",
    "        'üòÖ': 'üòÑ',\n",
    "        '‚öì': 'üòÑ',\n",
    "        'Œµ': 'Œ±',\n",
    "        'Œ∂': 'Œ±',\n",
    "        'Œ∑': 'Œ±',\n",
    "        'Œº': 'Œ±',\n",
    "        'Œ¥': 'Œ±',\n",
    "        'Œª': 'Œ±',\n",
    "        'ŒΩ': 'Œ±',\n",
    "        'Œ≤': 'Œ±',\n",
    "        'Œ≥': 'Œ±',\n",
    "        '„Å®': 'Â∞ã',\n",
    "        '„ÅÆ': 'Â∞ã',\n",
    "        'Á•û': 'Â∞ã',\n",
    "        'Èö†': 'Â∞ã',\n",
    "        '„Åó': 'Â∞ã',\n",
    "    }\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for token in sequence.split():\n",
    "\n",
    "        for key, value in symbol_map.items():\n",
    "            token = token.replace(key, value)\n",
    "\n",
    "        for keyword in ['www', 'http']:\n",
    "            if keyword in token:\n",
    "                token = '_html_'\n",
    "\n",
    "        result.append(token)\n",
    "\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_samples(row):\n",
    "    if row.snippet_x[0] in (',', '.'):\n",
    "        row.snippet_x = row.snippet_x[1:].strip()\n",
    "    if row.snippet_y[0] in (',', '.'):\n",
    "        row.snippet_x += row.snippet_y[0]\n",
    "        row.snippet_y = row.snippet_y[1:].strip()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/label_predictor_lstm'\n",
    "! mkdir $MODEL_PATH\n",
    "\n",
    "TRAIN_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_train.tsv')\n",
    "DEV_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_dev.tsv')\n",
    "TEST_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. prepare train/test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.train_test_split import split_train_dev_test\n",
    "\n",
    "train, dev, test = split_train_dev_test('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "TARGET = 'category_id'\n",
    "random_state = 45\n",
    "train_samples = []\n",
    "\n",
    "for file in tqdm(train):\n",
    "    gold = read_gold(file.replace('.edus', ''), features=True)\n",
    "    gold['len_x'] = gold.tokens_x.map(len)\n",
    "    gold = gold[gold.len_x < MAX_LEN]\n",
    "    gold['len_y'] = gold.tokens_y.map(len)\n",
    "    gold = gold[gold.len_y < MAX_LEN]\n",
    "    gold['snippet_x'] = gold.tokens_x.map(lambda row: ' '.join(row))\n",
    "    gold['snippet_y'] = gold.tokens_y.map(lambda row: ' '.join(row))\n",
    "    gold = gold.apply(correct_samples, axis=1)\n",
    "    sample = gold[[TARGET, 'snippet_x', 'snippet_y', 'order', 'filename']]\n",
    "    sample = sample[sample.snippet_x.map(len) > 1]\n",
    "    sample = sample[sample.snippet_y.map(len) > 1]\n",
    "    train_samples.append(sample)\n",
    "\n",
    "train_samples = pd.concat(train_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "train_samples.reset_index(level=0, inplace=True)\n",
    "train_samples[TARGET] = train_samples[TARGET].replace([0.0], 'same-unit_m')\n",
    "train_samples['order'] = train_samples['order'].replace([0.0], 'NN')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "train_samples['relation'] = train_samples[TARGET].map(lambda row: row[:-1]) + train_samples['order']\n",
    "train_samples['relation'] = train_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "train_samples['relation'] = train_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "train_samples['relation'] = train_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "train_samples['relation'] = train_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                               'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "train_samples['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = train_samples['relation'].value_counts(normalize=True).values\n",
    "NUMBER_CLASSES = len(counts)\n",
    "print(\"number of classes:\", NUMBER_CLASSES)\n",
    "print(\"class weights:\")\n",
    "np.round(counts.min() / counts, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples['snippet_x'] = train_samples.snippet_x.map(_prepare_sequence)\n",
    "train_samples['snippet_y'] = train_samples.snippet_y.map(_prepare_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TRAIN_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dev/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 45\n",
    "dev_samples = []\n",
    "\n",
    "for file in tqdm(dev):\n",
    "    gold = read_gold(file.replace('.edus', ''), features=True)\n",
    "    gold['len_x'] = gold.tokens_x.map(len)\n",
    "    gold = gold[gold.len_x < MAX_LEN]\n",
    "    gold['len_y'] = gold.tokens_y.map(len)\n",
    "    gold = gold[gold.len_y < MAX_LEN]\n",
    "    gold['snippet_x'] = gold.tokens_x.map(lambda row: ' '.join(row))\n",
    "    gold['snippet_y'] = gold.tokens_y.map(lambda row: ' '.join(row))\n",
    "    gold = gold.apply(correct_samples, axis=1)\n",
    "    sample = gold[[TARGET, 'snippet_x', 'snippet_y', 'order']]\n",
    "    sample = sample[sample.snippet_x.map(len) > 1]\n",
    "    sample = sample[sample.snippet_y.map(len) > 1]\n",
    "    dev_samples.append(sample)\n",
    "\n",
    "dev_samples = pd.concat(dev_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "dev_samples.reset_index(level=0, inplace=True)\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace([0.0], 'same-unit_m')\n",
    "dev_samples['order'] = dev_samples['order'].replace([0.0], 'NN')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['motivation_r',], 'condition_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev_samples['relation'] = dev_samples[TARGET].map(lambda row: row[:-1]) + dev_samples['order']\n",
    "dev_samples['relation'].value_counts()\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                           'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "dev_samples['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_samples['snippet_x'] = dev_samples.snippet_x.map(_prepare_sequence)\n",
    "dev_samples['snippet_y'] = dev_samples.snippet_y.map(_prepare_sequence)\n",
    "dev_samples = dev_samples[dev_samples.snippet_x.map(len) > 0]\n",
    "dev_samples = dev_samples[dev_samples.snippet_y.map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(DEV_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_state = 45\n",
    "test_samples = []\n",
    "\n",
    "for file in tqdm(test):\n",
    "    gold = read_gold(file.replace('.edus', ''), features=True)\n",
    "    gold['len_x'] = gold.tokens_x.map(len)\n",
    "    gold = gold[gold.len_x < MAX_LEN]\n",
    "    gold['len_y'] = gold.tokens_y.map(len)\n",
    "    gold = gold[gold.len_y < MAX_LEN]\n",
    "    gold['snippet_x'] = gold.tokens_x.map(lambda row: ' '.join(row))\n",
    "    gold['snippet_y'] = gold.tokens_y.map(lambda row: ' '.join(row))\n",
    "    gold = gold.apply(correct_samples, axis=1)\n",
    "    sample = gold[[TARGET, 'snippet_x', 'snippet_y', 'order', 'filename']]\n",
    "    sample = sample[sample.snippet_x.map(len) > 1]\n",
    "    sample = sample[sample.snippet_y.map(len) > 1]\n",
    "    test_samples.append(sample)\n",
    "\n",
    "test_samples = pd.concat(test_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "test_samples.reset_index(level=0, inplace=True)\n",
    "test_samples[TARGET] = test_samples[TARGET].replace([0.0], 'same-unit_m')\n",
    "test_samples['order'] = test_samples['order'].replace([0.0], 'NN')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "test_samples['relation'] = test_samples[TARGET].map(lambda row: row[:-1]) + test_samples['order']\n",
    "test_samples['relation'].value_counts()\n",
    "test_samples['relation'] = test_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                           'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "print(test_samples['relation'].value_counts())\n",
    "test_samples['snippet_x'] = test_samples.snippet_x.map(_prepare_sequence)\n",
    "test_samples['snippet_y'] = test_samples.snippet_y.map(_prepare_sequence)\n",
    "test_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TEST_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_samples.head(2).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/customization_package/model/multiclass_bimpm.py\n",
    "\n",
    "\"\"\"\n",
    "BiMPM (Bilateral Multi-Perspective Matching) model implementation.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Optional, List, Any\n",
    "\n",
    "from overrides import overrides\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "from allennlp.common.checks import check_dimensions_match\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.modules import FeedForward, Seq2SeqEncoder, Seq2VecEncoder, TextFieldEmbedder\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.nn import InitializerApplicator, RegularizerApplicator\n",
    "from allennlp.nn import util\n",
    "from allennlp.training.metrics import CategoricalAccuracy, F1Measure\n",
    "\n",
    "from allennlp.modules.bimpm_matching import BiMpmMatching\n",
    "\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "@Model.register(\"multiclass_bimpm\")\n",
    "class BiMpm(Model):\n",
    "    \"\"\"\n",
    "    This ``Model`` augments with additional features the BiMPM model described in `Bilateral Multi-Perspective \n",
    "    Matching for Natural Language Sentences <https://arxiv.org/abs/1702.03814>`_ by Zhiguo Wang et al., 2017.\n",
    "    implemented in https://github.com/galsang/BIMPM-pytorch>`_.\n",
    "    Additional features are added before the feedforward classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab: Vocabulary,\n",
    "                 text_field_embedder: TextFieldEmbedder,\n",
    "                 matcher_word: BiMpmMatching,\n",
    "                 encoder1: Seq2SeqEncoder,\n",
    "                 matcher_forward1: BiMpmMatching,\n",
    "                 matcher_backward1: BiMpmMatching,\n",
    "                 encoder2: Seq2SeqEncoder,\n",
    "                 matcher_forward2: BiMpmMatching,\n",
    "                 matcher_backward2: BiMpmMatching,\n",
    "                 aggregator: Seq2VecEncoder,\n",
    "                 classifier_feedforward: FeedForward,\n",
    "                 dropout: float = 0.1,\n",
    "                 class_weights: list = [],\n",
    "                 encode_together: bool = False,\n",
    "                 encode_lstm: bool = True,\n",
    "                 initializer: InitializerApplicator = InitializerApplicator(),\n",
    "                 regularizer: Optional[RegularizerApplicator] = None) -> None:\n",
    "        super(BiMpm, self).__init__(vocab, regularizer)\n",
    "\n",
    "        self.text_field_embedder = text_field_embedder\n",
    "\n",
    "        self.matcher_word = matcher_word\n",
    "\n",
    "        self.encoder1 = encoder1\n",
    "        self.matcher_forward1 = matcher_forward1\n",
    "        self.matcher_backward1 = matcher_backward1\n",
    "\n",
    "        self.encoder2 = encoder2\n",
    "        self.matcher_forward2 = matcher_forward2\n",
    "        self.matcher_backward2 = matcher_backward2\n",
    "\n",
    "        self.aggregator = aggregator\n",
    "        \n",
    "        self.encode_together = encode_together\n",
    "        self.encode_lstm = encode_lstm\n",
    "        \n",
    "        matching_dim = self.matcher_word.get_output_dim(\n",
    "            ) + self.text_field_embedder.get_output_dim()\n",
    "        \n",
    "        if self.encode_lstm:\n",
    "            matching_dim += self.matcher_forward1.get_output_dim(\n",
    "            ) + self.matcher_backward1.get_output_dim(\n",
    "            ) + self.matcher_forward2.get_output_dim(\n",
    "            ) + self.matcher_backward2.get_output_dim(\n",
    "            )\n",
    "\n",
    "#         check_dimensions_match(matching_dim, self.aggregator.get_input_dim(),\n",
    "#                                \"sum of dim of all matching layers\", \"aggregator input dim\")\n",
    "\n",
    "        self.classifier_feedforward = classifier_feedforward\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        if class_weights:\n",
    "            self.class_weights = class_weights\n",
    "        else:\n",
    "            self.class_weights = [1.] * self.classifier_feedforward.get_output_dim()\n",
    "            \n",
    "        self.metrics = {\"accuracy\": CategoricalAccuracy(),\n",
    "                        \"f1_rel0\": F1Measure(0),\n",
    "                        \"f1_rel1\": F1Measure(1),\n",
    "                        \"f1_rel2\": F1Measure(2)}\n",
    "\n",
    "        self.loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(self.class_weights))\n",
    "\n",
    "        initializer(self)\n",
    "\n",
    "    @overrides\n",
    "    def forward(self,  # type: ignore\n",
    "                premise: Dict[str, torch.LongTensor],\n",
    "                hypothesis: Dict[str, torch.LongTensor],\n",
    "                label: torch.LongTensor = None,\n",
    "                metadata: List[Dict[str, Any]] = None  # pylint:disable=unused-argument\n",
    "               ) -> Dict[str, torch.Tensor]:\n",
    "        # pylint: disable=arguments-differ\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        premise : Dict[str, torch.LongTensor]\n",
    "            The premise from a ``TextField``\n",
    "        hypothesis : Dict[str, torch.LongTensor]\n",
    "            The hypothesis from a ``TextField``\n",
    "        label : torch.LongTensor, optional (default = None)\n",
    "            The label for the pair of the premise and the hypothesis\n",
    "        metadata : ``List[Dict[str, Any]]``, optional, (default = None)\n",
    "            Additional information about the pair\n",
    "        Returns\n",
    "        -------\n",
    "        An output dictionary consisting of:\n",
    "        logits : torch.FloatTensor\n",
    "            A tensor of shape ``(batch_size, num_labels)`` representing unnormalised log\n",
    "            probabilities of the entailment label.\n",
    "        loss : torch.FloatTensor, optional\n",
    "            A scalar loss to be optimised.\n",
    "        \"\"\"\n",
    "        \n",
    "        def encode_pair(x1, x2, mask1=None, mask2=None):\n",
    "            _joined_pair: Dict[str, torch.LongTensor] = {}\n",
    "            \n",
    "            for key in premise.keys():\n",
    "                bsz = premise[key].size(0)\n",
    "                x1_len, x2_len = premise[key].size(1), hypothesis[key].size(1)\n",
    "                sep = torch.empty([bsz, 1], dtype=torch.long, device=premise[key].device)\n",
    "                sep.data.fill_(0) # 2 is the id for </s>\n",
    "                \n",
    "                x = torch.cat([premise[key], hypothesis[key]], dim=1)\n",
    "                _joined_pair[key] = x\n",
    "                \n",
    "            x_output = self.dropout(self.text_field_embedder(_joined_pair))\n",
    "            return x_output[:, :x1_len], x_output[:, -x2_len:], mask1, mask2\n",
    "\n",
    "        mask_premise = util.get_text_field_mask(premise)\n",
    "        mask_hypothesis = util.get_text_field_mask(hypothesis)\n",
    "        \n",
    "        if self.encode_together:\n",
    "            embedded_premise, embedded_hypothesis, _, _ = encode_pair(premise, hypothesis)\n",
    "        else:\n",
    "            embedded_premise = self.dropout(self.text_field_embedder(premise))\n",
    "            embedded_hypothesis = self.dropout(self.text_field_embedder(hypothesis))\n",
    "\n",
    "        # embedding and encoding of the premise\n",
    "        encoded_premise1 = self.dropout(self.encoder1(embedded_premise, mask_premise))\n",
    "        encoded_premise2 = self.dropout(self.encoder2(encoded_premise1, mask_premise))\n",
    "\n",
    "        # embedding and encoding of the hypothesis\n",
    "        encoded_hypothesis1 = self.dropout(self.encoder1(embedded_hypothesis, mask_hypothesis))\n",
    "        encoded_hypothesis2 = self.dropout(self.encoder2(encoded_hypothesis1, mask_hypothesis))\n",
    "        \n",
    "        matching_vector_premise: List[torch.Tensor] = []\n",
    "        matching_vector_hypothesis: List[torch.Tensor] = []\n",
    "\n",
    "        def add_matching_result(matcher, encoded_premise, encoded_hypothesis):\n",
    "            # utility function to get matching result and add to the result list\n",
    "            matching_result = matcher(encoded_premise, mask_premise, encoded_hypothesis, mask_hypothesis)\n",
    "            matching_vector_premise.extend(matching_result[0])\n",
    "            matching_vector_hypothesis.extend(matching_result[1])\n",
    "\n",
    "        # calculate matching vectors from word embedding, first layer encoding, and second layer encoding\n",
    "        add_matching_result(self.matcher_word, embedded_premise, embedded_hypothesis)\n",
    "        half_hidden_size_1 = self.encoder1.get_output_dim() // 2\n",
    "        add_matching_result(self.matcher_forward1,\n",
    "                            encoded_premise1[:, :, :half_hidden_size_1],\n",
    "                            encoded_hypothesis1[:, :, :half_hidden_size_1])\n",
    "        add_matching_result(self.matcher_backward1,\n",
    "                            encoded_premise1[:, :, half_hidden_size_1:],\n",
    "                            encoded_hypothesis1[:, :, half_hidden_size_1:])\n",
    "\n",
    "        half_hidden_size_2 = self.encoder2.get_output_dim() // 2\n",
    "        add_matching_result(self.matcher_forward2,\n",
    "                            encoded_premise2[:, :, :half_hidden_size_2],\n",
    "                            encoded_hypothesis2[:, :, :half_hidden_size_2])\n",
    "        add_matching_result(self.matcher_backward2,\n",
    "                            encoded_premise2[:, :, half_hidden_size_2:],\n",
    "                            encoded_hypothesis2[:, :, half_hidden_size_2:])\n",
    "\n",
    "        # concat the matching vectors\n",
    "        matching_vector_cat_premise = self.dropout(torch.cat(matching_vector_premise, dim=2))\n",
    "        matching_vector_cat_hypothesis = self.dropout(torch.cat(matching_vector_hypothesis, dim=2))\n",
    "\n",
    "        # aggregate the matching vectors\n",
    "        aggregated_premise = self.dropout(self.aggregator(matching_vector_cat_premise, mask_premise))\n",
    "        aggregated_hypothesis = self.dropout(self.aggregator(matching_vector_cat_hypothesis, mask_hypothesis))\n",
    "\n",
    "        # encode additional information\n",
    "        #batch_size, _ = aggregated_premise.size()\n",
    "        #encoded_meta = metadata.float().view(batch_size, -1)\n",
    "        \n",
    "        # the final forward layer\n",
    "        logits = self.classifier_feedforward(torch.cat([aggregated_premise, aggregated_hypothesis], dim=-1))\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        output_dict = {'logits': logits, \"probs\": probs}\n",
    "        \n",
    "        if label is not None:\n",
    "            loss = self.loss(logits, label)\n",
    "            for metric in self.metrics.values():\n",
    "                metric(logits, label)\n",
    "            output_dict[\"loss\"] = loss\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Converts indices to string labels, and adds a ``\"label\"`` key to the result.\n",
    "        \"\"\"\n",
    "        predictions = output_dict[\"probs\"].cpu().data.numpy()\n",
    "        argmax_indices = numpy.argmax(predictions, axis=-1)\n",
    "        labels = [self.vocab.get_token_from_index(x, namespace=\"labels\")\n",
    "                  for x in argmax_indices]\n",
    "        output_dict['label'] = labels\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = {\n",
    "            \"f1_rel0\": self.metrics[\"f1_rel0\"].get_metric(reset=reset)[2],\n",
    "            \"f1_rel1\": self.metrics[\"f1_rel1\"].get_metric(reset=reset)[2],\n",
    "            \"f1_rel2\": self.metrics[\"f1_rel2\"].get_metric(reset=reset)[2],\n",
    "            \"accuracy\": self.metrics[\"accuracy\"].get_metric(reset=reset)\n",
    "        }\n",
    "        metrics[\"f1_top3\"] = numpy.mean([metrics[\"f1_rel0\"], metrics[\"f1_rel1\"], metrics[\"f1_rel2\"]])\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $MODEL_PATH/config_bert.json\n",
    "\n",
    "// Configuration for a sentence matching model based on:\n",
    "//   Wang, Zhiguo, Wael Hamza, and Radu Florian. \"Bilateral multi-perspective matching for natural language sentences.\"\n",
    "//   Proceedings of the 26th International Joint Conference on Artificial Intelligence. 2017.\n",
    "\n",
    "{\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": \"quora_paraphrase\",\n",
    "    \"lazy\": false,\n",
    "    \"token_indexers\": {\n",
    "      \"bert\": {\n",
    "          \"type\": \"bert-pretrained\",\n",
    "          \"pretrained_model\": \"rubert_cased_L-12_H-768_A-12_pt\",\n",
    "          \"do_lowercase\": false,\n",
    "          \"use_starting_offsets\": true\n",
    "      },\n",
    "      \"token_characters\": {\n",
    "          \"type\": \"characters\",\n",
    "          \"min_padding_length\": 1\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"train_data_path\": \"label_predictor_lstm/nlabel_cf_train.tsv\",\n",
    "  \"validation_data_path\": \"label_predictor_lstm/nlabel_cf_dev.tsv\",\n",
    "  \"test_data_path\": \"label_predictor_lstm/nlabel_cf_test.tsv\",\n",
    "  \"model\": {\n",
    "    \"type\": \"bimpm\",\n",
    "    \"dropout\": 0.1,\n",
    "    \"text_field_embedder\": {\n",
    "        \"allow_unmatched_keys\": true,\n",
    "        \"embedder_to_indexer_map\": {\n",
    "            \"bert\": [\"bert\", \"bert-offsets\"],\n",
    "            \"token_characters\": [\"token_characters\"],\n",
    "        },\n",
    "        \"token_embedders\": {\n",
    "            \"bert\": {\n",
    "                \"type\": \"bert-pretrained\",\n",
    "                \"pretrained_model\": \"rubert_cased_L-12_H-768_A-12_pt\",\n",
    "            },\n",
    "            \"token_characters\": {\n",
    "                \"type\": \"character_encoding\",\n",
    "                \"embedding\": {\n",
    "                    \"embedding_dim\": 20,\n",
    "                    \"padding_index\": 0\n",
    "                },\n",
    "                \"encoder\": {\n",
    "                    \"type\": \"gru\",\n",
    "                    \"input_size\": 20,\n",
    "                    \"hidden_size\": 50,\n",
    "                    \"num_layers\": 1,\n",
    "                    \"bidirectional\": true\n",
    "              }\n",
    "            }\n",
    "      }\n",
    "    },\n",
    "    \"matcher_word\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 768+100,\n",
    "      \"num_perspectives\": 10,\n",
    "      \"with_full_match\": false\n",
    "    },\n",
    "    \"encoder1\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 768+100,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward1\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward1\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"encoder2\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 400,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward2\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward2\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"aggregator\":{\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 264,\n",
    "      \"hidden_size\": 100,\n",
    "      \"num_layers\": 1,\n",
    "      \"dropout\": 0.5\n",
    "    },\n",
    "    \"classifier_feedforward\": {\n",
    "      \"input_dim\": 400,\n",
    "      \"num_layers\": 2,\n",
    "      \"hidden_dims\": [200, 23],\n",
    "      \"activations\": [\"relu\", \"linear\"],\n",
    "      \"dropout\": [0.5, 0.0]\n",
    "    },\n",
    "    \"initializer\": [\n",
    "      [\".*linear_layers.*weight\", {\"type\": \"xavier_normal\"}],\n",
    "      [\".*linear_layers.*bias\", {\"type\": \"constant\", \"val\": 0}],\n",
    "      [\".*weight_ih.*\", {\"type\": \"xavier_normal\"}],\n",
    "      [\".*weight_hh.*\", {\"type\": \"orthogonal\"}],\n",
    "      [\".*bias.*\", {\"type\": \"constant\", \"val\": 0}],\n",
    "      [\".*matcher.*match_weights.*\", {\"type\": \"kaiming_normal\"}]\n",
    "    ]\n",
    "  },\n",
    "  \"iterator\": {\n",
    "    \"type\": \"basic\",\n",
    "    \"batch_size\": 2\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": 50,\n",
    "    \"patience\": 10,\n",
    "    \"cuda_device\": 0,\n",
    "    \"grad_norm\": 10.0,\n",
    "    \"validation_metric\": \"+accuracy\",\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"bert_adam\",\n",
    "      \"lr\": 0.002\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $MODEL_PATH/config_elmo.json\n",
    "\n",
    "// Configuration for a sentence matching model based on:\n",
    "//   Wang, Zhiguo, Wael Hamza, and Radu Florian. \"Bilateral multi-perspective matching for natural language sentences.\"\n",
    "//   Proceedings of the 26th International Joint Conference on Artificial Intelligence. 2017.\n",
    "\n",
    "{\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": \"quora_paraphrase\",\n",
    "    \"lazy\": false,\n",
    "    \"tokenizer\": {\n",
    "      \"type\": \"word\",\n",
    "      \"word_splitter\": {\n",
    "        \"type\": \"just_spaces\"\n",
    "      }\n",
    "    },\n",
    "    \"token_indexers\": {\n",
    "      \"token_characters\": {\n",
    "        \"type\": \"characters\",\n",
    "        \"min_padding_length\": 1\n",
    "      },\n",
    "      \"elmo\": {\n",
    "        \"type\": \"elmo_characters\"\n",
    "     }\n",
    "    }\n",
    "  },\n",
    "  \"train_data_path\": \"label_predictor_lstm/nlabel_cf_train.tsv\",\n",
    "  \"validation_data_path\": \"label_predictor_lstm/nlabel_cf_dev.tsv\",\n",
    "  \"test_data_path\": \"label_predictor_lstm/nlabel_cf_test.tsv\",\n",
    "  \"model\": {\n",
    "    \"type\": \"multiclass_bimpm\",\n",
    "    \"dropout\": 0.5,\n",
    "    \"class_weights\": [\n",
    "        0.025 , 0.0285, 0.0737, 0.1111, 0.1226, 0.1255, 0.1319, 0.1535,\n",
    "        0.1676, 0.1685, 0.1795, 0.1869, 0.2316, 0.2345, 0.325 , 0.3358,\n",
    "        0.3527, 0.523 , 0.5723, 0.7   , 0.8505, 0.8667, 1.0    ],\n",
    "    \"encode_together\": true,\n",
    "    \"text_field_embedder\": {\n",
    "        \"token_embedders\": {\n",
    "            \"elmo\": {\n",
    "                    \"type\": \"elmo_token_embedder\",\n",
    "                    \"options_file\": \"rsv_elmo/options.json\",\n",
    "                    \"weight_file\": \"rsv_elmo/model.hdf5\",\n",
    "                    \"do_layer_norm\": false,\n",
    "                    \"dropout\": 0.1\n",
    "            },\n",
    "            \"token_characters\": {\n",
    "                \"type\": \"character_encoding\",\n",
    "                \"embedding\": {\n",
    "                    \"embedding_dim\": 20,\n",
    "                    \"padding_index\": 0,\n",
    "                },\n",
    "                \"encoder\": {\n",
    "                    \"type\": \"gru\",\n",
    "                    \"input_size\": 20,\n",
    "                    \"hidden_size\": 50,\n",
    "                    \"num_layers\": 1,\n",
    "                    \"bidirectional\": true,\n",
    "                    \"dropout\": 0.1,\n",
    "                },\n",
    "            },\n",
    "      }\n",
    "    },\n",
    "    \"matcher_word\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 1024+100,\n",
    "      \"num_perspectives\": 10,\n",
    "      \"with_full_match\": false\n",
    "    },\n",
    "    \"encoder1\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 1024+100,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward1\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward1\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"encoder2\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 400,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward2\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward2\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"aggregator\":{\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 264,\n",
    "      \"hidden_size\": 100,\n",
    "      \"num_layers\": 1,\n",
    "    },\n",
    "    \"classifier_feedforward\": {\n",
    "      \"input_dim\": 400,\n",
    "      \"num_layers\": 1,\n",
    "      \"hidden_dims\": [23,],\n",
    "      \"activations\": [\"linear\"],\n",
    "      \"dropout\": [0.0]\n",
    "    },\n",
    "    \"initializer\": [\n",
    "      [\".*linear_layers.*weight\", {\"type\": \"xavier_normal\"}],\n",
    "      [\".*linear_layers.*bias\", {\"type\": \"constant\", \"val\": 0}],\n",
    "      [\".*weight_ih.*\", {\"type\": \"xavier_normal\"}],\n",
    "      [\".*weight_hh.*\", {\"type\": \"orthogonal\"}],\n",
    "      [\".*bias.*\", {\"type\": \"constant\", \"val\": 0}],\n",
    "      [\".*matcher.*match_weights.*\", {\"type\": \"kaiming_normal\"}]\n",
    "    ],\n",
    "  },\n",
    "  \"iterator\": {\n",
    "    \"type\": \"bucket\",\n",
    "    \"padding_noise\": 0,\n",
    "    \"sorting_keys\": [[\"premise\", \"num_tokens\"], [\"hypothesis\", \"num_tokens\"]],\n",
    "    \"batch_size\": 20,\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": 100,\n",
    "    \"patience\": 10,\n",
    "    \"cuda_device\": 0,\n",
    "    \"grad_norm\": 5.0,\n",
    "    \"validation_metric\": \"+accuracy\",\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"adam\",\n",
    "      \"lr\": 0.001\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Script for training/prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/train_label_predictor.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh train_label_predictor.sh {bert|elmo} result_30\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.tsv\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.tsv\"\n",
    "\n",
    "rm -r label_predictor_lstm/${RESULT_DIR}/\n",
    "allennlp train -s label_predictor_lstm/${RESULT_DIR}/ label_predictor_lstm/config_${METHOD}.json \\\n",
    "    --include-package customization_package\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_lstm/${RESULT_DIR}/predictions_dev.json label_predictor_lstm/${RESULT_DIR}/model.tar.gz label_predictor_lstm/${DEV_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_lstm/${RESULT_DIR}/predictions_test.json label_predictor_lstm/${RESULT_DIR}/model.tar.gz label_predictor_lstm/${TEST_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/eval_label_predictor.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh train_label_predictor.sh {bert|elmo} result_30\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.tsv\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.tsv\"\n",
    "\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_lstm/${RESULT_DIR}/predictions_dev.json label_predictor_lstm/${RESULT_DIR}/model.tar.gz label_predictor_lstm/${DEV_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_lstm/${RESULT_DIR}/predictions_test.json label_predictor_lstm/${RESULT_DIR}/model.tar.gz label_predictor_lstm/${TEST_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(path):\n",
    "    result = []\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            result.append(json.loads(line)[\"label\"])\n",
    "            \n",
    "    print('length of result:', len(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = 'result_003'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "true = pd.read_csv(DEV_FILE_PATH, sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_confusion_matrix import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = list(set(true))\n",
    "labels.sort()\n",
    "plot_confusion_matrix(confusion_matrix(true[:len(pred)], pred, labels), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_mapper = {\n",
    "#     'background_NS': 'other_NS',\n",
    "#     'background_SN': 'other_SN',\n",
    "#     'comparison_NN': 'other_NN',\n",
    "#     'interpretation-evaluation_SN': 'other_SN',\n",
    "#     'interpretation-evaluation_NS': 'other_NS',\n",
    "#     'evidence_NS': 'other_NS',\n",
    "#     'restatement_NN': 'other_NN',\n",
    "#     'sequence_NN': 'other_NN',\n",
    "# #     'solutionhood_SN': 'other_NS',\n",
    "#     'cause-effect_SN': 'joint_NN',\n",
    "#     'preparation_SN': 'elaboration_NS',\n",
    "#     'background_SN': 'joint_NN',\n",
    "#     'elaboration_NS': 'joint_NN',\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes = [\n",
    "    'attribution_NS',\n",
    "    'attribution_SN',\n",
    "    'purpose_NS',\n",
    "    'purpose_SN',\n",
    "    'condition_SN',\n",
    "    'contrast_NN',\n",
    "    'condition_NS',\n",
    "    'joint_NN',\n",
    "    'concession_NS',\n",
    "    'same-unit_NN',\n",
    "    'elaboration_NS',\n",
    "    'cause-effect_NS',\n",
    "    'solutionhood_SN',\n",
    "    'cause-effect_SN'\n",
    "]\n",
    "\n",
    "class_mapper = {weird_class: 'other' + weird_class[-3:] for weird_class in labels if not weird_class in top_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in pred]\n",
    "\n",
    "pred_mapper = {\n",
    "    'other_NN': 'joint_NN',\n",
    "    'other_NS': 'joint_NN',\n",
    "    'other_SN': 'joint_NN'\n",
    "}\n",
    "pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in pred]\n",
    "\n",
    "#pred = [value if not 'other' in value else true[i] for i, value in enumerate(pred)]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(pred)[_to_stay[:len(pred)]]\n",
    "labels = list(set(_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['attribution_NS', 'purpose_NS', 'joint_NN', 'attribution_SN', 'purpose_SN', 'condition_SN', \n",
    "#           'condition_NS', 'contrast_NN', 'elaboration_NS', 'same-unit_NN', 'cause-effect_NS', \n",
    "#           'interpretation-evaluation_NS', 'concession_NS', ]\n",
    "\n",
    "# labels = ['attribution_NS', 'purpose_NS', 'attribution_SN', 'purpose_SN', 'condition_SN', 'contrast_NN', \n",
    "#           'joint_NN', 'solutionhood_SN', 'concession_NS', \n",
    "#           'condition_NS', 'cause-effect_NS', \n",
    "#           'interpretation-evaluation_NS', 'same-unit_NN', 'elaboration_NS', 'restatement_NN', \n",
    "#           'interpretation-evaluation_SN', 'preparation_SN', 'background_SN']\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(_true[:len(_pred)], _pred), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for rel in np.unique(_true):\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "true = pd.read_csv(TEST_FILE_PATH, sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_test.json')\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in pred]\n",
    "pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in pred]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(pred)[_to_stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(_true[:len(_pred)], _pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: (Logreg+Catboost) + BiMPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_state = 41\n",
    "\n",
    "# train_samples = []\n",
    "test_samples = []\n",
    "dev_samples = []\n",
    "\n",
    "# for file in train:\n",
    "#     train_samples.append(pd.read_pickle(file.replace('.edus', '.gold.pkl')))\n",
    "\n",
    "for file in dev:\n",
    "    dev_samples.append(pd.read_pickle(file.replace('.edus', '.gold.pkl')))\n",
    "    \n",
    "for file in test:\n",
    "    test_samples.append(pd.read_pickle(file.replace('.edus', '.gold.pkl')))\n",
    "\n",
    "# train_samples = pd.concat(train_samples).sample(\n",
    "#     frac=1, random_state=random_state).reset_index(drop=True)\n",
    "dev_samples = pd.concat(dev_samples).sample(\n",
    "    frac=1, random_state=random_state).reset_index(drop=True)\n",
    "test_samples = pd.concat(test_samples).sample(\n",
    "    frac=1, random_state=random_state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'category_id'\n",
    "MAX_LEN = 100\n",
    "\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "dev_samples['relation'] = dev_samples[TARGET].map(lambda row: row[:-1]) + dev_samples['order']\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                               'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "dev_samples = dev_samples[dev_samples.tokens_x.map(len) < MAX_LEN]\n",
    "dev_samples = dev_samples[dev_samples.tokens_y.map(len) < MAX_LEN]\n",
    "\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "test_samples['relation'] = test_samples[TARGET].map(lambda row: row[:-1]) + test_samples['order']\n",
    "test_samples['relation'] = test_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                               'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "test_samples = test_samples[test_samples.tokens_x.map(len) < MAX_LEN]\n",
    "test_samples = test_samples[test_samples.tokens_y.map(len) < MAX_LEN]\n",
    "\n",
    "TARGET = 'relation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fs_catboost_plus_logreg = pickle.load(open('models/label_predictor/model.pkl', 'rb'))\n",
    "lab_encoder = pickle.load(open('models/label_predictor/label_encoder.pkl', 'rb'))\n",
    "scaler = pickle.load(open('models/label_predictor/scaler.pkl', 'rb'))\n",
    "drop_columns = pickle.load(open('models/label_predictor/drop_columns.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, X_train = train_samples[TARGET].to_frame(), train_samples.drop(TARGET, axis=1).drop(\n",
    "#     columns=drop_columns + ['category_id'])\n",
    "\n",
    "y_dev, X_dev = dev_samples[TARGET].to_frame(), dev_samples.drop(TARGET, axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])\n",
    "y_test, X_test = test_samples[TARGET].to_frame(), test_samples.drop(TARGET, axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])\n",
    "\n",
    "X_scaled_np = scaler.transform(X_dev)\n",
    "X_dev = pd.DataFrame(X_scaled_np, index=X_dev.index)#, columns=X.columns)\n",
    "\n",
    "X_scaled_np = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_scaled_np, index=X_test.index)#, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = lab_encoder.inverse_transform(fs_catboost_plus_logreg.predict(X_test))\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_test.values, predicted, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_test.values, predicted, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_test.values, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predicted, digits=4))\n",
    "print('macro precision: %.2f'%(metrics.precision_score(y_test, predicted, average='macro')*100.))\n",
    "print('macro recall: %.2f'%(metrics.recall_score(y_test, predicted, average='macro')*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
