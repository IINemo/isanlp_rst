{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass relations classification used in tree building\n",
    "\n",
    "1. prepare train/test sets\n",
    "2. generate config files for bimpm model\n",
    "3. generate training/prediction script\n",
    "4. model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utils.file_reading import read_edus, read_gold, read_negative, read_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_sequence(sequence):\n",
    "    symbol_map = {\n",
    "        'x': '—Ö',\n",
    "        'X': 'X',\n",
    "        'y': '—É',\n",
    "        '‚Äî': '-',\n",
    "        '‚Äú': '¬´',\n",
    "        '‚Äò': '¬´',\n",
    "        '‚Äù': '¬ª',\n",
    "        '‚Äô': '¬ª',\n",
    "        'üòÜ': 'üòÑ',\n",
    "        'üòä': 'üòÑ',\n",
    "        'üòë': 'üòÑ',\n",
    "        'üòî': 'üòÑ',\n",
    "        'üòâ': 'üòÑ',\n",
    "        '‚ùó': 'üòÑ',\n",
    "        'ü§î': 'üòÑ',\n",
    "        'üòÖ': 'üòÑ',\n",
    "        '‚öì': 'üòÑ',\n",
    "        'Œµ': 'Œ±',\n",
    "        'Œ∂': 'Œ±',\n",
    "        'Œ∑': 'Œ±',\n",
    "        'Œº': 'Œ±',\n",
    "        'Œ¥': 'Œ±',\n",
    "        'Œª': 'Œ±',\n",
    "        'ŒΩ': 'Œ±',\n",
    "        'Œ≤': 'Œ±',\n",
    "        'Œ≥': 'Œ±',\n",
    "        '„Å®': 'Â∞ã',\n",
    "        '„ÅÆ': 'Â∞ã',\n",
    "        'Á•û': 'Â∞ã',\n",
    "        'Èö†': 'Â∞ã',\n",
    "        '„Åó': 'Â∞ã',\n",
    "    }\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for token in sequence.split():\n",
    "\n",
    "        for key, value in symbol_map.items():\n",
    "            token = token.replace(key, value)\n",
    "\n",
    "        for keyword in ['www', 'http']:\n",
    "            if keyword in token:\n",
    "                token = '_html_'\n",
    "\n",
    "        result.append(token)\n",
    "\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_samples(row):\n",
    "    if row.snippet_x[0] in (',', '.'):\n",
    "        row.snippet_x = row.snippet_x[1:].strip()\n",
    "    if row.snippet_y[0] in (',', '.'):\n",
    "        row.snippet_x += row.snippet_y[0]\n",
    "        row.snippet_y = row.snippet_y[1:].strip()\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/label_predictor_bmgf'\n",
    "! mkdir $MODEL_PATH\n",
    "\n",
    "TRAIN_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_train.tsv')\n",
    "DEV_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_dev.tsv')\n",
    "TEST_FILE_PATH = os.path.join(MODEL_PATH, 'nlabel_cf_test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. prepare train/test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.train_test_split import split_train_dev_test\n",
    "\n",
    "train, dev, test = split_train_dev_test('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "TARGET = 'category_id'\n",
    "random_state = 45\n",
    "train_samples = []\n",
    "\n",
    "for file in tqdm(train):\n",
    "    gold = read_gold(file.replace('.edus', ''), features=True)\n",
    "    gold['len_x'] = gold.tokens_x.map(len)\n",
    "    gold = gold[gold.len_x < MAX_LEN]\n",
    "    gold['len_y'] = gold.tokens_y.map(len)\n",
    "    gold = gold[gold.len_y < MAX_LEN]\n",
    "    gold['snippet_x'] = gold.tokens_x.map(lambda row: ' '.join(row))\n",
    "    gold['snippet_y'] = gold.tokens_y.map(lambda row: ' '.join(row))\n",
    "    gold = gold.apply(correct_samples, axis=1)\n",
    "    sample = gold[[TARGET, 'snippet_x', 'snippet_y', 'order', 'filename']]\n",
    "    sample = sample[sample.snippet_x.map(len) > 1]\n",
    "    sample = sample[sample.snippet_y.map(len) > 1]\n",
    "    train_samples.append(sample)\n",
    "\n",
    "train_samples = pd.concat(train_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "train_samples.reset_index(level=0, inplace=True)\n",
    "train_samples[TARGET] = train_samples[TARGET].replace([0.0], 'same-unit_m')\n",
    "train_samples['order'] = train_samples['order'].replace([0.0], 'NN')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "train_samples[TARGET] = train_samples[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "train_samples['relation'] = train_samples[TARGET].map(lambda row: row[:-1]) + train_samples['order']\n",
    "train_samples['relation'] = train_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "train_samples['relation'] = train_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "train_samples['relation'] = train_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "train_samples['relation'] = train_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                               'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "train_samples['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "counts = train_samples['relation'].value_counts(normalize=True).values\n",
    "NUMBER_CLASSES = len(counts)\n",
    "print(\"number of classes:\", NUMBER_CLASSES)\n",
    "print(\"class weights:\")\n",
    "np.round(counts.min() / counts, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples['snippet_x'] = train_samples.snippet_x.map(_prepare_sequence)\n",
    "train_samples['snippet_y'] = train_samples.snippet_y.map(_prepare_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TRAIN_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_samples[['relation', 'snippet_x', 'snippet_y', 'index']].iloc[:10].to_csv(TRAIN_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dev/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 45\n",
    "dev_samples = []\n",
    "\n",
    "for file in tqdm(dev):\n",
    "    gold = read_gold(file.replace('.edus', ''), features=True)\n",
    "    gold['len_x'] = gold.tokens_x.map(len)\n",
    "    gold = gold[gold.len_x < MAX_LEN]\n",
    "    gold['len_y'] = gold.tokens_y.map(len)\n",
    "    gold = gold[gold.len_y < MAX_LEN]\n",
    "    gold['snippet_x'] = gold.tokens_x.map(lambda row: ' '.join(row))\n",
    "    gold['snippet_y'] = gold.tokens_y.map(lambda row: ' '.join(row))\n",
    "    gold = gold.apply(correct_samples, axis=1)\n",
    "    sample = gold[[TARGET, 'snippet_x', 'snippet_y', 'order']]\n",
    "    sample = sample[sample.snippet_x.map(len) > 1]\n",
    "    sample = sample[sample.snippet_y.map(len) > 1]\n",
    "    dev_samples.append(sample)\n",
    "\n",
    "dev_samples = pd.concat(dev_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "dev_samples.reset_index(level=0, inplace=True)\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace([0.0], 'same-unit_m')\n",
    "dev_samples['order'] = dev_samples['order'].replace([0.0], 'NN')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['motivation_r',], 'condition_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dev_samples['relation'] = dev_samples[TARGET].map(lambda row: row[:-1]) + dev_samples['order']\n",
    "dev_samples['relation'].value_counts()\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                           'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "dev_samples['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_samples['snippet_x'] = dev_samples.snippet_x.map(_prepare_sequence)\n",
    "dev_samples['snippet_y'] = dev_samples.snippet_y.map(_prepare_sequence)\n",
    "dev_samples = dev_samples[dev_samples.snippet_x.map(len) > 0]\n",
    "dev_samples = dev_samples[dev_samples.snippet_y.map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(DEV_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_state = 45\n",
    "test_samples = []\n",
    "\n",
    "for file in tqdm(test):\n",
    "    gold = read_gold(file.replace('.edus', ''), features=True)\n",
    "    gold['len_x'] = gold.tokens_x.map(len)\n",
    "    gold = gold[gold.len_x < MAX_LEN]\n",
    "    gold['len_y'] = gold.tokens_y.map(len)\n",
    "    gold = gold[gold.len_y < MAX_LEN]\n",
    "    gold['snippet_x'] = gold.tokens_x.map(lambda row: ' '.join(row))\n",
    "    gold['snippet_y'] = gold.tokens_y.map(lambda row: ' '.join(row))\n",
    "    gold = gold.apply(correct_samples, axis=1)\n",
    "    sample = gold[[TARGET, 'snippet_x', 'snippet_y', 'order', 'filename']]\n",
    "    sample = sample[sample.snippet_x.map(len) > 1]\n",
    "    sample = sample[sample.snippet_y.map(len) > 1]\n",
    "    test_samples.append(sample)\n",
    "\n",
    "test_samples = pd.concat(test_samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "test_samples.reset_index(level=0, inplace=True)\n",
    "test_samples[TARGET] = test_samples[TARGET].replace([0.0], 'same-unit_m')\n",
    "test_samples['order'] = test_samples['order'].replace([0.0], 'NN')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "test_samples['relation'] = test_samples[TARGET].map(lambda row: row[:-1]) + test_samples['order']\n",
    "test_samples['relation'].value_counts()\n",
    "test_samples['relation'] = test_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                           'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "print(test_samples['relation'].value_counts())\n",
    "test_samples['snippet_x'] = test_samples.snippet_x.map(_prepare_sequence)\n",
    "test_samples['snippet_y'] = test_samples.snippet_y.map(_prepare_sequence)\n",
    "test_samples[['relation', 'snippet_x', 'snippet_y', 'index']].to_csv(TEST_FILE_PATH, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_samples.head(2).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modify model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/customization_package/model/additional_layers.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "#from utils import map_activation_str_to_layer\n",
    "from torch.nn import Dropout\n",
    "\n",
    "INF = 1e12\n",
    "_INF = -1e12\n",
    "\n",
    "def map_activation_str_to_layer(act_str):\n",
    "    _act_map = {\"none\": lambda x: x,\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"softmax\": nn.Softmax(dim=-1),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"leaky_relu\": nn.LeakyReLU(),\n",
    "            \"prelu\": nn.PReLU()}\n",
    "    try:\n",
    "        return _act_map[act_str]\n",
    "    except:\n",
    "        raise NotImplementedError(\"Error: %s activation fuction is not supported now.\" % (act_str))\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_mlp_layers=2, activation=None):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.bns = nn.ModuleList()\n",
    "        self.num_mlp_layers = num_mlp_layers\n",
    "        self.activation = activation\n",
    "        self.output_dim = output_dim \n",
    "\n",
    "        if num_mlp_layers == 1:\n",
    "            self.layers.append(nn.Linear(input_dim, output_dim))\n",
    "        else:\n",
    "            self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            for i in range(num_mlp_layers-2):\n",
    "                self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "                self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_dim))\n",
    "            self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "        # init\n",
    "        scale = 1/hidden_dim**0.5\n",
    "        for layer in self.layers:\n",
    "            nn.init.normal_(layer.weight, 0.0, scale)\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_mlp_layers-1):\n",
    "            x = self.layers[i](x)\n",
    "            x = self.bns[i](x)\n",
    "            if self.activation:\n",
    "                x = self.activation(x)\n",
    "        return self.layers[-1](x)\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        return self.output_dim\n",
    "\n",
    "\n",
    "class FullyConnectedLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedLayer, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(input_dim, hidden_dim, output_dim, num_mlp_layers=2, activation=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        return self.mlp.output_dim\n",
    "\n",
    "\n",
    "class Highway(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=1, activation=\"relu\"):\n",
    "        super(Highway, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = nn.ModuleList([nn.Linear(input_dim, input_dim * 2) for _ in range(num_layers)])\n",
    "        self.activation = map_activation_str_to_layer(activation)\n",
    "        \n",
    "        # init\n",
    "        scale = 1/input_dim**0.5\n",
    "        for layer in self.layers:\n",
    "            nn.init.normal_(layer.weight, 0.0, scale)\n",
    "            nn.init.constant_(layer.bias[:input_dim], 0.0)\n",
    "            nn.init.constant_(layer.bias[input_dim:], 1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            o, g = layer(x).chunk(2, dim=-1)\n",
    "            o = self.activation(o)\n",
    "            g = F.sigmoid(g)\n",
    "            x = g * x + (1 - g) * o\n",
    "        return x\n",
    "\n",
    "\n",
    "def multi_perspective_match(vector1, vector2, weight):\n",
    "    assert vector1.size(0) == vector2.size(0)\n",
    "    assert weight.size(1) == vector1.size(2)\n",
    "\n",
    "    # (batch, seq_len, 1)\n",
    "    similarity_single = F.cosine_similarity(vector1, vector2, 2).unsqueeze(2)\n",
    "\n",
    "    # (1, 1, num_perspectives, hidden_size)\n",
    "    weight = weight.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # (batch, seq_len, num_perspectives, hidden_size)\n",
    "    vector1 = weight * vector1.unsqueeze(2)\n",
    "    vector2 = weight * vector2.unsqueeze(2)\n",
    "\n",
    "    similarity_multi = F.cosine_similarity(vector1, vector2, dim=3)\n",
    "\n",
    "    return similarity_single, similarity_multi\n",
    "\n",
    "\n",
    "def multi_perspective_match_pairwise(vector1, vector2, weight, eps=1e-8):\n",
    "    num_perspectives = weight.size(0)\n",
    "\n",
    "    # (1, num_perspectives, 1, hidden_size)\n",
    "    weight = weight.unsqueeze(0).unsqueeze(2)\n",
    "\n",
    "    # (batch, num_perspectives, seq_len*, hidden_size)\n",
    "    vector1 = weight * vector1.unsqueeze(1).expand(-1, num_perspectives, -1, -1)\n",
    "    vector2 = weight * vector2.unsqueeze(1).expand(-1, num_perspectives, -1, -1)\n",
    "\n",
    "    # (batch, num_perspectives, seq_len*, 1)\n",
    "    vector1_norm = vector1.norm(p=2, dim=3, keepdim=True)\n",
    "    vector2_norm = vector2.norm(p=2, dim=3, keepdim=True)\n",
    "\n",
    "    # (batch, num_perspectives, seq_len1, seq_len2)\n",
    "    mul_result = torch.matmul(vector1, vector2.transpose(2, 3))\n",
    "    norm_value = vector1_norm * vector2_norm.transpose(2, 3)\n",
    "\n",
    "    # (batch, seq_len1, seq_len2, num_perspectives)\n",
    "    return (mul_result / norm_value.clamp(min=eps)).permute(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "def masked_max(vector, mask, dim, keepdim=False, min_val=-1e7):\n",
    "    replaced_vector = vector.masked_fill(mask==0, min_val) if mask is not None else vector\n",
    "    max_value, _ = replaced_vector.max(dim=dim, keepdim=keepdim)\n",
    "    return max_value\n",
    "\n",
    "\n",
    "def masked_mean(vector, mask, dim, keepdim=False, eps=1e-8):\n",
    "    replaced_vector = vector.masked_fill(mask==0, 0.0) if mask is not None else vector\n",
    "    value_sum = torch.sum(replaced_vector, dim=dim, keepdim=keepdim)\n",
    "    value_count = torch.sum(mask.float(), dim=dim, keepdim=keepdim)\n",
    "    return value_sum / value_count.clamp(min=eps)\n",
    "\n",
    "\n",
    "def masked_softmax(vector, mask, dim=-1):\n",
    "    if mask is None:\n",
    "        result = F.softmax(vector, dim=dim)\n",
    "    else:\n",
    "        while mask.dim() < vector.dim():\n",
    "            mask = mask.unsqueeze(1)\n",
    "        masked_vector = vector.masked_fill(mask==0, _INF)\n",
    "        result = F.softmax(masked_vector, dim=dim)\n",
    "    return result\n",
    "\n",
    "\n",
    "class BiMpmMatching(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_dim,\n",
    "                 num_perspectives,\n",
    "                 share_weights_between_directions=True,\n",
    "                 with_full_match=True,\n",
    "                 with_maxpool_match=True,\n",
    "                 with_attentive_match=True,\n",
    "                 with_max_attentive_match=True):\n",
    "        super(BiMpmMatching, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_perspectives = num_perspectives\n",
    "\n",
    "        self.with_full_match = with_full_match\n",
    "        self.with_maxpool_match = with_maxpool_match\n",
    "        self.with_attentive_match = with_attentive_match\n",
    "        self.with_max_attentive_match = with_max_attentive_match\n",
    "\n",
    "        if not (with_full_match or with_maxpool_match or with_attentive_match or with_max_attentive_match):\n",
    "            raise ValueError(\"At least one of the matching method should be enabled\")\n",
    "\n",
    "        def create_parameter():  # utility function to create and initialize a parameter\n",
    "            param = nn.Parameter(torch.zeros(num_perspectives, hidden_dim))\n",
    "            nn.init.kaiming_normal_(param)\n",
    "            return param\n",
    "\n",
    "        def share_or_create(weights_to_share):  # utility function to create or share the weights\n",
    "            return weights_to_share if share_weights_between_directions else create_parameter()\n",
    "\n",
    "        output_dim = 2  # used to calculate total output dimension, 2 is for cosine max and cosine min\n",
    "        if with_full_match:\n",
    "            self.full_forward_match_weights = create_parameter()\n",
    "            self.full_forward_match_weights_reversed = share_or_create(self.full_forward_match_weights)\n",
    "            self.full_backward_match_weights = create_parameter()\n",
    "            self.full_backward_match_weights_reversed = share_or_create(self.full_backward_match_weights)\n",
    "            output_dim += (num_perspectives + 1) * 2\n",
    "\n",
    "        if with_maxpool_match:\n",
    "            self.maxpool_match_weights = create_parameter()\n",
    "            output_dim += num_perspectives * 2\n",
    "\n",
    "        if with_attentive_match:\n",
    "            self.attentive_match_weights = create_parameter()\n",
    "            self.attentive_match_weights_reversed = share_or_create(self.attentive_match_weights)\n",
    "            output_dim += num_perspectives + 1\n",
    "\n",
    "        if with_max_attentive_match:\n",
    "            self.max_attentive_match_weights = create_parameter()\n",
    "            self.max_attentive_match_weights_reversed = share_or_create(self.max_attentive_match_weights)\n",
    "            output_dim += num_perspectives + 1\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        return self.output_dim\n",
    "\n",
    "    def forward(self, context_1, mask_1, context_2, mask_2):\n",
    "        assert (not mask_2.requires_grad) and (not mask_1.requires_grad)\n",
    "        assert context_1.size(-1) == context_2.size(-1) == self.hidden_dim\n",
    "\n",
    "        # (batch,)\n",
    "        len_1 = mask_1.sum(dim=1).long()\n",
    "        len_2 = mask_2.sum(dim=1).long()\n",
    "\n",
    "        # explicitly set masked weights to zero\n",
    "        # (batch_size, seq_len*, hidden_dim)\n",
    "        context_1 = context_1 * mask_1.unsqueeze(-1)\n",
    "        context_2 = context_2 * mask_2.unsqueeze(-1)\n",
    "\n",
    "        # array to keep the matching vectors for the two sentences\n",
    "        matching_vector_1 = []\n",
    "        matching_vector_2 = []\n",
    "\n",
    "        # Step 0. unweighted cosine\n",
    "        # First calculate the cosine similarities between each forward\n",
    "        # (or backward) contextual embedding and every forward (or backward)\n",
    "        # contextual embedding of the other sentence.\n",
    "\n",
    "        # (batch, seq_len1, seq_len2)\n",
    "        cosine_sim = F.cosine_similarity(context_1.unsqueeze(-2), context_2.unsqueeze(-3), dim=3)\n",
    "\n",
    "        # (batch, seq_len*, 1)\n",
    "        cosine_max_1 = masked_max(cosine_sim, mask_2.unsqueeze(-2), dim=2, keepdim=True)\n",
    "        cosine_mean_1 = masked_mean(cosine_sim, mask_2.unsqueeze(-2), dim=2, keepdim=True)\n",
    "        cosine_max_2 = masked_max(cosine_sim.permute(0, 2, 1), mask_1.unsqueeze(-2), dim=2, keepdim=True)\n",
    "        cosine_mean_2 = masked_mean(cosine_sim.permute(0, 2, 1), mask_1.unsqueeze(-2), dim=2, keepdim=True)\n",
    "\n",
    "        matching_vector_1.extend([cosine_max_1, cosine_mean_1])\n",
    "        matching_vector_2.extend([cosine_max_2, cosine_mean_2])\n",
    "\n",
    "        # Step 1. Full-Matching\n",
    "        # Each time step of forward (or backward) contextual embedding of one sentence\n",
    "        # is compared with the last time step of the forward (or backward)\n",
    "        # contextual embedding of the other sentence\n",
    "        if self.with_full_match:\n",
    "            # (batch, 1, hidden_dim)\n",
    "            last_position_1 = (len_1 - 1).clamp(min=0)\n",
    "            last_position_1 = last_position_1.view(-1, 1, 1).expand(-1, 1, self.hidden_dim)\n",
    "            last_position_2 = (len_2 - 1).clamp(min=0)\n",
    "            last_position_2 = last_position_2.view(-1, 1, 1).expand(-1, 1, self.hidden_dim)\n",
    "\n",
    "            context_1_forward_last = context_1.gather(1, last_position_1)\n",
    "            context_2_forward_last = context_2.gather(1, last_position_2)\n",
    "            context_1_backward_last = context_1[:, 0:1, :]\n",
    "            context_2_backward_last = context_2[:, 0:1, :]\n",
    "\n",
    "            # (batch, seq_len*, num_perspectives)\n",
    "            matching_vector_1_forward_full = multi_perspective_match(context_1,\n",
    "                                                                    context_2_forward_last,\n",
    "                                                                    self.full_forward_match_weights)\n",
    "            matching_vector_2_forward_full = multi_perspective_match(context_2,\n",
    "                                                                    context_1_forward_last,\n",
    "                                                                    self.full_forward_match_weights_reversed)\n",
    "            matching_vector_1_backward_full = multi_perspective_match(context_1,\n",
    "                                                                    context_2_backward_last,\n",
    "                                                                    self.full_backward_match_weights)\n",
    "            matching_vector_2_backward_full = multi_perspective_match(context_2,\n",
    "                                                                    context_1_backward_last,\n",
    "                                                                    self.full_backward_match_weights_reversed)\n",
    "\n",
    "            matching_vector_1.extend(matching_vector_1_forward_full)\n",
    "            matching_vector_1.extend(matching_vector_1_backward_full)\n",
    "            matching_vector_2.extend(matching_vector_2_forward_full)\n",
    "            matching_vector_2.extend(matching_vector_2_backward_full)\n",
    "\n",
    "        # Step 2. Maxpooling-Matching\n",
    "        # Each time step of forward (or backward) contextual embedding of one sentence\n",
    "        # is compared with every time step of the forward (or backward)\n",
    "        # contextual embedding of the other sentence, and only the max value of each\n",
    "        # dimension is retained.\n",
    "        if self.with_maxpool_match:\n",
    "            # (batch, seq_len1, seq_len2, num_perspectives)\n",
    "            matching_vector_max = multi_perspective_match_pairwise(context_1,\n",
    "                                                                   context_2,\n",
    "                                                                   self.maxpool_match_weights)\n",
    "\n",
    "            # (batch, seq_len*, num_perspectives)\n",
    "            matching_vector_1_max = masked_max(matching_vector_max,\n",
    "                                               mask_2.unsqueeze(-2).unsqueeze(-1),\n",
    "                                               dim=2)\n",
    "            matching_vector_1_mean = masked_mean(matching_vector_max,\n",
    "                                                 mask_2.unsqueeze(-2).unsqueeze(-1),\n",
    "                                                 dim=2)\n",
    "            matching_vector_2_max = masked_max(matching_vector_max.permute(0, 2, 1, 3),\n",
    "                                               mask_1.unsqueeze(-2).unsqueeze(-1),\n",
    "                                               dim=2)\n",
    "            matching_vector_2_mean = masked_mean(matching_vector_max.permute(0, 2, 1, 3),\n",
    "                                                 mask_1.unsqueeze(-2).unsqueeze(-1),\n",
    "                                                 dim=2)\n",
    "\n",
    "            matching_vector_1.extend([matching_vector_1_max, matching_vector_1_mean])\n",
    "            matching_vector_2.extend([matching_vector_2_max, matching_vector_2_mean])\n",
    "\n",
    "\n",
    "        # Step 3. Attentive-Matching\n",
    "        # Each forward (or backward) similarity is taken as the weight\n",
    "        # of the forward (or backward) contextual embedding, and calculate an\n",
    "        # attentive vector for the sentence by weighted summing all its\n",
    "        # contextual embeddings.\n",
    "        # Finally match each forward (or backward) contextual embedding\n",
    "        # with its corresponding attentive vector.\n",
    "\n",
    "        # (batch, seq_len1, seq_len2, hidden_dim)\n",
    "        att_2 = context_2.unsqueeze(-3) * cosine_sim.unsqueeze(-1)\n",
    "\n",
    "        # (batch, seq_len1, seq_len2, hidden_dim)\n",
    "        att_1 = context_1.unsqueeze(-2) * cosine_sim.unsqueeze(-1)\n",
    "\n",
    "        if self.with_attentive_match:\n",
    "            # (batch, seq_len*, hidden_dim)\n",
    "            att_mean_2 = masked_softmax(att_2.sum(dim=2), mask_1.unsqueeze(-1))\n",
    "            att_mean_1 = masked_softmax(att_1.sum(dim=1), mask_2.unsqueeze(-1))\n",
    "\n",
    "            # (batch, seq_len*, num_perspectives)\n",
    "            matching_vector_1_att_mean = multi_perspective_match(context_1,\n",
    "                                                                 att_mean_2,\n",
    "                                                                 self.attentive_match_weights)\n",
    "            matching_vector_2_att_mean = multi_perspective_match(context_2,\n",
    "                                                                 att_mean_1,\n",
    "                                                                 self.attentive_match_weights_reversed)\n",
    "            matching_vector_1.extend(matching_vector_1_att_mean)\n",
    "            matching_vector_2.extend(matching_vector_2_att_mean)\n",
    "\n",
    "        # Step 4. Max-Attentive-Matching\n",
    "        # Pick the contextual embeddings with the highest cosine similarity as the attentive\n",
    "        # vector, and match each forward (or backward) contextual embedding with its\n",
    "        # corresponding attentive vector.\n",
    "        if self.with_max_attentive_match:\n",
    "            # (batch, seq_len*, hidden_dim)\n",
    "            att_max_2 = masked_max(att_2, mask_2.unsqueeze(-2).unsqueeze(-1), dim=2)\n",
    "            att_max_1 = masked_max(att_1.permute(0, 2, 1, 3), mask_1.unsqueeze(-2).unsqueeze(-1), dim=2)\n",
    "\n",
    "            # (batch, seq_len*, num_perspectives)\n",
    "            matching_vector_1_att_max = multi_perspective_match(context_1,\n",
    "                                                                att_max_2,\n",
    "                                                                self.max_attentive_match_weights)\n",
    "            matching_vector_2_att_max = multi_perspective_match(context_2,\n",
    "                                                                att_max_1,\n",
    "                                                                self.max_attentive_match_weights_reversed)\n",
    "\n",
    "            matching_vector_1.extend(matching_vector_1_att_max)\n",
    "            matching_vector_2.extend(matching_vector_2_att_max)\n",
    "\n",
    "        return matching_vector_1, matching_vector_2\n",
    "\n",
    "\n",
    "class MultiHeadAttn(nn.Module):\n",
    "    def __init__(self, query_dim, key_dim, value_dim, hidden_dim, num_head,\n",
    "            dropatt=0.0, \n",
    "            act_func=\"softmax\", add_zero_attn=False, \n",
    "            pre_lnorm=False, post_lnorm=False):\n",
    "        super(MultiHeadAttn, self).__init__()\n",
    "        assert hidden_dim%num_head == 0\n",
    "\n",
    "        self.query_dim = query_dim\n",
    "        self.key_dim = key_dim\n",
    "        self.value_dim = value_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.dropatt = nn.Dropout(dropatt)\n",
    "\n",
    "        head_dim = hidden_dim // num_head\n",
    "\n",
    "        self.q_net = nn.Linear(query_dim, hidden_dim, bias=False)\n",
    "        self.k_net = nn.Linear(key_dim, hidden_dim, bias=False)\n",
    "        self.v_net = nn.Linear(value_dim, hidden_dim, bias=False)\n",
    "        self.o_net = nn.Linear(hidden_dim, query_dim, bias=False)\n",
    "\n",
    "        self.scale = 1 / (head_dim ** 0.5)\n",
    "\n",
    "        self.act_func = act_func\n",
    "        self.add_zero_attn = add_zero_attn\n",
    "        self.pre_lnorm = pre_lnorm\n",
    "        self.post_lnorm = post_lnorm\n",
    "\n",
    "        if pre_lnorm:\n",
    "            self.q_layer_norm = nn.LayerNorm(query_dim)\n",
    "            self.k_layer_norm = nn.LayerNorm(key_dim)\n",
    "            self.v_layer_norm = nn.LayerNorm(value_dim)\n",
    "        if post_lnorm:\n",
    "            self.o_layer_norm = nn.LayerNorm(query_dim)\n",
    "        \n",
    "        # init\n",
    "        for net in [self.q_net, self.k_net, self.v_net, self.o_net]:\n",
    "            nn.init.xavier_uniform_(net.weight, 1.0)\n",
    "            if hasattr(net, \"bias\") and net.bias is not None:\n",
    "                nn.init.constant_(net.bias, 0.0)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            for layer_norm in [self.q_layer_norm, self.k_layer_norm, self.v_layer_norm]:\n",
    "                if hasattr(layer_norm, \"weight\"):\n",
    "                    nn.init.normal_(layer_norm.weight, 1.0, self.scale)\n",
    "                if hasattr(layer_norm, \"bias\") and layer_norm.bias is not None:\n",
    "                    nn.init.constant_(layer_norm.bias, 0.0)\n",
    "        if self.post_lnorm:\n",
    "            if hasattr(self.o_layer_norm, \"weight\"):\n",
    "                nn.init.normal_(self.o_layer_norm.weight, 1.0, self.scale)\n",
    "            if hasattr(self.o_layer_norm, \"bias\") and self.o_layer_norm.bias is not None:\n",
    "                nn.init.constant_(self.o_layer_norm.bias, 0.0)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None):\n",
    "        ##### multihead attention\n",
    "        # [bsz x hlen x num_head x head_dim]\n",
    "        bsz = query.size(0)\n",
    "\n",
    "        if self.add_zero_attn:\n",
    "            key = torch.cat([key, \n",
    "                torch.zeros((bsz, 1) + key.size()[2:], dtype=key.dtype, device=key.device)], dim=1)\n",
    "            value = torch.cat([value, \n",
    "                torch.zeros((bsz, 1) + value.size()[2:], dtype=value.dtype, device=value.device)], dim=1)\n",
    "            if attn_mask is not None:\n",
    "                attn_mask = torch.cat([attn_mask, \n",
    "                    torch.ones((bsz, 1), dtype=attn_mask.dtype, device=attn_mask.device)], dim=1)\n",
    "\n",
    "        qlen, klen, vlen = query.size(1), key.size(1), value.size(1)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            ##### layer normalization\n",
    "            query = self.q_layer_norm(query)\n",
    "            key = self.k_layer_norm(key)\n",
    "            value = self.v_layer_norm(value)\n",
    "\n",
    "        head_q = self.q_net(query).view(bsz, qlen, self.num_head, self.hidden_dim//self.num_head)\n",
    "        head_k = self.k_net(key).view(bsz, klen, self.num_head, self.hidden_dim//self.num_head)\n",
    "        head_v = self.v_net(value).view(bsz, vlen, self.num_head, self.hidden_dim//self.num_head)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head]\n",
    "        attn_score = torch.einsum(\"bind,bjnd->bijn\", (head_q, head_k))\n",
    "        attn_score.mul_(self.scale)\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_score.masked_fill_((attn_mask == 0).unsqueeze(1).unsqueeze(-1), _INF)\n",
    "            elif attn_mask.dim() == 3:\n",
    "                attn_score.masked_fill_((attn_mask == 0).unsqueeze(-1), _INF)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head]\n",
    "        if self.act_func is None or self.act_func == \"None\":\n",
    "            attn_prob = attn_score\n",
    "        elif self.act_func == \"softmax\":\n",
    "            attn_prob = F.softmax(attn_score, dim=2)\n",
    "        elif self.act_func == \"sigmoid\":\n",
    "            attn_prob = F.sigmoid(attn_score)\n",
    "        elif self.act_func == \"tanh\":\n",
    "            attn_prob = F.tanh(attn_score)\n",
    "        elif self.act_func == \"relu\":\n",
    "            attn_prob = F.relu(attn_score)\n",
    "        elif self.act_func == \"leaky_relu\":\n",
    "            attn_prob = F.leaky_relu(attn_score)\n",
    "        elif self.act_func == \"maximum\":\n",
    "            max_score = torch.max(attn_score, dim=2, keepdim=True)[0]\n",
    "            max_mask = attn_score == max_score\n",
    "            cnt = torch.sum(max_mask, dim=2, keepdim=True)\n",
    "            attn_prob = max_mask.float() / cnt.float()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        attn_prob = self.dropatt(attn_prob)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head] x [bsz x klen x num_head x head_dim] -> [bsz x qlen x num_head x head_dim]\n",
    "        attn_vec = torch.einsum(\"bijn,bjnd->bind\", (attn_prob, head_v))\n",
    "        attn_vec = attn_vec.contiguous().view(bsz, qlen, self.hidden_dim)\n",
    "\n",
    "        ##### linear projection\n",
    "        attn_out = self.o_net(attn_vec)\n",
    "        \n",
    "        if self.post_lnorm:\n",
    "            attn_out = self.o_layer_norm(attn_out)\n",
    "\n",
    "        return attn_out\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        return self.query_dim\n",
    "\n",
    "\n",
    "class GatedMultiHeadAttn(nn.Module):\n",
    "    def __init__(self, query_dim, key_dim, value_dim, hidden_dim, num_head,\n",
    "            dropatt=0.0, \n",
    "            act_func=\"softmax\", add_zero_attn=False, \n",
    "            pre_lnorm=False, post_lnorm=False):\n",
    "        super(GatedMultiHeadAttn, self).__init__()\n",
    "        assert hidden_dim%num_head == 0\n",
    "\n",
    "        self.query_dim = query_dim\n",
    "        self.key_dim = key_dim\n",
    "        self.value_dim = value_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.dropatt = nn.Dropout(dropatt)\n",
    "\n",
    "        head_dim = hidden_dim // num_head\n",
    "\n",
    "        self.q_net = nn.Linear(query_dim, hidden_dim, bias=False)\n",
    "        self.k_net = nn.Linear(key_dim, hidden_dim, bias=False)\n",
    "        self.v_net = nn.Linear(value_dim, hidden_dim, bias=False)\n",
    "        self.o_net = nn.Linear(hidden_dim, query_dim, bias=False)\n",
    "        self.g_net = nn.Linear(2*query_dim, query_dim, bias=True)\n",
    "\n",
    "        self.scale = 1 / (head_dim ** 0.5)\n",
    "\n",
    "        self.act_func = act_func\n",
    "        self.add_zero_attn = add_zero_attn\n",
    "        self.pre_lnorm = pre_lnorm\n",
    "        self.post_lnorm = post_lnorm\n",
    "\n",
    "        if pre_lnorm:\n",
    "            self.q_layer_norm = nn.LayerNorm(query_dim)\n",
    "            self.k_layer_norm = nn.LayerNorm(key_dim)\n",
    "            self.v_layer_norm = nn.LayerNorm(value_dim)\n",
    "        if post_lnorm:\n",
    "            self.o_layer_norm = nn.LayerNorm(query_dim)\n",
    "        \n",
    "        # init\n",
    "        for net in [self.q_net, self.k_net, self.v_net, self.o_net]:\n",
    "            nn.init.xavier_uniform_(net.weight, 1.0)\n",
    "            if hasattr(net, \"bias\") and net.bias is not None:\n",
    "                nn.init.constant_(net.bias, 0.0)\n",
    "        # when new data comes, it prefers to output 1 so that the gate is 1\n",
    "        nn.init.normal_(self.g_net.weight, 0.0, self.scale)\n",
    "        if hasattr(self.g_net, \"bias\") and self.g_net.bias is not None:\n",
    "            nn.init.constant_(self.g_net.bias, 1.0)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            for layer_norm in [self.q_layer_norm, self.k_layer_norm, self.v_layer_norm]:\n",
    "                if hasattr(layer_norm, \"weight\"):\n",
    "                    nn.init.normal_(layer_norm.weight, 1.0, self.scale)\n",
    "                if hasattr(layer_norm, \"bias\") and layer_norm.bias is not None:\n",
    "                    nn.init.constant_(layer_norm.bias, 0.0)\n",
    "        if self.post_lnorm:\n",
    "            if hasattr(self.o_layer_norm, \"weight\"):\n",
    "                nn.init.normal_(self.o_layer_norm.weight, 1.0, self.scale)\n",
    "            if hasattr(self.o_layer_norm, \"bias\") and self.o_layer_norm.bias is not None:\n",
    "                nn.init.constant_(self.o_layer_norm.bias, 0.0)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None):\n",
    "        ##### multihead attention\n",
    "        # [bsz x hlen x num_head x head_dim]\n",
    "        bsz = query.size(0)\n",
    "\n",
    "        if self.add_zero_attn:\n",
    "            key = torch.cat([key, \n",
    "                torch.zeros((bsz, 1) + key.size()[2:], dtype=key.dtype, device=key.device)], dim=1)\n",
    "            value = torch.cat([value, \n",
    "                torch.zeros((bsz, 1) + value.size()[2:], dtype=value.dtype, device=value.device)], dim=1)\n",
    "            if attn_mask is not None:\n",
    "                attn_mask = torch.cat([attn_mask, \n",
    "                    torch.ones((bsz, 1), dtype=attn_mask.dtype, device=attn_mask.device)], dim=1)\n",
    "\n",
    "        qlen, klen, vlen = query.size(1), key.size(1), value.size(1)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            ##### layer normalization\n",
    "            query = self.q_layer_norm(query)\n",
    "            key = self.k_layer_norm(key)\n",
    "            value = self.v_layer_norm(value)\n",
    "\n",
    "        head_q = self.q_net(query).view(bsz, qlen, self.num_head, self.hidden_dim//self.num_head)\n",
    "        head_k = self.k_net(key).view(bsz, klen, self.num_head, self.hidden_dim//self.num_head)\n",
    "        head_v = self.v_net(value).view(bsz, vlen, self.num_head, self.hidden_dim//self.num_head)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head]\n",
    "        attn_score = torch.einsum(\"bind,bjnd->bijn\", (head_q, head_k))\n",
    "        attn_score.mul_(self.scale)\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_score.masked_fill_((attn_mask == 0).unsqueeze(1).unsqueeze(-1), _INF)\n",
    "            elif attn_mask.dim() == 3:\n",
    "                attn_score.masked_fill_((attn_mask == 0).unsqueeze(-1), _INF)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head]\n",
    "        if self.act_func is None or self.act_func == \"None\":\n",
    "            attn_prob = attn_score\n",
    "        elif self.act_func == \"softmax\":\n",
    "            attn_prob = F.softmax(attn_score, dim=2)\n",
    "        elif self.act_func == \"sigmoid\":\n",
    "            attn_prob = F.sigmoid(attn_score)\n",
    "        elif self.act_func == \"tanh\":\n",
    "            attn_prob = F.tanh(attn_score)\n",
    "        elif self.act_func == \"relu\":\n",
    "            attn_prob = F.relu(attn_score)\n",
    "        elif self.act_func == \"leaky_relu\":\n",
    "            attn_prob = F.leaky_relu(attn_score)\n",
    "        elif self.act_func == \"maximum\":\n",
    "            max_score = torch.max(attn_score, dim=2, keepdim=True)[0]\n",
    "            max_mask = attn_score == max_score\n",
    "            cnt = torch.sum(max_mask, dim=2, keepdim=True)\n",
    "            attn_prob = max_mask.float() / cnt.float()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        attn_prob = self.dropatt(attn_prob)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head] x [bsz x klen x num_head x head_dim] -> [bsz x qlen x num_head x head_dim]\n",
    "        attn_vec = torch.einsum(\"bijn,bjnd->bind\", (attn_prob, head_v))\n",
    "        attn_vec = attn_vec.contiguous().view(bsz, qlen, self.hidden_dim)\n",
    "\n",
    "        ##### linear projection\n",
    "        attn_out = self.o_net(attn_vec)\n",
    "\n",
    "        ##### gate\n",
    "        gate = F.sigmoid(self.g_net(torch.cat([query, attn_out], dim=2)))\n",
    "        attn_out = gate * query + (1-gate) * attn_out\n",
    "        \n",
    "        if self.post_lnorm:\n",
    "            attn_out = self.o_layer_norm(attn_out)\n",
    "\n",
    "        return attn_out\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        return self.query_dim\n",
    "\n",
    "\n",
    "\n",
    "class CnnHighway(nn.Module):\n",
    "    def __init__(self, input_dim, filters, output_dim, num_highway=1, activation=\"relu\", projection_location=\"after_highway\", layer_norm=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert projection_location in [\"after_cnn\", \"after_highway\"]\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.projection_location = projection_location\n",
    "\n",
    "        self.activation = map_activation_str_to_layer(activation)\n",
    "        # Create the convolutions\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i, (width, num) in enumerate(filters):\n",
    "            conv = nn.Conv1d(in_channels=input_dim, out_channels=num, kernel_size=width, bias=True)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        # Create the highway layers\n",
    "        num_filters = sum(num for _, num in filters)\n",
    "        if projection_location == 'after_cnn':\n",
    "            highway_dim = output_dim\n",
    "        else:\n",
    "            # highway_dim is the number of cnn filters\n",
    "            highway_dim = num_filters\n",
    "        self.highways = Highway(highway_dim, num_highway, activation=activation)\n",
    "\n",
    "        # Projection layer: always num_filters -> output_dim\n",
    "        self.proj = nn.Linear(num_filters, output_dim)\n",
    "\n",
    "        # And add a layer norm\n",
    "        if layer_norm:\n",
    "            self.layer_norm = nn.LayerNorm(output_dim)\n",
    "        else:\n",
    "            self.layer_norm = None\n",
    "\n",
    "        # init\n",
    "        scale = 1/num_filters**0.5\n",
    "        for layer in self.convs:\n",
    "            nn.init.kaiming_normal_(layer.weight)\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "        nn.init.normal_(self.proj.weight, 0.0, scale)\n",
    "        nn.init.constant_(self.proj.bias, 0.0)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "\n",
    "        # convolutions want (batch_size, input_dim, num_characters)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        output = []\n",
    "        for conv in self.convs:\n",
    "            c = conv(x)\n",
    "            c = torch.max(c, dim=-1)[0]\n",
    "            c = self.activation(c)\n",
    "            output.append(c)\n",
    "\n",
    "        # (batch_size, n_filters)\n",
    "        output = torch.cat(output, dim=-1)\n",
    "\n",
    "        if self.projection_location == 'after_cnn':\n",
    "            output = self.proj(output)\n",
    "\n",
    "        # apply the highway layers (batch_size, highway_dim)\n",
    "        output = self.highways(output)\n",
    "\n",
    "        if self.projection_location == 'after_highway':\n",
    "            # final projection  (batch_size, output_dim)\n",
    "            output = self.proj(output)\n",
    "\n",
    "        # apply layer norm if appropriate\n",
    "        if self.layer_norm:\n",
    "            output = self.layer_norm(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        return self.output_dim\n",
    "\n",
    "class GatedMultiHeadAttn(nn.Module):\n",
    "    def __init__(self, query_dim, key_dim, value_dim, hidden_dim, num_head,\n",
    "            dropatt=0.0, \n",
    "            act_func=\"softmax\", add_zero_attn=False, \n",
    "            pre_lnorm=False, post_lnorm=False):\n",
    "        super(GatedMultiHeadAttn, self).__init__()\n",
    "        assert hidden_dim%num_head == 0\n",
    "\n",
    "        self.query_dim = query_dim\n",
    "        self.key_dim = key_dim\n",
    "        self.value_dim = value_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.dropatt = nn.Dropout(dropatt)\n",
    "\n",
    "        head_dim = hidden_dim // num_head\n",
    "\n",
    "        self.q_net = nn.Linear(query_dim, hidden_dim, bias=False)\n",
    "        self.k_net = nn.Linear(key_dim, hidden_dim, bias=False)\n",
    "        self.v_net = nn.Linear(value_dim, hidden_dim, bias=False)\n",
    "        self.o_net = nn.Linear(hidden_dim, query_dim, bias=False)\n",
    "        self.g_net = nn.Linear(2*query_dim, query_dim, bias=True)\n",
    "\n",
    "        self.scale = 1 / (head_dim ** 0.5)\n",
    "\n",
    "        self.act_func = act_func\n",
    "        self.add_zero_attn = add_zero_attn\n",
    "        self.pre_lnorm = pre_lnorm\n",
    "        self.post_lnorm = post_lnorm\n",
    "\n",
    "        if pre_lnorm:\n",
    "            self.q_layer_norm = nn.LayerNorm(query_dim)\n",
    "            self.k_layer_norm = nn.LayerNorm(key_dim)\n",
    "            self.v_layer_norm = nn.LayerNorm(value_dim)\n",
    "        if post_lnorm:\n",
    "            self.o_layer_norm = nn.LayerNorm(query_dim)\n",
    "        \n",
    "        # init\n",
    "        for net in [self.q_net, self.k_net, self.v_net, self.o_net]:\n",
    "            nn.init.xavier_uniform_(net.weight, 1.0)\n",
    "            if hasattr(net, \"bias\") and net.bias is not None:\n",
    "                nn.init.constant_(net.bias, 0.0)\n",
    "        # when new data comes, it prefers to output 1 so that the gate is 1\n",
    "        nn.init.normal_(self.g_net.weight, 0.0, self.scale)\n",
    "        if hasattr(self.g_net, \"bias\") and self.g_net.bias is not None:\n",
    "            nn.init.constant_(self.g_net.bias, 1.0)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            for layer_norm in [self.q_layer_norm, self.k_layer_norm, self.v_layer_norm]:\n",
    "                if hasattr(layer_norm, \"weight\"):\n",
    "                    nn.init.normal_(layer_norm.weight, 1.0, self.scale)\n",
    "                if hasattr(layer_norm, \"bias\") and layer_norm.bias is not None:\n",
    "                    nn.init.constant_(layer_norm.bias, 0.0)\n",
    "        if self.post_lnorm:\n",
    "            if hasattr(self.o_layer_norm, \"weight\"):\n",
    "                nn.init.normal_(self.o_layer_norm.weight, 1.0, self.scale)\n",
    "            if hasattr(self.o_layer_norm, \"bias\") and self.o_layer_norm.bias is not None:\n",
    "                nn.init.constant_(self.o_layer_norm.bias, 0.0)\n",
    "\n",
    "    def forward(self, query, key, value, attn_mask=None):\n",
    "        ##### multihead attention\n",
    "        # [bsz x hlen x num_head x head_dim]\n",
    "        bsz = query.size(0)\n",
    "\n",
    "        if self.add_zero_attn:\n",
    "            key = torch.cat([key, \n",
    "                torch.zeros((bsz, 1) + key.size()[2:], dtype=key.dtype, device=key.device)], dim=1)\n",
    "            value = torch.cat([value, \n",
    "                torch.zeros((bsz, 1) + value.size()[2:], dtype=value.dtype, device=value.device)], dim=1)\n",
    "            if attn_mask is not None:\n",
    "                attn_mask = torch.cat([attn_mask, \n",
    "                    torch.ones((bsz, 1), dtype=attn_mask.dtype, device=attn_mask.device)], dim=1)\n",
    "\n",
    "        qlen, klen, vlen = query.size(1), key.size(1), value.size(1)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            ##### layer normalization\n",
    "            query = self.q_layer_norm(query)\n",
    "            key = self.k_layer_norm(key)\n",
    "            value = self.v_layer_norm(value)\n",
    "\n",
    "        head_q = self.q_net(query).view(bsz, qlen, self.num_head, self.hidden_dim//self.num_head)\n",
    "        head_k = self.k_net(key).view(bsz, klen, self.num_head, self.hidden_dim//self.num_head)\n",
    "        head_v = self.v_net(value).view(bsz, vlen, self.num_head, self.hidden_dim//self.num_head)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head]\n",
    "        attn_score = torch.einsum(\"bind,bjnd->bijn\", (head_q, head_k))\n",
    "        attn_score.mul_(self.scale)\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_score.masked_fill_((attn_mask == 0).unsqueeze(1).unsqueeze(-1), _INF)\n",
    "            elif attn_mask.dim() == 3:\n",
    "                attn_score.masked_fill_((attn_mask == 0).unsqueeze(-1), _INF)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head]\n",
    "        if self.act_func is None or self.act_func == \"None\":\n",
    "            attn_prob = attn_score\n",
    "        elif self.act_func == \"softmax\":\n",
    "            attn_prob = F.softmax(attn_score, dim=2)\n",
    "        elif self.act_func == \"sigmoid\":\n",
    "            attn_prob = F.sigmoid(attn_score)\n",
    "        elif self.act_func == \"tanh\":\n",
    "            attn_prob = F.tanh(attn_score)\n",
    "        elif self.act_func == \"relu\":\n",
    "            attn_prob = F.relu(attn_score)\n",
    "        elif self.act_func == \"leaky_relu\":\n",
    "            attn_prob = F.leaky_relu(attn_score)\n",
    "        elif self.act_func == \"maximum\":\n",
    "            max_score = torch.max(attn_score, dim=2, keepdim=True)[0]\n",
    "            max_mask = attn_score == max_score\n",
    "            cnt = torch.sum(max_mask, dim=2, keepdim=True)\n",
    "            attn_prob = max_mask.float() / cnt.float()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        attn_prob = self.dropatt(attn_prob)\n",
    "\n",
    "        # [bsz x qlen x klen x num_head] x [bsz x klen x num_head x head_dim] -> [bsz x qlen x num_head x head_dim]\n",
    "        attn_vec = torch.einsum(\"bijn,bjnd->bind\", (attn_prob, head_v))\n",
    "        attn_vec = attn_vec.contiguous().view(bsz, qlen, self.hidden_dim)\n",
    "\n",
    "        ##### linear projection\n",
    "        attn_out = self.o_net(attn_vec)\n",
    "\n",
    "        ##### gate\n",
    "        gate = F.sigmoid(self.g_net(torch.cat([query, attn_out], dim=2)))\n",
    "        attn_out = gate * query + (1-gate) * attn_out\n",
    "        \n",
    "        if self.post_lnorm:\n",
    "            attn_out = self.o_layer_norm(attn_out)\n",
    "\n",
    "        return attn_out\n",
    "\n",
    "    def get_output_dim(self):\n",
    "        return self.query_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/customization_package/model/multiclass_bmgf.py\n",
    "\n",
    "\"\"\"\n",
    "BMGF (Bilateral Matching and Gated Fusion) model implementation.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, Optional, List, Any\n",
    "\n",
    "from overrides import overrides\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "from allennlp.common.checks import check_dimensions_match\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.modules import FeedForward, Seq2SeqEncoder, Seq2VecEncoder, TextFieldEmbedder\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.nn import InitializerApplicator, RegularizerApplicator\n",
    "from allennlp.nn import util\n",
    "from allennlp.training.metrics import CategoricalAccuracy, F1Measure\n",
    "\n",
    "from customization_package.model.additional_layers import *\n",
    "from allennlp.modules.bimpm_matching import BiMpmMatching\n",
    "\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "@Model.register(\"multiclass_bmgf\")\n",
    "class BMGFModel(Model):\n",
    "    \"\"\"\n",
    "    This ``Model`` mimics the BMGF model described in `On the Importance of Word and Sentence Representation Learning in\n",
    "Implicit Discourse Relation Classification <https://arxiv.org/pdf/2004.12617v2.pdf>`_ by Xin Liu et al., 2020.\n",
    "    implemented in https://github.com/HKUST-KnowComp/BMGF-RoBERTa>`_.\n",
    "    Additional features are added before the feedforward classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab: Vocabulary,\n",
    "                 text_field_embedder: TextFieldEmbedder,\n",
    "                 matcher_word: BiMpmMatching,\n",
    "                 encoder1: Seq2SeqEncoder,\n",
    "                 matcher_forward1: BiMpmMatching,\n",
    "                 matcher_backward1: BiMpmMatching,\n",
    "                 encoder2: Seq2SeqEncoder,\n",
    "                 matcher_forward2: BiMpmMatching,\n",
    "                 matcher_backward2: BiMpmMatching,\n",
    "                 aggregator: Seq2VecEncoder,\n",
    "                 classifier_feedforward: FeedForward,\n",
    "                 dropout: float = 0.1,\n",
    "                 hidden_dim: int = 128,\n",
    "                 num_filters: int = 64,\n",
    "                 num_perspectives: int = 16,\n",
    "                 class_weights: list = [],\n",
    "                 encode_together: bool = True,\n",
    "                 initializer: InitializerApplicator = InitializerApplicator(),\n",
    "                 regularizer: Optional[RegularizerApplicator] = None) -> None:\n",
    "        super(BMGFModel, self).__init__(vocab, regularizer)\n",
    "\n",
    "        self.text_field_embedder = text_field_embedder\n",
    "        self.encode_together = encode_together\n",
    "\n",
    "        self.matcher_word = matcher_word\n",
    "\n",
    "        self.encoder1 = encoder1\n",
    "        self.matcher_forward1 = matcher_forward1\n",
    "        self.matcher_backward1 = matcher_backward1\n",
    "\n",
    "        self.encoder2 = encoder2\n",
    "        self.matcher_forward2 = matcher_forward2\n",
    "        self.matcher_backward2 = matcher_backward2\n",
    "\n",
    "        self.aggregator = aggregator\n",
    "\n",
    "#         matching_dim = self.matcher_word.get_output_dim() + \\\n",
    "#                        self.matcher_forward1.get_output_dim() + self.matcher_backward1.get_output_dim() + \\\n",
    "#                        self.matcher_forward2.get_output_dim() + self.matcher_backward2.get_output_dim()\n",
    "\n",
    "#         check_dimensions_match(matching_dim, self.aggregator.get_input_dim(),\n",
    "#                                \"sum of dim of all matching layers\", \"aggregator input dim\")\n",
    "        \n",
    "        output_dim = self.matcher_word.get_output_dim() + self.text_field_embedder.get_output_dim()\n",
    "        output_dim = 1399\n",
    "        \n",
    "        self.gated_attn_layer = GatedMultiHeadAttn(\n",
    "            query_dim=output_dim,\n",
    "            key_dim=output_dim,\n",
    "            value_dim=output_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_head=num_perspectives,\n",
    "            dropatt=dropout,\n",
    "            act_func=\"softmax\",\n",
    "            add_zero_attn=False,\n",
    "            pre_lnorm=False,\n",
    "            post_lnorm=False)\n",
    "\n",
    "        self.conv_layer = CnnHighway(\n",
    "            input_dim=self.gated_attn_layer.get_output_dim(),\n",
    "            output_dim=hidden_dim,\n",
    "            filters=[(1, num_filters)], # , (2, num_filters)the shortest length is 2\n",
    "            num_highway=1,\n",
    "            activation=\"leaky_relu\",\n",
    "            layer_norm=False)\n",
    "\n",
    "        self.classifier_feedforward = classifier_feedforward\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.num_perspectives = num_perspectives\n",
    "        \n",
    "        if class_weights:\n",
    "            self.class_weights = class_weights\n",
    "        else:\n",
    "            self.class_weights = [1.] * self.classifier_feedforward.get_output_dim()\n",
    "\n",
    "        self.metrics = {\"accuracy\": CategoricalAccuracy(),\n",
    "                        \"f1_rel0\": F1Measure(0),\n",
    "                        \"f1_rel1\": F1Measure(1),\n",
    "                        \"f1_rel2\": F1Measure(2)}\n",
    "\n",
    "        self.loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(self.class_weights))\n",
    "\n",
    "        initializer(self)\n",
    "\n",
    "    @overrides\n",
    "    def forward(self,  # type: ignore\n",
    "                premise: Dict[str, torch.LongTensor],\n",
    "                hypothesis: Dict[str, torch.LongTensor],\n",
    "                label: torch.LongTensor = None,\n",
    "                metadata: List[Dict[str, Any]] = None  # pylint:disable=unused-argument\n",
    "               ) -> Dict[str, torch.Tensor]:\n",
    "        # pylint: disable=arguments-differ\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        premise : Dict[str, torch.LongTensor]\n",
    "            The premise from a ``TextField``\n",
    "        hypothesis : Dict[str, torch.LongTensor]\n",
    "            The hypothesis from a ``TextField``\n",
    "        label : torch.LongTensor, optional (default = None)\n",
    "            The label for the pair of the premise and the hypothesis\n",
    "        metadata : ``List[Dict[str, Any]]``, optional, (default = None)\n",
    "            Additional information about the pair\n",
    "        Returns\n",
    "        -------\n",
    "        An output dictionary consisting of:\n",
    "        logits : torch.FloatTensor\n",
    "            A tensor of shape ``(batch_size, num_labels)`` representing unnormalised log\n",
    "            probabilities of the entailment label.\n",
    "        loss : torch.FloatTensor, optional\n",
    "            A scalar loss to be optimised.\n",
    "        \"\"\"\n",
    "        \n",
    "        def encode_pair(x1, x2, mask1=None, mask2=None):\n",
    "            _joined_pair: Dict[str, torch.LongTensor] = {}\n",
    "            \n",
    "            for key in premise.keys():\n",
    "                bsz = premise[key].size(0)\n",
    "                x1_len, x2_len = premise[key].size(1), hypothesis[key].size(1)\n",
    "                sep = torch.empty([bsz, 1], dtype=torch.long, device=premise[key].device)\n",
    "                sep.data.fill_(0) # 2 is the id for </s>\n",
    "                \n",
    "                x = torch.cat([premise[key], hypothesis[key]], dim=1)\n",
    "                _joined_pair[key] = x\n",
    "                \n",
    "            x_output = self.dropout(self.text_field_embedder(_joined_pair))\n",
    "            return x_output[:, :x1_len], x_output[:, -x2_len:], mask1, mask2\n",
    "\n",
    "        mask_premise = util.get_text_field_mask(premise)\n",
    "        mask_hypothesis = util.get_text_field_mask(hypothesis)\n",
    "        \n",
    "        if self.encode_together:\n",
    "            embedded_premise, embedded_hypothesis, _, _ = encode_pair(premise, hypothesis)\n",
    "        else:\n",
    "            embedded_premise = self.dropout(self.text_field_embedder(premise))\n",
    "            embedded_hypothesis = self.dropout(self.text_field_embedder(hypothesis))\n",
    "\n",
    "        # embedding and encoding of the premise\n",
    "        encoded_premise1 = self.dropout(self.encoder1(embedded_premise, mask_premise))\n",
    "        encoded_premise2 = self.dropout(self.encoder2(encoded_premise1, mask_premise))\n",
    "\n",
    "        # embedding and encoding of the hypothesis\n",
    "        encoded_hypothesis1 = self.dropout(self.encoder1(embedded_hypothesis, mask_hypothesis))\n",
    "        encoded_hypothesis2 = self.dropout(self.encoder2(encoded_hypothesis1, mask_hypothesis))\n",
    "        \n",
    "        matching_vector_premise: List[torch.Tensor] = []\n",
    "        matching_vector_hypothesis: List[torch.Tensor] = []\n",
    "\n",
    "        def add_matching_result(matcher, encoded_premise, encoded_hypothesis):\n",
    "            # utility function to get matching result and add to the result list\n",
    "            matching_result = matcher(encoded_premise, mask_premise, encoded_hypothesis, mask_hypothesis)\n",
    "            matching_vector_premise.extend(matching_result[0])\n",
    "            matching_vector_hypothesis.extend(matching_result[1])\n",
    "\n",
    "        # calculate matching vectors from word embedding, first layer encoding, and second layer encoding\n",
    "        add_matching_result(self.matcher_word, embedded_premise, embedded_hypothesis)\n",
    "        half_hidden_size_1 = self.encoder1.get_output_dim() // 2\n",
    "        add_matching_result(self.matcher_forward1,\n",
    "                            encoded_premise1[:, :, :half_hidden_size_1],\n",
    "                            encoded_hypothesis1[:, :, :half_hidden_size_1])\n",
    "        add_matching_result(self.matcher_backward1,\n",
    "                            encoded_premise1[:, :, half_hidden_size_1:],\n",
    "                            encoded_hypothesis1[:, :, half_hidden_size_1:])\n",
    "\n",
    "        half_hidden_size_2 = self.encoder2.get_output_dim() // 2\n",
    "        add_matching_result(self.matcher_forward2,\n",
    "                            encoded_premise2[:, :, :half_hidden_size_2],\n",
    "                            encoded_hypothesis2[:, :, :half_hidden_size_2])\n",
    "        add_matching_result(self.matcher_backward2,\n",
    "                            encoded_premise2[:, :, half_hidden_size_2:],\n",
    "                            encoded_hypothesis2[:, :, half_hidden_size_2:])\n",
    "\n",
    "        # concat the matching vectors\n",
    "        matching_vector_cat_premise = self.dropout(torch.cat(matching_vector_premise, dim=2))\n",
    "        matching_vector_cat_hypothesis = self.dropout(torch.cat(matching_vector_hypothesis, dim=2))\n",
    "\n",
    "        # aggregate the matching vectors\n",
    "        aggregated_premise = self.dropout(self.aggregator(matching_vector_cat_premise, mask_premise))\n",
    "        aggregated_hypothesis = self.dropout(self.aggregator(matching_vector_cat_hypothesis, mask_hypothesis))\n",
    "        \n",
    "        #print('>>', (embedded_premise.size(), aggregated_premise.size()))\n",
    "        arg1_self_attned_feats = torch.cat([embedded_premise, matching_vector_cat_premise], dim=2)\n",
    "        arg2_self_attned_feats = torch.cat([embedded_hypothesis, matching_vector_cat_hypothesis], dim=2)\n",
    "        arg1_self_attned_feats = self.dropout(self.gated_attn_layer(\n",
    "            arg1_self_attned_feats, arg1_self_attned_feats, arg1_self_attned_feats, attn_mask=mask_premise))\n",
    "        arg2_self_attned_feats = self.dropout(self.gated_attn_layer(\n",
    "            arg2_self_attned_feats, arg2_self_attned_feats, arg2_self_attned_feats, attn_mask=mask_hypothesis))\n",
    "        \n",
    "        arg1_conv = self.dropout(self.conv_layer(arg1_self_attned_feats, mask_premise))\n",
    "        arg2_conv = self.dropout(self.conv_layer(arg2_self_attned_feats, mask_hypothesis))\n",
    "\n",
    "        # encode additional information\n",
    "        #batch_size, _ = aggregated_premise.size()\n",
    "        #encoded_meta = metadata.float().view(batch_size, -1)\n",
    "        \n",
    "        # the final forward layer\n",
    "        #logits = self.classifier_feedforward(torch.cat([aggregated_premise, aggregated_hypothesis], dim=-1))\n",
    "        logits = self.classifier_feedforward(torch.cat([arg1_conv, arg2_conv], dim=1))\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "        output_dict = {'logits': logits, \"probs\": probs}\n",
    "        \n",
    "        if label is not None:\n",
    "            loss = self.loss(logits, label)\n",
    "            for metric in self.metrics.values():\n",
    "                metric(logits, label)\n",
    "            output_dict[\"loss\"] = loss\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Converts indices to string labels, and adds a ``\"label\"`` key to the result.\n",
    "        \"\"\"\n",
    "        predictions = output_dict[\"probs\"].cpu().data.numpy()\n",
    "        argmax_indices = numpy.argmax(predictions, axis=-1)\n",
    "        labels = [self.vocab.get_token_from_index(x, namespace=\"labels\")\n",
    "                  for x in argmax_indices]\n",
    "        output_dict['label'] = labels\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        metrics = {\n",
    "            \"f1_rel0\": self.metrics[\"f1_rel0\"].get_metric(reset=reset)[2],\n",
    "            \"f1_rel1\": self.metrics[\"f1_rel1\"].get_metric(reset=reset)[2],\n",
    "            \"f1_rel2\": self.metrics[\"f1_rel2\"].get_metric(reset=reset)[2],\n",
    "            \"accuracy\": self.metrics[\"accuracy\"].get_metric(reset=reset)\n",
    "        }\n",
    "        metrics[\"f1_top3\"] = numpy.mean([metrics[\"f1_rel0\"], metrics[\"f1_rel1\"], metrics[\"f1_rel2\"]])\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $MODEL_PATH/config_elmo.json\n",
    "\n",
    "// Configuration for a sentence matching model based on:\n",
    "//   Wang, Zhiguo, Wael Hamza, and Radu Florian. \"Bilateral multi-perspective matching for natural language sentences.\"\n",
    "//   Proceedings of the 26th International Joint Conference on Artificial Intelligence. 2017.\n",
    "\n",
    "{\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": \"quora_paraphrase\",\n",
    "    \"lazy\": false,\n",
    "    \"tokenizer\": {\n",
    "      \"type\": \"word\",\n",
    "      \"word_splitter\": {\n",
    "        \"type\": \"just_spaces\"\n",
    "      }\n",
    "    },\n",
    "    \"token_indexers\": {\n",
    "      \"token_characters\": {\n",
    "        \"type\": \"characters\",\n",
    "        \"min_padding_length\": 50\n",
    "      },\n",
    "      \"elmo\": {\n",
    "        \"type\": \"elmo_characters\"\n",
    "     }\n",
    "    }\n",
    "  },\n",
    "  \"train_data_path\": \"label_predictor_bmgf/nlabel_cf_train.tsv\",\n",
    "  \"validation_data_path\": \"label_predictor_bmgf/nlabel_cf_dev.tsv\",\n",
    "  \"test_data_path\": \"label_predictor_bmgf/nlabel_cf_test.tsv\",\n",
    "  \"model\": {\n",
    "    \"type\": \"multiclass_bmgf\",\n",
    "    \"dropout\": 0.5,\n",
    "    \"class_weights\": [\n",
    "        0.03, 0.03, 0.07, 0.11, 0.12, 0.13, 0.13, 0.15, 0.17, 0.17, 0.18,\n",
    "        0.19, 0.23, 0.23, 0.33, 0.34, 0.35, 0.52, 0.57, 0.7 , 0.85, 0.87,\n",
    "        1.0  ],\n",
    "    \"encode_together\": true,\n",
    "    \"text_field_embedder\": {\n",
    "        \"token_embedders\": {\n",
    "            \"elmo\": {\n",
    "                    \"type\": \"elmo_token_embedder\",\n",
    "                    \"options_file\": \"rsv_elmo/options.json\",\n",
    "                    \"weight_file\": \"rsv_elmo/model.hdf5\",\n",
    "                    \"do_layer_norm\": false,\n",
    "                    \"dropout\": 0.1\n",
    "            },\n",
    "            \"token_characters\": {\n",
    "                \"type\": \"character_encoding\",\n",
    "                \"embedding\": {\n",
    "                    \"embedding_dim\": 20,\n",
    "                    \"padding_index\": 0,\n",
    "                },\n",
    "                \"encoder\": {\n",
    "                    \"type\": \"gru\",\n",
    "                    \"input_size\": 20,\n",
    "                    \"hidden_size\": 50,\n",
    "                    \"num_layers\": 1,\n",
    "                    \"bidirectional\": true,\n",
    "                    \"dropout\": 0.1,\n",
    "                },\n",
    "            },\n",
    "      }\n",
    "    },\n",
    "    \"matcher_word\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 1024+100,\n",
    "      \"num_perspectives\": 10,\n",
    "      \"with_full_match\": true\n",
    "    },\n",
    "    \"encoder1\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 1024+100,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward1\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward1\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"encoder2\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 400,\n",
    "      \"hidden_size\": 200,\n",
    "      \"num_layers\": 1\n",
    "    },\n",
    "    \"matcher_forward2\": {\n",
    "      \"is_forward\": true,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"matcher_backward2\": {\n",
    "      \"is_forward\": false,\n",
    "      \"hidden_dim\": 200,\n",
    "      \"num_perspectives\": 10\n",
    "    },\n",
    "    \"aggregator\":{\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 275,\n",
    "      \"hidden_size\": 100,\n",
    "      \"num_layers\": 1,\n",
    "    },\n",
    "    \"classifier_feedforward\": {\n",
    "      \"input_dim\": 256,\n",
    "      \"num_layers\": 1,\n",
    "      \"hidden_dims\": [23,],\n",
    "      \"activations\": [\"relu\"],\n",
    "      \"dropout\": [0.0]\n",
    "    },\n",
    "    \"initializer\": [\n",
    "      [\".*linear_layers.*weight\", {\"type\": \"xavier_normal\"}],\n",
    "      [\".*linear_layers.*bias\", {\"type\": \"constant\", \"val\": 0}],\n",
    "      [\".*weight_ih.*\", {\"type\": \"xavier_normal\"}],\n",
    "      [\".*weight_hh.*\", {\"type\": \"orthogonal\"}],\n",
    "      [\".*bias.*\", {\"type\": \"constant\", \"val\": 0}],\n",
    "      [\".*matcher.*match_weights.*\", {\"type\": \"kaiming_normal\"}]\n",
    "    ],\n",
    "  },\n",
    "  \"iterator\": {\n",
    "    \"type\": \"bucket\",\n",
    "    \"padding_noise\": 0,\n",
    "    \"sorting_keys\": [[\"premise\", \"num_tokens\"], [\"hypothesis\", \"num_tokens\"]],\n",
    "    \"batch_size\": 20,\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": 100,\n",
    "    \"patience\": 10,\n",
    "    \"cuda_device\": 1,\n",
    "    \"grad_norm\": 2.0,\n",
    "    \"validation_metric\": \"+accuracy\",\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"adam\",\n",
    "      \"lr\": 0.0001,\n",
    "      \"weight_decay\": 0.0005\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Script for training/prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/train_label_predictor_bmgf.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh train_label_predictor_bmgf.sh {bert|elmo} result_000\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.tsv\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.tsv\"\n",
    "\n",
    "rm -r label_predictor_bmgf/${RESULT_DIR}/\n",
    "allennlp train -s label_predictor_bmgf/${RESULT_DIR}/ label_predictor_bmgf/config_${METHOD}.json \\\n",
    "    --include-package customization_package\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_bmgf/${RESULT_DIR}/predictions_dev.json label_predictor_bmgf/${RESULT_DIR}/model.tar.gz label_predictor_bmgf/${DEV_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_bmgf/${RESULT_DIR}/predictions_test.json label_predictor_bmgf/${RESULT_DIR}/model.tar.gz label_predictor_bmgf/${TEST_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile models/eval_label_predictor_bmgf.sh\n",
    "# usage:\n",
    "# $ cd models \n",
    "# $ sh eval_label_predictor_bmgf.sh {bert|elmo} result_000\n",
    "\n",
    "export METHOD=${1}\n",
    "export RESULT_DIR=${2}\n",
    "export DEV_FILE_PATH=\"nlabel_cf_dev.tsv\"\n",
    "export TEST_FILE_PATH=\"nlabel_cf_test.tsv\"\n",
    "\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_bmgf/${RESULT_DIR}/predictions_dev.json label_predictor_bmgf/${RESULT_DIR}/model.tar.gz label_predictor_bmgf/${DEV_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment\n",
    "allennlp predict --use-dataset-reader --silent \\\n",
    "    --output-file label_predictor_bmgf/${RESULT_DIR}/predictions_test.json label_predictor_bmgf/${RESULT_DIR}/model.tar.gz label_predictor_bmgf/${TEST_FILE_PATH} \\\n",
    "    --include-package customization_package \\\n",
    "    --predictor textual-entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predictions(path):\n",
    "    result = []\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            result.append(json.loads(line)[\"label\"])\n",
    "            \n",
    "    print('length of result:', len(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = 'result_100'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "true = pd.read_csv(DEV_FILE_PATH, sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_confusion_matrix import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = list(set(true))\n",
    "labels.sort()\n",
    "plot_confusion_matrix(confusion_matrix(true[:len(pred)], pred, labels), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_mapper = {\n",
    "#     'background_NS': 'other_NS',\n",
    "#     'background_SN': 'other_SN',\n",
    "#     'comparison_NN': 'other_NN',\n",
    "#     'interpretation-evaluation_SN': 'other_SN',\n",
    "#     'interpretation-evaluation_NS': 'other_NS',\n",
    "#     'evidence_NS': 'other_NS',\n",
    "#     'restatement_NN': 'other_NN',\n",
    "#     'sequence_NN': 'other_NN',\n",
    "# #     'solutionhood_SN': 'other_NS',\n",
    "#     'cause-effect_SN': 'joint_NN',\n",
    "#     'preparation_SN': 'elaboration_NS',\n",
    "#     'background_SN': 'joint_NN',\n",
    "#     'elaboration_NS': 'joint_NN',\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes = [\n",
    "    'attribution_NS',\n",
    "    'attribution_SN',\n",
    "    'purpose_NS',\n",
    "    'purpose_SN',\n",
    "    'condition_SN',\n",
    "    'contrast_NN',\n",
    "    'condition_NS',\n",
    "    'joint_NN',\n",
    "    'concession_NS',\n",
    "    'same-unit_NN',\n",
    "    'elaboration_NS',\n",
    "    'cause-effect_NS',\n",
    "    'solutionhood_SN',\n",
    "    'cause-effect_SN'\n",
    "]\n",
    "\n",
    "class_mapper = {weird_class: 'other' + weird_class[-3:] for weird_class in labels if not weird_class in top_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in pred]\n",
    "\n",
    "pred_mapper = {\n",
    "    'other_NN': 'joint_NN',\n",
    "    'other_NS': 'joint_NN',\n",
    "    'other_SN': 'joint_NN'\n",
    "}\n",
    "pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in pred]\n",
    "\n",
    "#pred = [value if not 'other' in value else true[i] for i, value in enumerate(pred)]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(pred)[_to_stay[:len(pred)]]\n",
    "labels = list(set(_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(true[:len(pred)], pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(true[:len(pred)], pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['attribution_NS', 'purpose_NS', 'joint_NN', 'attribution_SN', 'purpose_SN', 'condition_SN', \n",
    "#           'condition_NS', 'contrast_NN', 'elaboration_NS', 'same-unit_NN', 'cause-effect_NS', \n",
    "#           'interpretation-evaluation_NS', 'concession_NS', ]\n",
    "\n",
    "# labels = ['attribution_NS', 'purpose_NS', 'attribution_SN', 'purpose_SN', 'condition_SN', 'contrast_NN', \n",
    "#           'joint_NN', 'solutionhood_SN', 'concession_NS', \n",
    "#           'condition_NS', 'cause-effect_NS', \n",
    "#           'interpretation-evaluation_NS', 'same-unit_NN', 'elaboration_NS', 'restatement_NN', \n",
    "#           'interpretation-evaluation_SN', 'preparation_SN', 'background_SN']\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(_true[:len(_pred)], _pred), target_names=labels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for rel in np.unique(_true):\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "true = pd.read_csv(TEST_FILE_PATH, sep='\\t', header=None)[0].values.tolist()\n",
    "pred = load_predictions(f'{MODEL_PATH}/{RESULT_DIR}/predictions_test.json')\n",
    "\n",
    "print(classification_report(true[:len(pred)], pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = [class_mapper.get(value) if class_mapper.get(value) else value for value in true]\n",
    "pred = [class_mapper.get(value) if class_mapper.get(value) else value for value in pred]\n",
    "pred = [pred_mapper.get(value) if pred_mapper.get(value) else value for value in pred]\n",
    "\n",
    "_to_stay = (np.array(true) != 'other_NN') & (np.array(true) != 'other_SN') & (np.array(true) != 'other_NS')\n",
    "\n",
    "_true = np.array(true)[_to_stay]\n",
    "_pred = np.array(pred)[_to_stay]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(_true[:len(_pred)], _pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "print('f1: %.2f'%(f1_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('pr: %.2f'%(precision_score(_true[:len(_pred)], _pred, average='macro')*100))\n",
    "print('re: %.2f'%(recall_score(_true[:len(_pred)], _pred, average='macro')*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: (Logreg+Catboost) + BiMPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_state = 41\n",
    "\n",
    "# train_samples = []\n",
    "test_samples = []\n",
    "dev_samples = []\n",
    "\n",
    "# for file in train:\n",
    "#     train_samples.append(pd.read_pickle(file.replace('.edus', '.gold.pkl')))\n",
    "\n",
    "for file in dev:\n",
    "    dev_samples.append(pd.read_pickle(file.replace('.edus', '.gold.pkl')))\n",
    "    \n",
    "for file in test:\n",
    "    test_samples.append(pd.read_pickle(file.replace('.edus', '.gold.pkl')))\n",
    "\n",
    "# train_samples = pd.concat(train_samples).sample(\n",
    "#     frac=1, random_state=random_state).reset_index(drop=True)\n",
    "dev_samples = pd.concat(dev_samples).sample(\n",
    "    frac=1, random_state=random_state).reset_index(drop=True)\n",
    "test_samples = pd.concat(test_samples).sample(\n",
    "    frac=1, random_state=random_state).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'category_id'\n",
    "MAX_LEN = 100\n",
    "\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "dev_samples[TARGET] = dev_samples[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "dev_samples['relation'] = dev_samples[TARGET].map(lambda row: row[:-1]) + dev_samples['order']\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "dev_samples['relation'] = dev_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                               'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "dev_samples = dev_samples[dev_samples.tokens_x.map(len) < MAX_LEN]\n",
    "dev_samples = dev_samples[dev_samples.tokens_y.map(len) < MAX_LEN]\n",
    "\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "test_samples[TARGET] = test_samples[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "test_samples['relation'] = test_samples[TARGET].map(lambda row: row[:-1]) + test_samples['order']\n",
    "test_samples['relation'] = test_samples['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "test_samples['relation'] = test_samples['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                               'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "test_samples = test_samples[test_samples.tokens_x.map(len) < MAX_LEN]\n",
    "test_samples = test_samples[test_samples.tokens_y.map(len) < MAX_LEN]\n",
    "\n",
    "TARGET = 'relation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fs_catboost_plus_logreg = pickle.load(open('models/label_predictor/model.pkl', 'rb'))\n",
    "lab_encoder = pickle.load(open('models/label_predictor/label_encoder.pkl', 'rb'))\n",
    "scaler = pickle.load(open('models/label_predictor/scaler.pkl', 'rb'))\n",
    "drop_columns = pickle.load(open('models/label_predictor/drop_columns.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, X_train = train_samples[TARGET].to_frame(), train_samples.drop(TARGET, axis=1).drop(\n",
    "#     columns=drop_columns + ['category_id'])\n",
    "\n",
    "y_dev, X_dev = dev_samples[TARGET].to_frame(), dev_samples.drop(TARGET, axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])\n",
    "y_test, X_test = test_samples[TARGET].to_frame(), test_samples.drop(TARGET, axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])\n",
    "\n",
    "X_scaled_np = scaler.transform(X_dev)\n",
    "X_dev = pd.DataFrame(X_scaled_np, index=X_dev.index)#, columns=X.columns)\n",
    "\n",
    "X_scaled_np = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_scaled_np, index=X_test.index)#, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = lab_encoder.inverse_transform(fs_catboost_plus_logreg.predict(X_test))\n",
    "\n",
    "print('weighted f1: ', metrics.f1_score(y_test.values, predicted, average='weighted'))\n",
    "print('macro f1: ', metrics.f1_score(y_test.values, predicted, average='macro'))\n",
    "print('accuracy: ', metrics.accuracy_score(y_test.values, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predicted, digits=4))\n",
    "print('macro precision: %.2f'%(metrics.precision_score(y_test, predicted, average='macro')*100.))\n",
    "print('macro recall: %.2f'%(metrics.recall_score(y_test, predicted, average='macro')*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
