{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree building evaluation on gold EDUs (mostly) and playground for tree building scripts\n",
    "\n",
    "1. Modifications of library components for tree building\n",
    "2. Scripts for test and evaluation of Sklearn-, AllenNLP- and gold-annotation-based RST parsers on manually segmented corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.print_tree import printBTree\n",
    "#from utils.rst_annotation import DiscourseUnit\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.annotation_rst import DiscourseUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTree(tree):\n",
    "    def _(n):\n",
    "        if n.relation:\n",
    "            value = (n.relation, \"%.2f\"%(n.proba))\n",
    "        else:\n",
    "            value = n.text\n",
    "        return str(value), n.left, n.right\n",
    "\n",
    "    return printBTree(_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscourseUnitCreator:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        \n",
    "    def __call__(self, left_node, right_node, proba):\n",
    "        self.id += 1\n",
    "        return DiscourseUnit(\n",
    "            id=id,\n",
    "            left=left_node,\n",
    "            right=right_node,\n",
    "            relation=1,\n",
    "            proba=proba\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv ../isanlp_rst/models/structure_predictor_lstm backup_simple_structure_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ../isanlp_rst/models/structure_predictor_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r models/structure_predictor_lstm/result_42/model.tar.gz ../isanlp_rst/models/structure_predictor_lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r models/customization_package ../isanlp_rst/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.customization_package.model.custom_bimpm_predictor import CustomBiMPMPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = CustomBiMPMPredictor.from_path('models/structure_predictor_lstm/result_42/model.tar.gz', \n",
    "                                    predictor_name='custom_bimpm_predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.predict_json({\"premise\":\"В мировой парламентской практике есть масса примеров того , как небольшая партия становилась , по сути , самой главной ,\",\n",
    "                \"hypothesis\":\"поскольку именно её немногочисленные голоса обеспечивали решающее большинство при вступлении в коалицию с одной из крупных партий .\",\n",
    "                \"metadata\":\"1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [{\"premise\":\"В мировой парламентской практике есть масса примеров того , как небольшая партия становилась , по сути , самой главной ,\",\n",
    "                       \"hypothesis\":\"поскольку именно её немногочисленные голоса обеспечивали решающее большинство при вступлении в коалицию с одной из крупных партий .\",\n",
    "                       \"metadata\":\"1\"},\n",
    "                      {\"premise\":\"Именно её немногочисленные голоса обеспечивали решающее большинство при вступлении в коалицию с одной из крупных партий .\",\n",
    "                       \"hypothesis\":\"Следующая новость - про носорогов.\",\n",
    "                       \"metadata\":\"0\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.predict_batch_json(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr.predict(premise=\"В мировой парламентской практике есть масса примеров того , как небольшая партия становилась , по сути , самой главной ,\",\n",
    "                             hypothesis=\"поскольку именно её немногочисленные голоса обеспечивали решающее большинство при вступлении в коалицию с одной из крупных партий .\",\n",
    "                             metadata=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = customization_package.model.custom_bimpm_predictor.CustomBiMPMPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors import Predictor\n",
    "\n",
    "pr = Predictor.from_path('models/structure_predictor_lstm/result_42/model.tar.gz', predictor_name='custom_bimpm_predictor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp_rst.src.isanlp_rst.sklearn_classifier import SklearnClassifier\n",
    "from isanlp_rst.src.isanlp_rst.allennlp_classifier import AllenNLPClassifier\n",
    "from isanlp_rst.src.isanlp_rst.allennlp_classifier_custom_bimpm import AllenNLPClassifier as LargeAllenNLPClassifier\n",
    "from isanlp_rst.src.isanlp_rst.rst_tree_predictor import *\n",
    "from isanlp_rst.src.isanlp_rst.greedy_rst_parser import GreedyRSTParser\n",
    "from isanlp_rst.src.isanlp_rst.features_extractor import FeaturesExtractor\n",
    "from isanlp_rst.src.isanlp_rst.features_processor_tokenizer import FeaturesProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.train_test_split import split_train_dev_test\n",
    "\n",
    "train, dev, test = split_train_dev_test('./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SPAN_PREDICTOR = {\n",
    "    'lstm': (LargeAllenNLPClassifier, 'structure_predictor_lstm', 0.1, 0.5),\n",
    "    'ensemble': (SklearnClassifier, 'structure_predictor', 0.15, 0.2),\n",
    "}\n",
    "\n",
    "_LABEL_PREDICTOR = {\n",
    "    'lstm': (AllenNLPClassifier, 'label_predictor_lstm'),\n",
    "    'ensemble': (SklearnClassifier, 'label_predictor'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_classifier = LargeAllenNLPClassifier('../isanlp_rst/models/structure_predictor_lstm/')\n",
    "label_classifier = AllenNLPClassifier('../isanlp_rst/models/label_predictor_lstm/')\n",
    "\n",
    "features_processor = FeaturesProcessor(model_dir_path='models', verbose=False)\n",
    "features_extractor = FeaturesExtractor(features_processor)\n",
    "\n",
    "predictor = LargeNNTreePredictor(features_processor=features_extractor, \n",
    "                            relation_predictor_sentence=None,\n",
    "                            relation_predictor_text=binary_classifier, \n",
    "                            label_predictor=label_classifier)\n",
    "\n",
    "paragraph_parser = GreedyRSTParser(predictor,\n",
    "                                   confidence_threshold=_SPAN_PREDICTOR['lstm'][2])\n",
    "\n",
    "document_parser = GreedyRSTParser(predictor,\n",
    "                                  confidence_threshold=_SPAN_PREDICTOR['lstm'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LargeNNTreePredictor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_document_parser = GreedyRSTParser(predictor,\n",
    "                                             confidence_threshold=_SPAN_PREDICTOR['lstm'][3]-0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.annotation import Sentence\n",
    "\n",
    "def split_by_paragraphs(annot_text, annot_tokens, annot_sentences, annot_lemma, annot_morph, annot_postag,\n",
    "                        annot_syntax_dep_tree):\n",
    "\n",
    "    def split_on_two(sents, boundary):\n",
    "        list_sum = lambda l: sum([len(sublist) for sublist in l])\n",
    "\n",
    "        i = 1\n",
    "        while list_sum(sents[:i]) < boundary and i < len(sents):\n",
    "            i += 1\n",
    "\n",
    "        intersentence_boundary = min(len(sents[i - 1]), boundary - list_sum(sents[:i - 1]))\n",
    "        return (sents[:i - 1] + [sents[i - 1][:intersentence_boundary]],\n",
    "                [sents[i - 1][intersentence_boundary:]] + sents[i:])\n",
    "\n",
    "    def recount_sentences(chunk):\n",
    "        sentences = []\n",
    "        lemma = []\n",
    "        morph = []\n",
    "        postag = []\n",
    "        syntax_dep_tree = []\n",
    "        tokens_cursor = 0\n",
    "\n",
    "        for i, sent in enumerate(chunk['syntax_dep_tree']):\n",
    "            if len(sent) > 0:\n",
    "                sentences.append(Sentence(tokens_cursor, tokens_cursor + len(sent)))\n",
    "                lemma.append(chunk['lemma'][i])\n",
    "                morph.append(chunk['morph'][i])\n",
    "                postag.append(chunk['postag'][i])\n",
    "                syntax_dep_tree.append(chunk['syntax_dep_tree'][i])\n",
    "                tokens_cursor += len(sent)\n",
    "\n",
    "        chunk['sentences'] = sentences\n",
    "        chunk['lemma'] = lemma\n",
    "        chunk['morph'] = morph\n",
    "        chunk['postag'] = postag\n",
    "        chunk['syntax_dep_tree'] = syntax_dep_tree\n",
    "\n",
    "        return chunk\n",
    "\n",
    "    chunks = []\n",
    "    prev_right_boundary = -1\n",
    "\n",
    "    for i, token in enumerate(annot_tokens[:-1]):\n",
    "\n",
    "        if '\\n' in annot_text[token.end:annot_tokens[i + 1].begin]:\n",
    "            if prev_right_boundary > -1:\n",
    "                chunk = {\n",
    "                    'text': annot_text[annot_tokens[prev_right_boundary].end:token.end + 1].strip(),\n",
    "                    'tokens': annot_tokens[prev_right_boundary + 1:i + 1]\n",
    "                }\n",
    "            else:\n",
    "                chunk = {\n",
    "                    'text': annot_text[:token.end + 1].strip(),\n",
    "                    'tokens': annot_tokens[:i + 1]\n",
    "                }\n",
    "\n",
    "            lemma, annot_lemma = split_on_two(annot_lemma, i - prev_right_boundary)\n",
    "            morph, annot_morph = split_on_two(annot_morph, i - prev_right_boundary)\n",
    "            postag, annot_postag = split_on_two(annot_postag, i - prev_right_boundary)\n",
    "            syntax_dep_tree, annot_syntax_dep_tree = split_on_two(annot_syntax_dep_tree, i - prev_right_boundary)\n",
    "\n",
    "            chunk.update({\n",
    "                'lemma': lemma,\n",
    "                'morph': morph,\n",
    "                'postag': postag,\n",
    "                'syntax_dep_tree': syntax_dep_tree,\n",
    "            })\n",
    "            chunks.append(recount_sentences(chunk))\n",
    "\n",
    "            prev_right_boundary = i  # number of last token in the last chunk\n",
    "\n",
    "    chunk = {\n",
    "        'text': annot_text[annot_tokens[prev_right_boundary].end:].strip(),\n",
    "        'tokens': annot_tokens[prev_right_boundary + 1:],\n",
    "        'lemma': annot_lemma,\n",
    "        'morph': annot_morph,\n",
    "        'postag': annot_postag,\n",
    "        'syntax_dep_tree': annot_syntax_dep_tree,\n",
    "    }\n",
    "\n",
    "    chunks.append(recount_sentences(chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_paragraphs_edus(edus, text):\n",
    "    res = []\n",
    "    parag = []\n",
    "    \n",
    "    for edu in edus:\n",
    "        parag.append(edu)\n",
    "        boundary = text.find(edu)+len(edu)\n",
    "        if boundary < len(text):\n",
    "            if text[boundary] == '\\n':\n",
    "                res.append(parag)\n",
    "                parag = []\n",
    "         \n",
    "    if parag:\n",
    "        res.append(parag)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gold_pairs(gold_pairs):\n",
    "    TARGET = 'category_id'\n",
    "\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace([0.0], 'same-unit_m')\n",
    "    gold_pairs['order'] = gold_pairs['order'].replace([0.0], 'NN')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['antithesis_r',], 'contrast_m')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['cause_r', 'effect_r'], 'cause-effect_r')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['conclusion_r',], 'restatement_m')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['evaluation_r'], 'interpretation-evaluation_r')\n",
    "    gold_pairs[TARGET] = gold_pairs[TARGET].replace(['motivation_r',], 'condition_r')\n",
    "    gold_pairs['relation'] = gold_pairs[TARGET].map(lambda row: row[:-1]) + gold_pairs['order']\n",
    "    gold_pairs['relation'].value_counts()\n",
    "    gold_pairs['relation'] = gold_pairs['relation'].replace(['restatement_SN', 'restatement_NS'], 'restatement_NN')\n",
    "    gold_pairs['relation'] = gold_pairs['relation'].replace(['contrast_SN', 'contrast_NS'], 'contrast_NN')\n",
    "    gold_pairs['relation'] = gold_pairs['relation'].replace(['solutionhood_NS', 'preparation_NS'], 'elaboration_NS')\n",
    "    gold_pairs['relation'] = gold_pairs['relation'].replace(['concession_SN', 'evaluation_SN', \n",
    "                                                             'elaboration_SN', 'evidence_SN'], 'preparation_SN')\n",
    "\n",
    "    _class_mapper = {\n",
    "            'background_NS': 'elaboration_NS',\n",
    "            'background_SN': 'preparation_SN',\n",
    "            'comparison_NN': 'contrast_NN',\n",
    "            'interpretation-evaluation_SN': 'elaboration_NS',\n",
    "            'evidence_NS': 'elaboration_NS',\n",
    "            'restatement_NN': 'joint_NN',\n",
    "            'sequence_NN': 'joint_NN'\n",
    "        }\n",
    "\n",
    "    for key, value in _class_mapper.items():\n",
    "        gold_pairs['relation'] = gold_pairs['relation'].replace(key, value)\n",
    "        \n",
    "    gold_pairs['order'] = gold_pairs['relation'].map(lambda row: row.split('_')[1])\n",
    "    gold_pairs[TARGET] = gold_pairs['relation'].map(lambda row: row.split('_')[0])\n",
    "        \n",
    "    return gold_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find edus containing multiple paragraphs and add to exceptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from utils.file_reading import *\n",
    "from utils.evaluation import extr_pairs, extr_pairs_forest\n",
    "\n",
    "\n",
    "broken_files = []\n",
    "smallest_file = 'data/news2_4.edus'\n",
    "coolest_file = 'data/blogs_17.edus'\n",
    "shit = 'data/blogs_99.edus'\n",
    "#test[:1]\n",
    "for file in tqdm(test):\n",
    "    filename = '.'.join(file.split('.')[:-1])\n",
    "    edus = read_edus(filename)\n",
    "    #gold = read_gold(filename)\n",
    "    gold = prepare_gold_pairs(read_gold(filename, features=True))\n",
    "    \n",
    "    annot = read_annotation(filename)\n",
    "    \n",
    "    for missegmentation in (\"\\nIMG\", \n",
    "                            \"\\nгимнастический коврик;\",\n",
    "                            \"\\nгантели или бутылки с песком;\",\n",
    "                            \"\\nнебольшой резиновый мяч;\",\n",
    "                            \"\\nэластичная лента (эспандер);\",\n",
    "                            \"\\nхула-хуп (обруч).\",\n",
    "                            \"\\n200?\",\n",
    "                            \"\\n300?\",\n",
    "                            \"\\nНе требуйте странного.\",\n",
    "                            \"\\nИспользуйте мою модель.\",\n",
    "                            '\\n\"А чего вы от них требуете?\"',\n",
    "                            '\\n\"Решить проблемы с тестерами\".',\n",
    "                            \"\\nКак гончая на дичь.\", \"\\nИ крупная.\",\n",
    "                            \"\\nВ прошлом году компания удивила рынок\",\n",
    "                            \"\\nЧужой этики особенно.\",\n",
    "                            \"\\nНо и своей тоже.\",\n",
    "                            \"\\nАэропорт имени,\",\n",
    "                            \"\\nА вот и монголы.\",\n",
    "                            \"\\nЗолотой Будда.\", \n",
    "                            \"\\nДворец Богдо-Хана.\",\n",
    "                            \"\\nПлощадь Сухэ-Батора.\",\n",
    "                            \"\\nОдноклассники)\",\n",
    "                            \"\\nВечерняя площадь.\",\n",
    "                            \"\\nТугрики.\",\n",
    "                            \"\\nВнутренние монголы.\",\n",
    "                            \"\\nВид сверху.\",\n",
    "                            \"\\nНациональный парк Тэрэлж. IMG IMG\",\n",
    "                            '\\nГора \"Черепаха\".',\n",
    "                            \"\\nПуть к медитации.\",\n",
    "                            \"\\nЖить надо высоко,\",\n",
    "                            \"\\nЧан с кумысом.\",\n",
    "                            \"\\nЖилая юрта.\",\n",
    "                            \"\\nКумыс.\",\n",
    "                            \"\\nТрадиционное занятие монголов\",\n",
    "                            \"\\nДвугорбый верблюд мало где\",\n",
    "                            \"\\nМонгол Шуудан переводится\",\n",
    "                            \"\\nОвощные буузы.\",\n",
    "                            \"\\nЗнаменитый чай!\"\n",
    "                            ):\n",
    "        annot['text'] = annot['text'].replace(missegmentation, ' '+missegmentation[1:])\n",
    "\n",
    "    for edu in edus:\n",
    "        if annot['text'].find(edu) == -1:\n",
    "            print(f'::: {filename} ::: {edu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from utils.file_reading import *\n",
    "from utils.evaluation import *\n",
    "\n",
    "\n",
    "broken_files = []\n",
    "smallest_file = 'data/news2_4.edus'\n",
    "weirdest_file = 'data/blogs_39.edus'\n",
    "\n",
    "for file in tqdm([weirdest_file]):\n",
    "    filename = '.'.join(file.split('.')[:-1])\n",
    "    edus = read_edus(filename)\n",
    "    gold = prepare_gold_pairs(read_gold(filename, features=True))\n",
    "    annot = read_annotation(filename)\n",
    "    \n",
    "    for missegmentation in (\"\\nIMG\", \n",
    "                            \"\\nгимнастический коврик;\",\n",
    "                            \"\\nгантели или бутылки с песком;\",\n",
    "                            \"\\nнебольшой резиновый мяч;\",\n",
    "                            \"\\nэластичная лента (эспандер);\",\n",
    "                            \"\\nхула-хуп (обруч).\",\n",
    "                            \"\\n200?\",\n",
    "                            \"\\n300?\",\n",
    "                            \"\\nНе требуйте странного.\",\n",
    "                            \"\\nИспользуйте мою модель.\",\n",
    "                            '\\n\"А чего вы от них требуете?\"',\n",
    "                            '\\n\"Решить проблемы с тестерами\".',\n",
    "                            \"\\nКак гончая на дичь.\", \"\\nИ крупная.\",\n",
    "                            \"\\nВ прошлом году компания удивила рынок\",\n",
    "                            \"\\nЧужой этики особенно.\",\n",
    "                            \"\\nНо и своей тоже.\",\n",
    "                            \"\\nАэропорт имени,\",\n",
    "                            \"\\nА вот и монголы.\",\n",
    "                            \"\\nЗолотой Будда.\", \n",
    "                            \"\\nДворец Богдо-Хана.\",\n",
    "                            \"\\nПлощадь Сухэ-Батора.\",\n",
    "                            \"\\nОдноклассники)\",\n",
    "                            \"\\nВечерняя площадь.\",\n",
    "                            \"\\nТугрики.\",\n",
    "                            \"\\nВнутренние монголы.\",\n",
    "                            \"\\nВид сверху.\",\n",
    "                            \"\\nНациональный парк Тэрэлж. IMG IMG\",\n",
    "                            '\\nГора \"Черепаха\".',\n",
    "                            \"\\nПуть к медитации.\",\n",
    "                            \"\\nЖить надо высоко,\",\n",
    "                            \"\\nЧан с кумысом.\",\n",
    "                            \"\\nЖилая юрта.\",\n",
    "                            \"\\nКумыс.\",\n",
    "                            \"\\nТрадиционное занятие монголов\",\n",
    "                            \"\\nДвугорбый верблюд мало где\",\n",
    "                            \"\\nМонгол Шуудан переводится\",\n",
    "                            \"\\nОвощные буузы.\",\n",
    "                            \"\\nЗнаменитый чай!\"\n",
    "                            ):\n",
    "        annot['text'] = annot['text'].replace(missegmentation, ' '+missegmentation[1:])\n",
    "\n",
    "    \n",
    "    if '\\n' in annot['text']:\n",
    "        chunks = split_by_paragraphs(\n",
    "            annot['text'],\n",
    "            annot['tokens'], \n",
    "            annot['sentences'], \n",
    "            annot['lemma'], \n",
    "            annot['morph'], \n",
    "            annot['postag'], \n",
    "            annot['syntax_dep_tree'])\n",
    "        \n",
    "        chunked_edus = split_by_paragraphs_edus(edus, annot['text'])\n",
    "    \n",
    "    dus = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        _edus = []\n",
    "        last_end = 0\n",
    "        \n",
    "        for max_id in range(len(chunked_edus[i])):\n",
    "            start = len(annot['text'][:last_end]) + annot['text'][last_end:].find(chunked_edus[i][max_id])\n",
    "            end = start + len(chunked_edus[i][max_id])\n",
    "            temp = DiscourseUnit(\n",
    "                    id=max_id,\n",
    "                    left=None,\n",
    "                    right=None,\n",
    "                    relation='edu',\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    orig_text=annot['text'],\n",
    "                    proba=1.,\n",
    "                )\n",
    "\n",
    "            _edus.append(temp)\n",
    "            last_end = end + 1\n",
    "            \n",
    "        if len(_edus) == 1:\n",
    "            dus += _edus\n",
    "            start_id = _edus[-1].id + 1\n",
    "\n",
    "        elif len(_edus) > 1:\n",
    "            trees = paragraph_parser(_edus,\n",
    "                annot['text'], chunk['tokens'], chunk['sentences'], chunk['lemma'],\n",
    "                chunk['morph'], chunk['postag'], chunk['syntax_dep_tree'])\n",
    "            \n",
    "            dus += trees\n",
    "#             print('::: chunk processed :::')\n",
    "#             print(dus[-1].text)\n",
    "            start_id = dus[-1].id + 1\n",
    "        \n",
    "    parsed = document_parser(\n",
    "                dus, \n",
    "                annot['text'], \n",
    "                annot['tokens'], \n",
    "                annot['sentences'], \n",
    "                annot['lemma'], \n",
    "                annot['morph'], \n",
    "                annot['postag'], \n",
    "                annot['syntax_dep_tree'],\n",
    "                genre=filename.split('_')[0])\n",
    "    \n",
    "    if len(parsed) > len(annot['text']) // 400:\n",
    "        parsed = additional_document_parser(\n",
    "            parsed, \n",
    "            annot['text'], \n",
    "            annot['tokens'], \n",
    "            annot['sentences'], \n",
    "            annot['lemma'], \n",
    "            annot['morph'], \n",
    "            annot['postag'], \n",
    "            annot['syntax_dep_tree'],\n",
    "            genre=filename.split('_')[0]\n",
    "        )\n",
    "    \n",
    "    parsed_pairs = pd.DataFrame(extr_pairs_forest(parsed, annot['text']), \n",
    "                                columns=['snippet_x', 'snippet_y', 'category_id', 'order'])\n",
    "    evaluation = eval_pipeline(parsed, edus, gold, annot['text'])\n",
    "    evaluation['filename'] = file\n",
    "    cache.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annot['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed[8].left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(cache)\n",
    "tmp['pr_seg'] = tmp.seg_true_pred / tmp.seg_all_pred\n",
    "tmp['re_seg'] = tmp.seg_true_pred / tmp.seg_all_true\n",
    "tmp['f1_seg'] = 2 * tmp.pr_seg * tmp.re_seg / (tmp.pr_seg + tmp.re_seg)\n",
    "tmp['pr_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_pred\n",
    "tmp['re_unlab'] = tmp.unlab_true_pred / tmp.unlab_all_true\n",
    "tmp['f1_unlab'] = 2 * tmp.pr_unlab * tmp.re_unlab / (tmp.pr_unlab + tmp.re_unlab)\n",
    "tmp['pr_lab'] = tmp.lab_true_pred / tmp.lab_all_pred\n",
    "tmp['re_lab'] = tmp.lab_true_pred / tmp.lab_all_true\n",
    "tmp['f1_lab'] = 2 * tmp.pr_lab * tmp.re_lab / (tmp.pr_lab + tmp.re_lab)\n",
    "tmp['pr_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_pred\n",
    "tmp['re_nuc'] = tmp.nuc_true_pred / tmp.nuc_all_true\n",
    "tmp['f1_nuc'] = 2 * tmp.pr_nuc * tmp.re_nuc / (tmp.pr_nuc + tmp.re_nuc)\n",
    "tmp['pr_full'] = tmp.full_true_pred / tmp.full_all_pred\n",
    "tmp['re_full'] = tmp.full_true_pred / tmp.full_all_true\n",
    "tmp['f1_full'] = 2 * tmp.pr_full * tmp.re_full / (tmp.pr_full + tmp.re_full)\n",
    "tmp.sort_values('f1_unlab', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = 44./200\n",
    "pr = .5\n",
    "f1 = 2. * pr * re / (pr + re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlabeled tree building score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_micro = tmp.unlab_true_pred.sum() / tmp.unlab_all_pred.sum() * 100.\n",
    "re_micro = tmp.unlab_true_pred.sum() / tmp.unlab_all_true.sum() * 100.\n",
    "f1_micro = 2. * pr_micro * re_micro / (pr_micro + re_micro)\n",
    "\n",
    "unlab_micro = (pr_micro, re_micro, f1_micro)\n",
    "unlab_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_macro = tmp.pr_unlab.sum() / tmp.shape[0] * 100.\n",
    "re_macro = tmp.re_unlab.sum() / tmp.shape[0] * 100.\n",
    "f1_macro = 2. * pr_macro * re_macro / (pr_macro + re_macro)\n",
    "\n",
    "unlab_macro = (pr_macro, re_macro, f1_macro)\n",
    "unlab_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled tree building score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_micro = tmp.lab_true_pred.sum() / tmp.lab_all_pred.sum() * 100.\n",
    "re_micro = tmp.lab_true_pred.sum() / tmp.lab_all_true.sum() * 100.\n",
    "f1_micro = 2. * pr_micro * re_micro / (pr_micro + re_micro)\n",
    "\n",
    "lab_micro = (pr_micro, re_micro, f1_micro)\n",
    "lab_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_macro = tmp.pr_lab.sum() / tmp.shape[0] * 100.\n",
    "re_macro = tmp.re_lab.sum() / tmp.shape[0] * 100.\n",
    "f1_macro = 2. * pr_macro * re_macro / (pr_macro + re_macro)\n",
    "\n",
    "lab_macro = (pr_macro, re_macro, f1_macro)\n",
    "lab_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuclearity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_micro = tmp.nuc_true_pred.sum() / tmp.nuc_all_pred.sum() * 100.\n",
    "re_micro = tmp.nuc_true_pred.sum() / tmp.nuc_all_true.sum() * 100.\n",
    "f1_micro = 2. * pr_micro * re_micro / (pr_micro + re_micro)\n",
    "\n",
    "nuc_micro = (pr_micro, re_micro, f1_micro)\n",
    "nuc_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_macro = tmp.pr_nuc.sum() / tmp.shape[0] * 100.\n",
    "re_macro = tmp.re_nuc.sum() / tmp.shape[0] * 100.\n",
    "f1_macro = 2. * pr_macro * re_macro / (pr_macro + re_macro)\n",
    "\n",
    "nuc_macro = (pr_macro, re_macro, f1_macro)\n",
    "nuc_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full tree building score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_micro = tmp.full_true_pred.sum() / tmp.full_all_pred.sum() * 100.\n",
    "re_micro = tmp.full_true_pred.sum() / tmp.full_all_true.sum() * 100.\n",
    "f1_micro = 2. * pr_micro * re_micro / (pr_micro + re_micro)\n",
    "\n",
    "full_micro = pr_micro, re_micro, f1_micro\n",
    "full_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_macro = tmp.pr_full.sum() / tmp.shape[0] * 100.\n",
    "re_macro = tmp.re_full.sum() / tmp.shape[0] * 100.\n",
    "f1_macro = 2. * pr_macro * re_macro / (pr_macro + re_macro)\n",
    "\n",
    "full_macro = (pr_macro, re_macro, f1_macro)\n",
    "full_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_table = pd.DataFrame(columns=['component', 'P', 'R', 'F1', 'P', 'R', 'F1'], data=[\n",
    "    #['segmentation', overall_score['pr_seg'], overall_score['re_seg'], overall_score['f1_seg']],\n",
    "    ['span', unlab_micro[0], unlab_micro[1], unlab_micro[2], unlab_macro[0], unlab_macro[1], unlab_macro[2]],\n",
    "    ['nuclearity', nuc_micro[0], nuc_micro[1], nuc_micro[2], nuc_macro[0], nuc_macro[1], nuc_macro[2]],\n",
    "    ['relation', lab_micro[0], lab_micro[1], lab_micro[2], lab_macro[0], lab_macro[1], lab_macro[2]],\n",
    "    ['full', full_micro[0], full_micro[1], full_micro[2], full_macro[0], full_macro[1], full_macro[2]],\n",
    "])\n",
    "\n",
    "print(evaluation_table.to_latex(index=False, float_format='%.2f', column_format='|l|l|l|l|'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
